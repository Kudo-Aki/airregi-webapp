"""
Airãƒ¬ã‚¸ å£²ä¸Šåˆ†æãƒ»éœ€è¦äºˆæ¸¬ Webã‚¢ãƒ—ãƒªï¼ˆv12: Vertex AI AutoML Forecasting å®Œå…¨çµ±åˆç‰ˆï¼‰

v11ã‹ã‚‰ã®å¤‰æ›´ç‚¹:
1. google.generativeai â†’ google.cloud.aiplatform ã«å¤‰æ›´
2. APIã‚­ãƒ¼èªè¨¼ â†’ ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆJSONèªè¨¼ ã«å¤‰æ›´
3. çµ±è¨ˆãƒ™ãƒ¼ã‚¹äºˆæ¸¬ â†’ Vertex AI AutoML Forecastingã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå‘¼ã³å‡ºã—
4. å…±å¤‰é‡ï¼ˆå¤©æ°—ã€å…­æ›œã€ã‚¤ãƒ™ãƒ³ãƒˆç­‰ï¼‰å¯¾å¿œ
5. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–ï¼ˆAPIåˆ¶é™ã€æ¥ç¶šã‚¨ãƒ©ãƒ¼å¯¾å¿œï¼‰

v11ã‹ã‚‰ã®ç¶­æŒæ©Ÿèƒ½:
- è¤‡æ•°æˆä¸å“é¸æŠæ™‚ã«ã€Œåˆç®—ã€ã€Œå€‹åˆ¥ã€ã‚’é¸æŠå¯èƒ½
- äºˆæ¸¬æœŸé–“ã‚’ã€Œæ—¥æ•°æŒ‡å®šã€ã€ŒæœŸé–“æŒ‡å®šã€ã§é¸æŠå¯èƒ½
- æ–°è¦æˆä¸å“ã®éœ€è¦äºˆæ¸¬ï¼ˆé¡ä¼¼å•†å“ãƒ™ãƒ¼ã‚¹ï¼‰
- äºˆæ¸¬ç²¾åº¦ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
- é«˜åº¦ãªåˆ†æã‚¿ãƒ–
"""

import streamlit as st
import pandas as pd
import numpy as np
from datetime import date, datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
import plotly.express as px
import plotly.graph_objects as go
from collections import defaultdict
import calendar
import re
import os
import json
import logging
import hashlib

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import sys
sys.path.append('.')
from modules.data_loader import SheetsDataLoader, aggregate_by_products, merge_with_calendar
from modules.product_normalizer import ProductNormalizer
import config

# é«˜åº¦ãªåˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ï¼‰
try:
    from modules.demand_analyzer import InternalAnalyzer, ExternalAnalyzer, MarketAnalyzer, DemandForecastEngine
    ADVANCED_ANALYSIS_AVAILABLE = True
except ImportError:
    ADVANCED_ANALYSIS_AVAILABLE = False


# =============================================================================
# Vertex AI AutoML Forecasting çµ±åˆ
# =============================================================================

# Vertex AIè¨­å®šï¼ˆconfig.pyã¾ãŸã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼‰
VERTEX_AI_CONFIG = {
    'project_id': getattr(config, 'VERTEX_AI_PROJECT_ID', os.environ.get('VERTEX_AI_PROJECT_ID', '')),
    'location': getattr(config, 'VERTEX_AI_LOCATION', os.environ.get('VERTEX_AI_LOCATION', 'asia-northeast1')),
    'endpoint_id': getattr(config, 'VERTEX_AI_ENDPOINT_ID', os.environ.get('VERTEX_AI_ENDPOINT_ID', '')),
    'service_account_file': getattr(config, 'VERTEX_AI_SERVICE_ACCOUNT_FILE', 
                                     os.environ.get('VERTEX_AI_SERVICE_ACCOUNT_FILE', 'service_account.json')),
}

# Vertex AIåˆ©ç”¨å¯èƒ½ãƒ•ãƒ©ã‚°
VERTEX_AI_AVAILABLE = False
aiplatform = None
prediction_service_client = None

try:
    from google.cloud import aiplatform
    from google.cloud.aiplatform.gapic.schema import predict as predict_schema
    from google.protobuf import json_format
    from google.protobuf.struct_pb2 import Value
    from google.oauth2 import service_account
    from google.api_core import exceptions as google_exceptions
    
    # ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆèªè¨¼
    if os.path.exists(VERTEX_AI_CONFIG['service_account_file']):
        credentials = service_account.Credentials.from_service_account_file(
            VERTEX_AI_CONFIG['service_account_file'],
            scopes=['https://www.googleapis.com/auth/cloud-platform']
        )
        
        # Vertex AIåˆæœŸåŒ–
        if VERTEX_AI_CONFIG['project_id'] and VERTEX_AI_CONFIG['endpoint_id']:
            aiplatform.init(
                project=VERTEX_AI_CONFIG['project_id'],
                location=VERTEX_AI_CONFIG['location'],
                credentials=credentials
            )
            VERTEX_AI_AVAILABLE = True
            logger.info("Vertex AI AutoML Forecasting: åˆæœŸåŒ–æˆåŠŸ")
        else:
            logger.warning("Vertex AI: project_idã¾ãŸã¯endpoint_idãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    else:
        logger.warning(f"Vertex AI: ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {VERTEX_AI_CONFIG['service_account_file']}")
        
except ImportError as e:
    logger.warning(f"Vertex AI SDKãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“: {e}")
except Exception as e:
    logger.error(f"Vertex AIåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")


class VertexAIForecaster:
    """Vertex AI AutoML Forecastingã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’å‘¼ã³å‡ºã™ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.project_id = VERTEX_AI_CONFIG['project_id']
        self.location = VERTEX_AI_CONFIG['location']
        self.endpoint_id = VERTEX_AI_CONFIG['endpoint_id']
        self.endpoint_name = f"projects/{self.project_id}/locations/{self.location}/endpoints/{self.endpoint_id}"
        self._client = None
    
    @property
    def client(self):
        """Prediction Service Clientã‚’å–å¾—ï¼ˆé…å»¶åˆæœŸåŒ–ï¼‰"""
        if self._client is None:
            from google.cloud.aiplatform_v1.services.prediction_service import PredictionServiceClient
            from google.cloud.aiplatform_v1.types import PredictRequest
            
            client_options = {"api_endpoint": f"{self.location}-aiplatform.googleapis.com"}
            credentials = service_account.Credentials.from_service_account_file(
                VERTEX_AI_CONFIG['service_account_file'],
                scopes=['https://www.googleapis.com/auth/cloud-platform']
            )
            self._client = PredictionServiceClient(
                credentials=credentials,
                client_options=client_options
            )
        return self._client
    
    def prepare_forecast_instances(
        self,
        historical_data: pd.DataFrame,
        forecast_horizon: int,
        product_id: str,
        covariates: Optional[Dict[str, List]] = None
    ) -> List[Dict[str, Any]]:
        """
        Vertex AI Forecasting APIãŒæœŸå¾…ã™ã‚‹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å½¢å¼ã‚’æº–å‚™
        
        Args:
            historical_data: éå»ã®å£²ä¸Šãƒ‡ãƒ¼ã‚¿ï¼ˆdate, è²©å£²å•†å“æ•°ï¼‰
            forecast_horizon: äºˆæ¸¬æ—¥æ•°
            product_id: å•†å“è­˜åˆ¥å­
            covariates: å°†æ¥åˆ©ç”¨å¯èƒ½ãªå…±å¤‰é‡ï¼ˆå¤©æ°—ã€å…­æ›œã€ã‚¤ãƒ™ãƒ³ãƒˆç­‰ï¼‰
        
        Returns:
            APIãƒªã‚¯ã‚¨ã‚¹ãƒˆç”¨ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãƒªã‚¹ãƒˆ
        """
        df = historical_data.copy()
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values('date')
        
        # æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        time_series = []
        for _, row in df.iterrows():
            time_series.append({
                'timestamp': row['date'].strftime('%Y-%m-%dT00:00:00Z'),
                'target': float(row['è²©å£²å•†å“æ•°'])
            })
        
        # äºˆæ¸¬æœŸé–“ã®æº–å‚™
        last_date = df['date'].max()
        forecast_timestamps = []
        for i in range(1, forecast_horizon + 1):
            future_date = last_date + timedelta(days=i)
            forecast_timestamps.append(future_date.strftime('%Y-%m-%dT00:00:00Z'))
        
        # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ§‹é€ ã®æ§‹ç¯‰
        instance = {
            'time_series_identifier': product_id,
            'time_column': 'timestamp',
            'target_column': 'target',
            'historical_data': time_series,
            'forecast_horizon': forecast_horizon,
            'forecast_timestamps': forecast_timestamps,
        }
        
        # å…±å¤‰é‡ã®è¿½åŠ ï¼ˆå¤©æ°—ã€å…­æ›œã€ã‚¤ãƒ™ãƒ³ãƒˆç­‰ï¼‰
        if covariates:
            instance['available_at_forecast_columns'] = list(covariates.keys())
            
            # éå»ãƒ‡ãƒ¼ã‚¿ã®å…±å¤‰é‡
            if 'historical_covariates' in covariates:
                instance['historical_covariates'] = covariates['historical_covariates']
            
            # å°†æ¥ãƒ‡ãƒ¼ã‚¿ã®å…±å¤‰é‡
            if 'future_covariates' in covariates:
                instance['future_covariates'] = covariates['future_covariates']
        
        return [instance]
    
    def predict(
        self,
        historical_data: pd.DataFrame,
        forecast_horizon: int,
        product_id: str = "default",
        covariates: Optional[Dict[str, List]] = None
    ) -> Tuple[pd.DataFrame, Dict[str, Any]]:
        """
        Vertex AI AutoML Forecastingã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«äºˆæ¸¬ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
        
        Args:
            historical_data: éå»ã®å£²ä¸Šãƒ‡ãƒ¼ã‚¿
            forecast_horizon: äºˆæ¸¬æ—¥æ•°
            product_id: å•†å“è­˜åˆ¥å­
            covariates: å…±å¤‰é‡ãƒ‡ãƒ¼ã‚¿
        
        Returns:
            äºˆæ¸¬çµæœã®DataFrameã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        """
        if not VERTEX_AI_AVAILABLE:
            raise RuntimeError("Vertex AIãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        
        try:
            # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æº–å‚™
            instances = self.prepare_forecast_instances(
                historical_data, forecast_horizon, product_id, covariates
            )
            
            # Protobufå½¢å¼ã«å¤‰æ›
            instances_pb = [json_format.ParseDict(inst, Value()) for inst in instances]
            
            # äºˆæ¸¬ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡
            response = self.client.predict(
                endpoint=self.endpoint_name,
                instances=instances_pb,
            )
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æ
            predictions = []
            metadata = {
                'model_version': getattr(response, 'model_version_id', 'unknown'),
                'deployed_model_id': getattr(response, 'deployed_model_id', 'unknown'),
            }
            
            last_date = pd.to_datetime(historical_data['date']).max()
            
            for i, prediction in enumerate(response.predictions):
                pred_dict = json_format.MessageToDict(prediction)
                
                # äºˆæ¸¬å€¤ã®å–å¾—ï¼ˆAutoML Forecastingã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ã«å¿œã˜ã¦èª¿æ•´ï¼‰
                if 'value' in pred_dict:
                    pred_value = pred_dict['value']
                elif 'predicted_target' in pred_dict:
                    pred_value = pred_dict['predicted_target']
                else:
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒªã‚¹ãƒˆå½¢å¼ã®å ´åˆ
                    pred_value = list(pred_dict.values())[0] if pred_dict else 0
                
                # äºˆæ¸¬å€¤ãŒé…åˆ—ã®å ´åˆã®å‡¦ç†
                if isinstance(pred_value, list):
                    for j, val in enumerate(pred_value):
                        predictions.append({
                            'date': last_date + timedelta(days=j+1),
                            'predicted': max(0, round(float(val))),
                            'confidence_lower': pred_dict.get('lower_bound', [None])[j] if isinstance(pred_dict.get('lower_bound'), list) else None,
                            'confidence_upper': pred_dict.get('upper_bound', [None])[j] if isinstance(pred_dict.get('upper_bound'), list) else None,
                        })
                else:
                    predictions.append({
                        'date': last_date + timedelta(days=i+1),
                        'predicted': max(0, round(float(pred_value))),
                    })
            
            return pd.DataFrame(predictions), metadata
            
        except google_exceptions.ResourceExhausted as e:
            logger.error(f"Vertex AI ã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™: {e}")
            raise RuntimeError(f"APIã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚\nè©³ç´°: {e}")
        
        except google_exceptions.InvalidArgument as e:
            logger.error(f"Vertex AI ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            raise RuntimeError(f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆå½¢å¼ãŒä¸æ­£ã§ã™ã€‚\nè©³ç´°: {e}")
        
        except google_exceptions.NotFound as e:
            logger.error(f"Vertex AI ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆæœªç™ºè¦‹: {e}")
            raise RuntimeError(f"æŒ‡å®šã•ã‚ŒãŸã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚endpoint_idã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\nè©³ç´°: {e}")
        
        except google_exceptions.PermissionDenied as e:
            logger.error(f"Vertex AI æ¨©é™ã‚¨ãƒ©ãƒ¼: {e}")
            raise RuntimeError(f"ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®æ¨©é™ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\nè©³ç´°: {e}")
        
        except Exception as e:
            logger.error(f"Vertex AI äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
            raise RuntimeError(f"äºˆæ¸¬ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\nè©³ç´°: {e}")


# Vertex AIãƒ•ã‚©ã‚¢ã‚­ãƒ£ã‚¹ã‚¿ãƒ¼ã®ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
_vertex_ai_forecaster = None

def get_vertex_ai_forecaster() -> Optional[VertexAIForecaster]:
    """Vertex AIãƒ•ã‚©ã‚¢ã‚­ãƒ£ã‚¹ã‚¿ãƒ¼ã‚’å–å¾—"""
    global _vertex_ai_forecaster
    if VERTEX_AI_AVAILABLE and _vertex_ai_forecaster is None:
        _vertex_ai_forecaster = VertexAIForecaster()
    return _vertex_ai_forecaster


# =============================================================================
# å…±å¤‰é‡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆå¤©æ°—ã€å…­æ›œã€ã‚¤ãƒ™ãƒ³ãƒˆï¼‰
# =============================================================================

def generate_covariates(start_date: date, end_date: date, location: str = "hitachinaka") -> Dict[str, List]:
    """
    å°†æ¥åˆ©ç”¨å¯èƒ½ãªå…±å¤‰é‡ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
    
    Args:
        start_date: é–‹å§‹æ—¥
        end_date: çµ‚äº†æ—¥
        location: åœ°åŸŸï¼ˆå¤©æ°—äºˆå ±ç”¨ï¼‰
    
    Returns:
        å…±å¤‰é‡ãƒ‡ãƒ¼ã‚¿ã®è¾æ›¸
    """
    covariates = {
        'future_covariates': []
    }
    
    current_date = start_date
    while current_date <= end_date:
        covariate_entry = {
            'timestamp': current_date.strftime('%Y-%m-%dT00:00:00Z'),
            'weekday': current_date.weekday(),  # 0=æœˆæ›œ, 6=æ—¥æ›œ
            'is_weekend': 1 if current_date.weekday() >= 5 else 0,
            'month': current_date.month,
            'day_of_month': current_date.day,
        }
        
        # å…­æ›œï¼ˆç°¡æ˜“è¨ˆç®—ï¼‰
        rokuyou_list = ['å¤§å®‰', 'èµ¤å£', 'å…ˆå‹', 'å‹å¼•', 'å…ˆè² ', 'ä»æ»…']
        rokuyou_idx = (current_date.year + current_date.month + current_date.day) % 6
        covariate_entry['rokuyou'] = rokuyou_idx
        covariate_entry['is_taian'] = 1 if rokuyou_list[rokuyou_idx] == 'å¤§å®‰' else 0
        
        # ç‰¹åˆ¥æœŸé–“ãƒ•ãƒ©ã‚°
        covariate_entry['is_new_year'] = 1 if (current_date.month == 1 and current_date.day <= 7) else 0
        covariate_entry['is_obon'] = 1 if (current_date.month == 8 and 13 <= current_date.day <= 16) else 0
        covariate_entry['is_shichigosan'] = 1 if (current_date.month == 11 and 10 <= current_date.day <= 20) else 0
        covariate_entry['is_golden_week'] = 1 if (current_date.month == 5 and 3 <= current_date.day <= 5) else 0
        
        covariates['future_covariates'].append(covariate_entry)
        current_date += timedelta(days=1)
    
    return covariates


# =============================================================================
# äºˆæ¸¬é–¢æ•°ï¼ˆVertex AI + ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
# =============================================================================

def get_vertex_ai_prediction(
    df: pd.DataFrame,
    periods: int,
    product_id: str = "default",
    use_covariates: bool = True
) -> Tuple[pd.DataFrame, bool, str]:
    """
    Vertex AI AutoML Forecastingã«ã‚ˆã‚‹äºˆæ¸¬ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ãï¼‰
    
    Args:
        df: å£²ä¸Šãƒ‡ãƒ¼ã‚¿ï¼ˆdate, è²©å£²å•†å“æ•°ï¼‰
        periods: äºˆæ¸¬æ—¥æ•°
        product_id: å•†å“è­˜åˆ¥å­
        use_covariates: å…±å¤‰é‡ã‚’ä½¿ç”¨ã™ã‚‹ã‹
    
    Returns:
        äºˆæ¸¬DataFrame, Vertex AIä½¿ç”¨ãƒ•ãƒ©ã‚°, ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    """
    forecaster = get_vertex_ai_forecaster()
    
    if forecaster is None:
        # Vertex AIãŒåˆ©ç”¨ä¸å¯ã®å ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        return forecast_with_seasonality_fallback(df, periods), False, "Vertex AIæœªè¨­å®šã®ãŸã‚ã€çµ±è¨ˆãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬"
    
    try:
        # å…±å¤‰é‡ã®æº–å‚™
        covariates = None
        if use_covariates:
            last_date = pd.to_datetime(df['date']).max()
            start_date = (last_date + timedelta(days=1)).date()
            end_date = (last_date + timedelta(days=periods)).date()
            covariates = generate_covariates(start_date, end_date)
        
        # Vertex AIäºˆæ¸¬
        predictions, metadata = forecaster.predict(
            historical_data=df,
            forecast_horizon=periods,
            product_id=product_id,
            covariates=covariates
        )
        
        return predictions, True, f"Vertex AI AutoML Forecasting (ãƒ¢ãƒ‡ãƒ«: {metadata.get('deployed_model_id', 'N/A')})"
        
    except RuntimeError as e:
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        logger.warning(f"Vertex AIäºˆæ¸¬å¤±æ•—ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ: {e}")
        return forecast_with_seasonality_fallback(df, periods), False, f"Vertex AIã‚¨ãƒ©ãƒ¼: {str(e)[:100]}... çµ±è¨ˆãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬"
    except Exception as e:
        logger.error(f"äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
        return forecast_with_seasonality_fallback(df, periods), False, f"ã‚¨ãƒ©ãƒ¼: {str(e)[:100]}... çµ±è¨ˆãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬"


def forecast_with_seasonality_fallback(df: pd.DataFrame, periods: int) -> pd.DataFrame:
    """
    ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®å­£ç¯€æ€§è€ƒæ…®äºˆæ¸¬ï¼ˆçµ±è¨ˆãƒ™ãƒ¼ã‚¹ï¼‰
    
    Vertex AIãŒåˆ©ç”¨ã§ããªã„å ´åˆã«ä½¿ç”¨
    """
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'])
    df = df.sort_values('date')
    
    overall_mean = df['è²©å£²å•†å“æ•°'].mean()
    
    if pd.isna(overall_mean) or overall_mean == 0:
        overall_mean = 1
    
    # æ›œæ—¥ä¿‚æ•°
    df['weekday'] = df['date'].dt.dayofweek
    weekday_means = df.groupby('weekday')['è²©å£²å•†å“æ•°'].mean()
    weekday_factor = {}
    for wd in range(7):
        if wd in weekday_means.index and weekday_means[wd] > 0:
            weekday_factor[wd] = weekday_means[wd] / overall_mean
        else:
            weekday_factor[wd] = 1.0
    
    # æœˆä¿‚æ•°
    df['month'] = df['date'].dt.month
    month_means = df.groupby('month')['è²©å£²å•†å“æ•°'].mean()
    month_factor = {}
    for m in range(1, 13):
        if m in month_means.index and month_means[m] > 0:
            month_factor[m] = month_means[m] / overall_mean
        else:
            month_factor[m] = 1.0
    
    # äºˆæ¸¬
    last_date = df['date'].max()
    future_dates = pd.date_range(start=last_date + timedelta(days=1), periods=periods, freq='D')
    
    predictions = []
    for d in future_dates:
        weekday_f = weekday_factor.get(d.dayofweek, 1.0)
        month_f = month_factor.get(d.month, 1.0)
        
        # ç‰¹åˆ¥æœŸé–“ã®èª¿æ•´
        special_factor = 1.0
        if d.month == 1 and d.day <= 7:  # æ­£æœˆ
            special_factor = 3.0
        elif d.month == 8 and 13 <= d.day <= 16:  # ãŠç›†
            special_factor = 1.5
        elif d.month == 11 and 10 <= d.day <= 20:  # ä¸ƒäº”ä¸‰
            special_factor = 1.3
        
        pred = overall_mean * weekday_f * month_f * special_factor
        pred = max(0.1, pred)
        
        predictions.append({
            'date': d,
            'predicted': round(pred)
        })
    
    return pd.DataFrame(predictions)


# =============================================================================
# äºˆæ¸¬æ–¹æ³•ã®çµ±åˆï¼ˆVertex AIå¯¾å¿œï¼‰
# =============================================================================

def forecast_with_vertex_ai(
    df: pd.DataFrame,
    periods: int,
    method: str = "Vertex AI",
    product_id: str = "default"
) -> Tuple[pd.DataFrame, str]:
    """
    äºˆæ¸¬æ–¹æ³•ã«å¿œã˜ãŸäºˆæ¸¬ã‚’å®Ÿè¡Œ
    
    Args:
        df: å£²ä¸Šãƒ‡ãƒ¼ã‚¿
        periods: äºˆæ¸¬æ—¥æ•°
        method: äºˆæ¸¬æ–¹æ³•
        product_id: å•†å“è­˜åˆ¥å­
    
    Returns:
        äºˆæ¸¬DataFrame, ä½¿ç”¨ã—ãŸäºˆæ¸¬æ–¹æ³•ã®èª¬æ˜
    """
    if method == "ğŸš€ Vertex AIï¼ˆæ¨å¥¨ï¼‰":
        predictions, used_vertex_ai, message = get_vertex_ai_prediction(df, periods, product_id, use_covariates=True)
        return predictions, message
    
    elif method == "ç§»å‹•å¹³å‡æ³•ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ï¼‰":
        return forecast_moving_average(df, periods), "ç§»å‹•å¹³å‡æ³•ï¼ˆçµ±è¨ˆãƒ¢ãƒ‡ãƒ«ï¼‰"
    
    elif method == "å­£ç¯€æ€§è€ƒæ…®ï¼ˆçµ±è¨ˆï¼‰":
        return forecast_with_seasonality_fallback(df, periods), "å­£ç¯€æ€§è€ƒæ…®ï¼ˆçµ±è¨ˆãƒ¢ãƒ‡ãƒ«ï¼‰"
    
    elif method == "æŒ‡æ•°å¹³æ»‘æ³•":
        return forecast_exponential_smoothing(df, periods), "æŒ‡æ•°å¹³æ»‘æ³•ï¼ˆçµ±è¨ˆãƒ¢ãƒ‡ãƒ«ï¼‰"
    
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯Vertex AI
        predictions, used_vertex_ai, message = get_vertex_ai_prediction(df, periods, product_id, use_covariates=True)
        return predictions, message


def forecast_moving_average(df: pd.DataFrame, periods: int, window: int = 30) -> pd.DataFrame:
    """ç§»å‹•å¹³å‡æ³•ã«ã‚ˆã‚‹äºˆæ¸¬"""
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'])
    df = df.sort_values('date')
    
    recent_data = df.tail(window)
    base_mean = recent_data['è²©å£²å•†å“æ•°'].mean()
    
    if pd.isna(base_mean) or base_mean <= 0:
        base_mean = 1.0
    
    last_date = df['date'].max()
    future_dates = pd.date_range(start=last_date + timedelta(days=1), periods=periods, freq='D')
    
    predictions = []
    for d in future_dates:
        pred = max(0.1, base_mean)
        predictions.append({
            'date': d,
            'predicted': round(pred)
        })
    
    return pd.DataFrame(predictions)


def forecast_exponential_smoothing(df: pd.DataFrame, periods: int, alpha: float = 0.3) -> pd.DataFrame:
    """æŒ‡æ•°å¹³æ»‘æ³•ã«ã‚ˆã‚‹äºˆæ¸¬"""
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'])
    df = df.sort_values('date')
    
    values = df['è²©å£²å•†å“æ•°'].values
    
    if len(values) == 0:
        return pd.DataFrame({'date': [], 'predicted': []})
    
    smoothed = [values[0]]
    for i in range(1, len(values)):
        smoothed_value = alpha * values[i] + (1 - alpha) * smoothed[-1]
        smoothed.append(smoothed_value)
    
    base_prediction = smoothed[-1] if smoothed else 1.0
    
    if pd.isna(base_prediction) or base_prediction <= 0:
        base_prediction = 1.0
    
    if len(smoothed) >= 7:
        recent_trend = (smoothed[-1] - smoothed[-7]) / 7
    else:
        recent_trend = 0
    
    last_date = df['date'].max()
    future_dates = pd.date_range(start=last_date + timedelta(days=1), periods=periods, freq='D')
    
    predictions = []
    for i, d in enumerate(future_dates):
        decay_factor = 0.95 ** i
        pred = base_prediction + (recent_trend * i * decay_factor)
        pred = max(0.1, pred)
        
        predictions.append({
            'date': d,
            'predicted': round(pred)
        })
    
    return pd.DataFrame(predictions)


def forecast_all_methods_with_vertex_ai(df: pd.DataFrame, periods: int, product_id: str = "default") -> Dict[str, Tuple[pd.DataFrame, str]]:
    """
    ã™ã¹ã¦ã®äºˆæ¸¬æ–¹æ³•ã§äºˆæ¸¬ã‚’å®Ÿè¡Œï¼ˆVertex AIå«ã‚€ï¼‰
    """
    results = {}
    
    # Vertex AIäºˆæ¸¬
    if VERTEX_AI_AVAILABLE:
        predictions, used_vertex_ai, message = get_vertex_ai_prediction(df, periods, product_id)
        results['Vertex AI'] = (predictions, message)
    
    # çµ±è¨ˆãƒ¢ãƒ‡ãƒ«äºˆæ¸¬
    results['å­£ç¯€æ€§è€ƒæ…®'] = (forecast_with_seasonality_fallback(df, periods), "å­£ç¯€æ€§è€ƒæ…®ï¼ˆçµ±è¨ˆãƒ¢ãƒ‡ãƒ«ï¼‰")
    results['ç§»å‹•å¹³å‡æ³•'] = (forecast_moving_average(df, periods), "ç§»å‹•å¹³å‡æ³•ï¼ˆçµ±è¨ˆãƒ¢ãƒ‡ãƒ«ï¼‰")
    results['æŒ‡æ•°å¹³æ»‘æ³•'] = (forecast_exponential_smoothing(df, periods), "æŒ‡æ•°å¹³æ»‘æ³•ï¼ˆçµ±è¨ˆãƒ¢ãƒ‡ãƒ«ï¼‰")
    
    return results


# =============================================================================
# äºˆæ¸¬æ–¹æ³•ã®å®šç¾©ï¼ˆv12æ›´æ–°ï¼‰
# =============================================================================

FORECAST_METHODS = {
    "ğŸš€ Vertex AIï¼ˆæ¨å¥¨ï¼‰": {
        "description": "Google Cloud AutoML Forecastingã«ã‚ˆã‚‹é«˜ç²¾åº¦äºˆæ¸¬ã€‚å¤©æ°—ãƒ»å…­æ›œãƒ»ã‚¤ãƒ™ãƒ³ãƒˆã‚’è€ƒæ…®ã€‚",
        "icon": "ğŸš€",
        "color": "#4285F4",
        "requires_vertex_ai": True
    },
    "å­£ç¯€æ€§è€ƒæ…®ï¼ˆçµ±è¨ˆï¼‰": {
        "description": "æœˆåˆ¥ãƒ»æ›œæ—¥åˆ¥ã®å‚¾å‘ã¨ç‰¹åˆ¥æœŸé–“ã‚’è€ƒæ…®ã—ãŸçµ±è¨ˆãƒ¢ãƒ‡ãƒ«ã€‚Vertex AIæœªè¨­å®šæ™‚ã®æ¨å¥¨ã€‚",
        "icon": "ğŸ“ˆ",
        "color": "#4CAF50",
        "requires_vertex_ai": False
    },
    "ç§»å‹•å¹³å‡æ³•ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ï¼‰": {
        "description": "éå»30æ—¥é–“ã®å¹³å‡å€¤ã‚’ãƒ™ãƒ¼ã‚¹ã«äºˆæ¸¬ã€‚å®‰å®šã—ãŸå•†å“å‘ã‘ã€‚",
        "icon": "ğŸ“Š",
        "color": "#1E88E5",
        "requires_vertex_ai": False
    },
    "æŒ‡æ•°å¹³æ»‘æ³•": {
        "description": "ç›´è¿‘ã®ãƒ‡ãƒ¼ã‚¿ã‚’é‡è¦–ã—ãŸäºˆæ¸¬ã€‚ãƒˆãƒ¬ãƒ³ãƒ‰ã®å¤‰åŒ–ã«æ•æ„Ÿã€‚",
        "icon": "ğŸ“‰",
        "color": "#FF9800",
        "requires_vertex_ai": False
    },
    "ğŸ”„ ã™ã¹ã¦ã®æ–¹æ³•ã§æ¯”è¼ƒ": {
        "description": "Vertex AIã¨çµ±è¨ˆãƒ¢ãƒ‡ãƒ«ã™ã¹ã¦ã§äºˆæ¸¬ã—ã€çµæœã‚’æ¯”è¼ƒã—ã¾ã™ã€‚",
        "icon": "ğŸ”„",
        "color": "#9C27B0",
        "requires_vertex_ai": False
    }
}

# ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥ã®ç‰¹æ€§ï¼ˆæ–°è¦æˆä¸å“äºˆæ¸¬ç”¨ï¼‰
CATEGORY_CHARACTERISTICS = {
    "ãŠå®ˆã‚Š": {"seasonality": "high", "base_daily": 3.0, "price_range": (500, 1500)},
    "å¾¡æœ±å°": {"seasonality": "medium", "base_daily": 5.0, "price_range": (300, 500)},
    "å¾¡æœ±å°å¸³": {"seasonality": "low", "base_daily": 1.0, "price_range": (1500, 3000)},
    "ãŠã¿ãã˜": {"seasonality": "high", "base_daily": 10.0, "price_range": (100, 300)},
    "çµµé¦¬": {"seasonality": "high", "base_daily": 2.0, "price_range": (500, 1000)},
    "ãŠæœ­": {"seasonality": "high", "base_daily": 1.5, "price_range": (500, 3000)},
    "ç¸èµ·ç‰©": {"seasonality": "medium", "base_daily": 1.0, "price_range": (500, 5000)},
    "ãã®ä»–": {"seasonality": "low", "base_daily": 0.5, "price_range": (500, 2000)},
}


# =============================================================================
# ãƒšãƒ¼ã‚¸è¨­å®š
# =============================================================================

st.set_page_config(
    page_title="Airãƒ¬ã‚¸ å£²ä¸Šåˆ†æï¼ˆVertex AIç‰ˆï¼‰",
    page_icon="â›©ï¸",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    /* ============================================
       åŸºæœ¬ã‚¹ã‚¿ã‚¤ãƒ«
       ============================================ */
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1E88E5;
        margin-bottom: 1rem;
    }
    .section-header {
        font-size: 1.5rem;
        font-weight: bold;
        color: #333;
        border-bottom: 2px solid #1E88E5;
        padding-bottom: 0.5rem;
        margin: 1.5rem 0 1rem 0;
    }
    .accuracy-good { color: #4CAF50; font-weight: bold; }
    .accuracy-medium { color: #FF9800; font-weight: bold; }
    .accuracy-poor { color: #F44336; font-weight: bold; }
    .new-product-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        border-radius: 15px;
        padding: 20px;
        color: white;
        margin: 10px 0;
    }
    .analysis-card {
        background: linear-gradient(135deg, #f5f7fa 0%, #e4e8eb 100%);
        border-radius: 10px;
        padding: 15px;
        margin: 10px 0;
        border-left: 4px solid #1E88E5;
    }
    .method-card {
        background: #f8f9fa;
        border-radius: 8px;
        padding: 12px;
        margin: 8px 0;
        border-left: 3px solid;
    }
    .method-vertex-ai { border-left-color: #4285F4; background: #e8f0fe; }
    .method-seasonality { border-left-color: #4CAF50; }
    .method-moving-avg { border-left-color: #1E88E5; }
    .method-exponential { border-left-color: #FF9800; }
    .vertex-ai-status {
        padding: 10px 15px;
        border-radius: 8px;
        margin: 10px 0;
    }
    .vertex-ai-available {
        background: #e8f5e9;
        border: 1px solid #4CAF50;
        color: #2e7d32;
    }
    .vertex-ai-unavailable {
        background: #fff3e0;
        border: 1px solid #FF9800;
        color: #e65100;
    }
    .individual-product-box {
        background: #f0f8ff;
        border-radius: 10px;
        padding: 15px;
        margin: 10px 0;
        border: 1px solid #1E88E5;
    }
    
    /* ============================================
       ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®šï¼ˆæ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«é˜²æ­¢ï¼‰
       ============================================ */
    .main .block-container {
        max-width: 100%;
        padding-left: 1rem;
        padding-right: 1rem;
        overflow-x: hidden;
    }
    
    /* ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®æ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯¾å¿œ */
    [data-testid="stDataFrame"] {
        width: 100%;
    }
    [data-testid="stDataFrame"] > div {
        overflow-x: auto;
        -webkit-overflow-scrolling: touch;
    }
    
    /* ============================================
       ã‚¹ãƒãƒ›å¯¾å¿œï¼ˆ768pxä»¥ä¸‹ï¼‰
       ============================================ */
    @media screen and (max-width: 768px) {
        /* ãƒ˜ãƒƒãƒ€ãƒ¼ */
        .main-header {
            font-size: 1.4rem;
            text-align: center;
        }
        .section-header {
            font-size: 1.1rem;
        }
        
        /* ã‚«ãƒ©ãƒ ã‚’ç¸¦ä¸¦ã³ã« */
        [data-testid="column"] {
            width: 100% !important;
            flex: 1 1 100% !important;
            min-width: 100% !important;
        }
        
        /* ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆæ•°å€¤è¡¨ç¤ºï¼‰ã‚’ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã« */
        [data-testid="metric-container"] {
            padding: 8px 5px;
            background: #f8f9fa;
            border-radius: 8px;
            margin: 4px 0;
        }
        [data-testid="stMetricLabel"] {
            font-size: 0.75rem !important;
        }
        [data-testid="stMetricValue"] {
            font-size: 1.1rem !important;
        }
        
        /* ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’2åˆ—è¡¨ç¤ºã« */
        [data-testid="stHorizontalBlock"] {
            flex-wrap: wrap;
            gap: 8px;
        }
        [data-testid="stHorizontalBlock"] > [data-testid="column"] {
            flex: 1 1 45% !important;
            min-width: 45% !important;
            max-width: 48% !important;
        }
        
        /* ã‚¿ãƒ– */
        .stTabs [data-baseweb="tab-list"] {
            gap: 0;
            overflow-x: auto;
            -webkit-overflow-scrolling: touch;
            scrollbar-width: none;
        }
        .stTabs [data-baseweb="tab-list"]::-webkit-scrollbar {
            display: none;
        }
        .stTabs [data-baseweb="tab"] {
            font-size: 0.75rem;
            padding: 8px 10px;
            white-space: nowrap;
        }
        
        /* ãƒœã‚¿ãƒ³ */
        .stButton > button {
            width: 100%;
            padding: 12px 16px;
            font-size: 0.9rem;
        }
        
        /* å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ */
        .stSelectbox, .stNumberInput, .stTextInput {
            margin-bottom: 8px;
        }
        .stSelectbox label, .stNumberInput label, .stTextInput label {
            font-size: 0.8rem;
        }
        
        /* ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã‚’ç¸¦ä¸¦ã³ã« */
        [data-testid="stRadio"] > div {
            flex-direction: column;
            gap: 8px;
        }
        [data-testid="stRadio"] label {
            font-size: 0.85rem;
        }
        
        /* ã‚«ãƒ¼ãƒ‰ */
        .analysis-card, .method-card {
            padding: 10px;
            font-size: 0.85rem;
        }
        .new-product-card {
            padding: 15px;
        }
        .new-product-card h2 {
            font-size: 1.1rem;
        }
        .new-product-card p {
            font-size: 0.85rem;
        }
        
        /* ã‚°ãƒ©ãƒ• */
        .js-plotly-plot {
            margin: 0 -10px;
        }
        .js-plotly-plot .plotly .modebar {
            display: none !important;
        }
        
        /* Expander */
        .streamlit-expanderHeader {
            font-size: 0.9rem;
            padding: 10px;
        }
        
        /* Info/Warning/Errorãƒœãƒƒã‚¯ã‚¹ */
        [data-testid="stAlert"] {
            padding: 10px;
            font-size: 0.85rem;
        }
        
        /* Divider */
        hr {
            margin: 15px 0;
        }
        
        /* é¸æŠä¸­ã®æˆä¸å“ */
        .product-tag {
            font-size: 0.8rem;
            padding: 4px 10px;
        }
    }
    
    /* ============================================
       ã‚¿ãƒ–ãƒ¬ãƒƒãƒˆå¯¾å¿œï¼ˆ769pxã€œ1024pxï¼‰
       ============================================ */
    @media screen and (min-width: 769px) and (max-width: 1024px) {
        .main-header {
            font-size: 2rem;
        }
        [data-testid="column"] {
            min-width: 45% !important;
        }
    }
    
    /* ============================================
       é¸æŠä¸­ã®æˆä¸å“ã®å‰Šé™¤ãƒœã‚¿ãƒ³
       ============================================ */
    .product-tag {
        display: inline-flex;
        align-items: center;
        background: #e3f2fd;
        border-radius: 20px;
        padding: 5px 12px;
        margin: 3px;
        font-size: 0.9rem;
    }
    .product-tag-remove {
        margin-left: 8px;
        cursor: pointer;
        color: #666;
        font-weight: bold;
    }
    .product-tag-remove:hover {
        color: #f44336;
    }
    
    /* ============================================
       ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
       ============================================ */
    /* ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è»½é‡åŒ– */
    * {
        -webkit-tap-highlight-color: transparent;
    }
    .stApp {
        -webkit-font-smoothing: antialiased;
    }
</style>
""", unsafe_allow_html=True)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'data_loader' not in st.session_state:
    st.session_state.data_loader = None
if 'normalizer' not in st.session_state:
    st.session_state.normalizer = None
if 'selected_products' not in st.session_state:
    st.session_state.selected_products = []
if 'categories' not in st.session_state:
    st.session_state.categories = {}
if 'sales_data' not in st.session_state:
    st.session_state.sales_data = None
if 'forecast_data' not in st.session_state:
    st.session_state.forecast_data = None
if 'forecast_total' not in st.session_state:
    st.session_state.forecast_total = 0
if 'forecast_results' not in st.session_state:
    st.session_state.forecast_results = {}
if 'analysis_mode' not in st.session_state:
    st.session_state.analysis_mode = "åˆç®—"
if 'individual_sales_data' not in st.session_state:
    st.session_state.individual_sales_data = {}
if 'last_forecast_method' not in st.session_state:
    st.session_state.last_forecast_method = ""
if 'product_to_remove' not in st.session_state:
    st.session_state.product_to_remove = None
if 'clear_all_flag' not in st.session_state:
    st.session_state.clear_all_flag = False
if 'individual_forecast_results' not in st.session_state:
    st.session_state.individual_forecast_results = []
if 'pending_delete_product' not in st.session_state:
    st.session_state.pending_delete_product = None
# ã‚°ãƒ«ãƒ¼ãƒ—ç®¡ç†ç”¨: {å•†å“å: ã‚°ãƒ«ãƒ¼ãƒ—ç•ªå·} ã®è¾æ›¸
if 'product_groups' not in st.session_state:
    st.session_state.product_groups = {}
# å€‹åˆ¥ãƒ¢ãƒ¼ãƒ‰ã§ã®å…¨äºˆæ¸¬æ–¹æ³•ã®çµæœï¼ˆãƒãƒˆãƒªãƒƒã‚¯ã‚¹å½¢å¼ï¼‰
if 'individual_all_methods_results' not in st.session_state:
    st.session_state.individual_all_methods_results = {}


# =============================================================================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# =============================================================================

def round_up_to_50(value: int) -> int:
    """50ã®å€æ•°ã«åˆ‡ã‚Šä¸Šã’"""
    if value <= 0:
        return 0
    return ((value + 49) // 50) * 50


def match_mail_product_to_airregi(mail_product: str, airregi_names: list) -> Optional[str]:
    """
    éƒµé€ã®å•†å“åã‚’Airãƒ¬ã‚¸ã®å•†å“åã«ãƒãƒƒãƒãƒ³ã‚°ã™ã‚‹å…±é€šé–¢æ•°
    
    Args:
        mail_product: éƒµé€ãƒ‡ãƒ¼ã‚¿ã®å•†å“å
        airregi_names: Airãƒ¬ã‚¸ã®å•†å“åãƒªã‚¹ãƒˆï¼ˆã‚ªãƒªã‚¸ãƒŠãƒ«åï¼‰
    
    Returns:
        ãƒãƒƒãƒã—ãŸAirãƒ¬ã‚¸ã®å•†å“åã€ãƒãƒƒãƒã—ãªã„å ´åˆã¯None
    """
    mail_product = str(mail_product).strip()
    
    for airregi_name in airregi_names:
        airregi_name_str = str(airregi_name).strip()
        
        # 1. å®Œå…¨ä¸€è‡´
        if mail_product == airregi_name_str:
            return airregi_name_str
        
        # 2. éƒµé€ã®å•†å“åãŒAirãƒ¬ã‚¸ã®å•†å“åã«å«ã¾ã‚Œã¦ã„ã‚‹
        # ä¾‹: ã€Œã†ã¾ãã„ãå®ˆã€ãŒã€Œã€åˆå¹´ã‚¢ã‚¯ãƒªãƒ«ã€‘ç·‘ã†ã¾ãã„ãå®ˆã€ã«å«ã¾ã‚Œã‚‹
        if mail_product in airregi_name_str:
            return airregi_name_str
        
        # 3. Airãƒ¬ã‚¸ã®å•†å“åãŒéƒµé€ã®å•†å“åã«å«ã¾ã‚Œã¦ã„ã‚‹ï¼ˆé€†ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
        if airregi_name_str in mail_product:
            return airregi_name_str
        
        # 4. ã€ã€‘ï¼ˆå¤§æ‹¬å¼§ï¼‰ã‚’é™¤å»ã—ã¦ãƒãƒƒãƒãƒ³ã‚°
        # ä¾‹: ã€Œã€åˆå¹´ã‚¢ã‚¯ãƒªãƒ«ã€‘ç·‘ã†ã¾ãã„ãå®ˆã€â†’ã€Œç·‘ã†ã¾ãã„ãå®ˆã€
        clean_name = re.sub(r'ã€[^ã€‘]*ã€‘', '', airregi_name_str).strip()
        if clean_name:
            if mail_product in clean_name or clean_name in mail_product:
                return airregi_name_str
            if mail_product == clean_name:
                return airregi_name_str
        
        # 5. è‰²åã‚’é™¤å»ã—ã¦ãƒãƒƒãƒãƒ³ã‚°
        # ä¾‹: ã€Œç·‘ã†ã¾ãã„ãå®ˆã€â†’ã€Œã†ã¾ãã„ãå®ˆã€
        colors = ['ç·‘', 'ç™½', 'èµ¤', 'é’', 'é»„', 'é‡‘', 'éŠ€', 'ãƒ”ãƒ³ã‚¯', 'ç´«', 'é»’', 'èŒ¶', 'æ°´è‰²', 'ã‚ªãƒ¬ãƒ³ã‚¸']
        clean_name_no_color = clean_name
        for color in colors:
            if clean_name_no_color.startswith(color):
                clean_name_no_color = clean_name_no_color[len(color):]
                break
        
        if clean_name_no_color and clean_name_no_color != clean_name:
            if mail_product == clean_name_no_color:
                return airregi_name_str
            if mail_product in clean_name_no_color or clean_name_no_color in mail_product:
                return airregi_name_str
        
        # 6. ()ï¼ˆä¸¸æ‹¬å¼§ï¼‰ã‚‚é™¤å»ã—ã¦ãƒãƒƒãƒãƒ³ã‚°
        # ä¾‹: ã€Œé‡‘é‹å®ˆï¼ˆå¤§ï¼‰ã€â†’ã€Œé‡‘é‹å®ˆã€
        clean_name_no_paren = re.sub(r'[ï¼ˆ(][^ï¼‰)]*[ï¼‰)]', '', clean_name).strip()
        if clean_name_no_paren and clean_name_no_paren != clean_name:
            if mail_product == clean_name_no_paren:
                return airregi_name_str
            if mail_product in clean_name_no_paren or clean_name_no_paren in mail_product:
                return airregi_name_str
        
        # 7. ã€Œå®ˆã€ã€Œå®ˆã‚Šã€ã®è¡¨è¨˜ã‚†ã‚Œã«å¯¾å¿œ
        # ä¾‹: ã€Œã†ã¾ãã„ãå®ˆã€ã¨ã€Œã†ã¾ãã„ãå®ˆã‚Šã€
        mail_normalized = mail_product.replace('å®ˆã‚Š', 'å®ˆ').replace('ãŠå®ˆã‚Š', 'ãŠå®ˆ')
        airregi_normalized = clean_name.replace('å®ˆã‚Š', 'å®ˆ').replace('ãŠå®ˆã‚Š', 'ãŠå®ˆ')
        if mail_normalized == airregi_normalized:
            return airregi_name_str
        if mail_normalized in airregi_normalized or airregi_normalized in mail_normalized:
            return airregi_name_str
    
    return None


def get_available_forecast_methods() -> List[str]:
    """åˆ©ç”¨å¯èƒ½ãªäºˆæ¸¬æ–¹æ³•ã®ãƒªã‚¹ãƒˆã‚’å–å¾—"""
    methods = []
    for method_name, method_info in FORECAST_METHODS.items():
        if method_info.get('requires_vertex_ai', False) and not VERTEX_AI_AVAILABLE:
            continue
        methods.append(method_name)
    return methods


def get_mobile_chart_config() -> dict:
    """ã‚¹ãƒãƒ›æœ€é©åŒ–ã•ã‚ŒãŸPlotlyãƒãƒ£ãƒ¼ãƒˆè¨­å®šã‚’å–å¾—"""
    return {
        'displayModeBar': False,  # ãƒ„ãƒ¼ãƒ«ãƒãƒ¼éè¡¨ç¤º
        'staticPlot': False,      # æ“ä½œã¯å¯èƒ½
        'responsive': True,       # ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–
        'scrollZoom': False,      # ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã‚ºãƒ¼ãƒ ç„¡åŠ¹
    }


def get_mobile_chart_layout(title: str = '', height: int = 300) -> dict:
    """ã‚¹ãƒãƒ›æœ€é©åŒ–ã•ã‚ŒãŸPlotlyãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­å®šã‚’å–å¾—"""
    return {
        'title': dict(text=title, font=dict(size=14)),
        'height': height,
        'margin': dict(l=40, r=20, t=40, b=40),
        'legend': dict(
            orientation='h',
            yanchor='bottom',
            y=1.02,
            xanchor='center',
            x=0.5,
            font=dict(size=10)
        ),
        'xaxis': dict(
            tickfont=dict(size=10),
            title=dict(font=dict(size=11))
        ),
        'yaxis': dict(
            tickfont=dict(size=10),
            title=dict(font=dict(size=11))
        ),
        'dragmode': False,
        'hovermode': 'x unified',
    }


# =============================================================================
# ãƒ‡ãƒ¼ã‚¿åˆæœŸåŒ–
# =============================================================================

def init_data():
    """ãƒ‡ãƒ¼ã‚¿ã‚’åˆæœŸåŒ–"""
    if st.session_state.data_loader is None:
        try:
            st.session_state.data_loader = SheetsDataLoader()
        except Exception as e:
            st.error(f"ãƒ‡ãƒ¼ã‚¿æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    if st.session_state.normalizer is None:
        try:
            df_items = st.session_state.data_loader.load_item_sales()
            st.session_state.normalizer = ProductNormalizer()
            st.session_state.normalizer.build_master(df_items, "å•†å“å")
            build_categories()
        except Exception as e:
            st.error(f"æˆä¸å“ãƒã‚¹ã‚¿æ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {e}")
    
    return True


def build_categories():
    """ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’Dåˆ—ã‹ã‚‰å–å¾—"""
    if st.session_state.data_loader is None:
        return
    
    df_items = st.session_state.data_loader.load_item_sales()
    
    if df_items.empty:
        return
    
    categories = defaultdict(list)
    
    category_col = None
    for col in df_items.columns:
        if 'ã‚«ãƒ†ã‚´ãƒª' in col or col == 'ã‚«ãƒ†ã‚´ãƒªãƒ¼' or col == 'category':
            category_col = col
            break
    
    if category_col is None and len(df_items.columns) >= 4:
        category_col = df_items.columns[3]
    
    if category_col is None:
        return
    
    product_col = None
    for col in df_items.columns:
        if 'å•†å“å' in col or col == 'å•†å“' or col == 'product':
            product_col = col
            break
    
    if product_col is None and len(df_items.columns) >= 3:
        product_col = df_items.columns[2]
    
    if product_col is None:
        return
    
    for _, row in df_items[[product_col, category_col]].drop_duplicates().iterrows():
        product_name = row[product_col]
        category = row[category_col]
        
        if pd.isna(category) or str(category).strip() == '':
            category = 'ãã®ä»–'
        
        if st.session_state.normalizer:
            normalized = st.session_state.normalizer.normalize(product_name)
            if normalized and normalized not in categories[category]:
                categories[category].append(normalized)
    
    st.session_state.categories = dict(categories)


# =============================================================================
# ãƒ˜ãƒƒãƒ€ãƒ¼
# =============================================================================

def render_header():
    """ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æç”»"""
    col1, col2 = st.columns([4, 1])
    
    with col1:
        st.markdown('<p class="main-header">â›©ï¸ æˆä¸å“ å£²ä¸Šåˆ†æãƒ»éœ€è¦äºˆæ¸¬</p>', unsafe_allow_html=True)
    
    with col2:
        if st.button("ğŸ”„ ãƒ‡ãƒ¼ã‚¿æ›´æ–°"):
            st.cache_data.clear()
            st.session_state.data_loader = None
            st.session_state.selected_products = []
            st.session_state.sales_data = None
            st.session_state.forecast_data = None
            st.session_state.forecast_results = {}
            st.session_state.individual_sales_data = {}
            st.rerun()
    
    # Vertex AIã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
    if VERTEX_AI_AVAILABLE:
        st.markdown(f"""
        <div class="vertex-ai-status vertex-ai-available">
            âœ… <strong>Vertex AI AutoML Forecasting:</strong> æ¥ç¶šæ¸ˆã¿
            ï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {VERTEX_AI_CONFIG['project_id']}, ãƒªãƒ¼ã‚¸ãƒ§ãƒ³: {VERTEX_AI_CONFIG['location']}ï¼‰
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown("""
        <div class="vertex-ai-status vertex-ai-unavailable">
            âš ï¸ <strong>Vertex AI:</strong> æœªè¨­å®šï¼ˆçµ±è¨ˆãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ã—ã¾ã™ï¼‰
        </div>
        """, unsafe_allow_html=True)
    
    if st.session_state.data_loader:
        min_date, max_date = st.session_state.data_loader.get_date_range()
        if min_date and max_date:
            st.caption(f"ğŸ“… ãƒ‡ãƒ¼ã‚¿æœŸé–“: {min_date.strftime('%Yå¹´%mæœˆ%dæ—¥')} ã€œ {max_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}")


# =============================================================================
# ãƒ¡ã‚¤ãƒ³ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
# =============================================================================

def render_main_tabs():
    """ãƒ¡ã‚¤ãƒ³ã‚¿ãƒ–ã‚’æç”»"""
    tab_labels = [
        "ğŸ“Š æ—¢å­˜æˆä¸å“ã®åˆ†æãƒ»äºˆæ¸¬",
        "âœ¨ æ–°è¦æˆä¸å“ã®éœ€è¦äºˆæ¸¬",
        "âš™ï¸ Vertex AIè¨­å®š",
    ]
    
    if ADVANCED_ANALYSIS_AVAILABLE:
        tab_labels.append("ğŸ”¬ é«˜åº¦ãªåˆ†æ")
    
    tab_labels.append("ğŸ“ˆ äºˆæ¸¬ç²¾åº¦ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
    
    tabs = st.tabs(tab_labels)
    
    tab_idx = 0
    
    with tabs[tab_idx]:
        render_existing_product_analysis()
    tab_idx += 1
    
    with tabs[tab_idx]:
        render_new_product_forecast()
    tab_idx += 1
    
    with tabs[tab_idx]:
        render_vertex_ai_settings()
    tab_idx += 1
    
    if ADVANCED_ANALYSIS_AVAILABLE:
        with tabs[tab_idx]:
            render_advanced_analysis()
        tab_idx += 1
    
    with tabs[tab_idx]:
        render_accuracy_dashboard()


# =============================================================================
# Vertex AIè¨­å®šã‚¿ãƒ–
# =============================================================================

def render_vertex_ai_settings():
    """Vertex AIè¨­å®šã‚¿ãƒ–"""
    st.markdown('<p class="section-header">âš™ï¸ Vertex AI AutoML Forecasting è¨­å®š</p>', unsafe_allow_html=True)
    
    # ç¾åœ¨ã®è¨­å®šçŠ¶æ³
    st.write("### ğŸ“‹ ç¾åœ¨ã®è¨­å®šçŠ¶æ³")
    
    config_status = {
        'ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆID': VERTEX_AI_CONFIG['project_id'] or 'æœªè¨­å®š',
        'ãƒªãƒ¼ã‚¸ãƒ§ãƒ³': VERTEX_AI_CONFIG['location'] or 'æœªè¨­å®š',
        'ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆID': VERTEX_AI_CONFIG['endpoint_id'] or 'æœªè¨­å®š',
        'ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«': VERTEX_AI_CONFIG['service_account_file'],
        'ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨': 'âœ… ã‚ã‚Š' if os.path.exists(VERTEX_AI_CONFIG['service_account_file']) else 'âŒ ãªã—',
        'Vertex AIåˆ©ç”¨å¯èƒ½': 'âœ… ã¯ã„' if VERTEX_AI_AVAILABLE else 'âŒ ã„ã„ãˆ',
    }
    
    for key, value in config_status.items():
        st.write(f"- **{key}**: {value}")
    
    st.divider()
    
    # è¨­å®šæ–¹æ³•ã®èª¬æ˜
    st.write("### ğŸ”§ è¨­å®šæ–¹æ³•")
    
    st.markdown("""
    **æ–¹æ³•1: ç’°å¢ƒå¤‰æ•°ã§è¨­å®š**
    ```bash
    export VERTEX_AI_PROJECT_ID="your-project-id"
    export VERTEX_AI_LOCATION="asia-northeast1"
    export VERTEX_AI_ENDPOINT_ID="your-endpoint-id"
    export VERTEX_AI_SERVICE_ACCOUNT_FILE="path/to/service_account.json"
    ```
    
    **æ–¹æ³•2: config.pyã§è¨­å®š**
    ```python
    # config.py
    VERTEX_AI_PROJECT_ID = "your-project-id"
    VERTEX_AI_LOCATION = "asia-northeast1"
    VERTEX_AI_ENDPOINT_ID = "your-endpoint-id"
    VERTEX_AI_SERVICE_ACCOUNT_FILE = "service_account.json"
    ```
    """)
    
    st.divider()
    
    # AutoML Forecastingãƒ¢ãƒ‡ãƒ«ã®ä½œæˆæ‰‹é †
    st.write("### ğŸ“š AutoML Forecastingãƒ¢ãƒ‡ãƒ«ã®ä½œæˆæ‰‹é †")
    
    with st.expander("1ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™", expanded=False):
        st.markdown("""
        Vertex AI AutoML Forecastingã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿å½¢å¼ï¼š
        
        | ã‚«ãƒ©ãƒ  | èª¬æ˜ | ä¾‹ |
        |--------|------|-----|
        | timestamp | æ™‚é–“åˆ—ï¼ˆISOå½¢å¼ï¼‰ | 2025-01-01T00:00:00Z |
        | target | äºˆæ¸¬å¯¾è±¡ï¼ˆè²©å£²æ•°ï¼‰ | 15 |
        | time_series_identifier | ç³»åˆ—è­˜åˆ¥å­ï¼ˆå•†å“IDç­‰ï¼‰ | product_001 |
        | weekday | æ›œæ—¥ï¼ˆå…±å¤‰é‡ï¼‰ | 0-6 |
        | is_holiday | ä¼‘æ—¥ãƒ•ãƒ©ã‚°ï¼ˆå…±å¤‰é‡ï¼‰ | 0 or 1 |
        | weather | å¤©æ°—ï¼ˆå…±å¤‰é‡ï¼‰ | sunny, rainy, etc. |
        """)
    
    with st.expander("2ï¸âƒ£ ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°", expanded=False):
        st.markdown("""
        1. [Google Cloud Console](https://console.cloud.google.com/vertex-ai) ã«ã‚¢ã‚¯ã‚»ã‚¹
        2. ã€Œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€â†’ã€Œä½œæˆã€â†’ã€Œæ™‚ç³»åˆ—äºˆæ¸¬ã€ã‚’é¸æŠ
        3. CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ã‚«ãƒ©ãƒ ã‚’è¨­å®š
        4. ã€Œãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã€â†’ã€ŒAutoMLã€ã‚’é¸æŠ
        5. ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†ã‚’å¾…ã¤ï¼ˆæ•°æ™‚é–“ã€œï¼‰
        """)
    
    with st.expander("3ï¸âƒ£ ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ãƒ‡ãƒ—ãƒ­ã‚¤", expanded=False):
        st.markdown("""
        1. ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ
        2. ã€Œãƒ‡ãƒ—ãƒ­ã‚¤ã¨ãƒ†ã‚¹ãƒˆã€â†’ã€Œã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«ãƒ‡ãƒ—ãƒ­ã‚¤ã€
        3. ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆåã‚’è¨­å®šã—ã¦ãƒ‡ãƒ—ãƒ­ã‚¤
        4. ãƒ‡ãƒ—ãƒ­ã‚¤å®Œäº†å¾Œã€ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆIDã‚’ã‚³ãƒ”ãƒ¼
        """)
    
    with st.expander("4ï¸âƒ£ ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®è¨­å®š", expanded=False):
        st.markdown("""
        1. ã€ŒIAMã¨ç®¡ç†ã€â†’ã€Œã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã€
        2. ã€Œã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ä½œæˆã€
        3. ä»¥ä¸‹ã®ãƒ­ãƒ¼ãƒ«ã‚’ä»˜ä¸ï¼š
           - Vertex AI ãƒ¦ãƒ¼ã‚¶ãƒ¼
           - Vertex AI äºˆæ¸¬ãƒ¦ãƒ¼ã‚¶ãƒ¼
        4. ã€Œéµã‚’ä½œæˆã€â†’ JSONå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        5. ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚©ãƒ«ãƒ€ã«é…ç½®
        """)
    
    # æ¥ç¶šãƒ†ã‚¹ãƒˆ
    st.divider()
    st.write("### ğŸ§ª æ¥ç¶šãƒ†ã‚¹ãƒˆ")
    
    if st.button("ğŸ” Vertex AIæ¥ç¶šã‚’ãƒ†ã‚¹ãƒˆ", type="primary"):
        if not VERTEX_AI_AVAILABLE:
            st.error("Vertex AIãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ä¸Šè¨˜ã®è¨­å®šã‚’å®Œäº†ã—ã¦ãã ã•ã„ã€‚")
        else:
            with st.spinner("æ¥ç¶šãƒ†ã‚¹ãƒˆä¸­..."):
                try:
                    forecaster = get_vertex_ai_forecaster()
                    # ç°¡å˜ãªãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§æ¥ç¶šç¢ºèª
                    test_df = pd.DataFrame({
                        'date': pd.date_range(start='2025-01-01', periods=30, freq='D'),
                        'è²©å£²å•†å“æ•°': np.random.randint(1, 10, 30)
                    })
                    predictions, metadata = forecaster.predict(test_df, 7, "test_product")
                    st.success(f"âœ… æ¥ç¶šæˆåŠŸï¼ãƒ¢ãƒ‡ãƒ«ID: {metadata.get('deployed_model_id', 'N/A')}")
                    st.write("ãƒ†ã‚¹ãƒˆäºˆæ¸¬çµæœ:")
                    st.dataframe(predictions.head())
                except Exception as e:
                    st.error(f"âŒ æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")


# =============================================================================
# æ—¢å­˜æˆä¸å“ã®åˆ†æ
# =============================================================================

def render_existing_product_analysis():
    """æ—¢å­˜æˆä¸å“ã®åˆ†æãƒ»äºˆæ¸¬"""
    render_product_selection()
    start_date, end_date = render_period_selection()
    
    if len(st.session_state.selected_products) > 1:
        render_analysis_mode_selection()
    
    if st.session_state.analysis_mode == "å€‹åˆ¥":
        render_individual_analysis(start_date, end_date)
    else:
        sales_data = render_sales_analysis(start_date, end_date)
        render_forecast_section(sales_data)
        render_delivery_section()


def render_analysis_mode_selection():
    """åˆç®—/å€‹åˆ¥ãƒ¢ãƒ¼ãƒ‰ã®é¸æŠ"""
    st.markdown('<p class="section-header">ğŸ“Š åˆ†æãƒ¢ãƒ¼ãƒ‰</p>', unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        mode = st.radio(
            "è¤‡æ•°æˆä¸å“ã®åˆ†ææ–¹æ³•",
            ["åˆç®—", "å€‹åˆ¥"],
            index=0 if st.session_state.analysis_mode == "åˆç®—" else 1,
            horizontal=True,
            help="åˆç®—ï¼šé¸æŠã—ãŸæˆä¸å“ã®åˆè¨ˆã‚’åˆ†æ\nå€‹åˆ¥ï¼šæˆä¸å“ã”ã¨ã«åˆ¥ã€…ã«åˆ†æ"
        )
        st.session_state.analysis_mode = mode
    
    with col2:
        if mode == "åˆç®—":
            st.info(f"ğŸ“Š {len(st.session_state.selected_products)}ä»¶ã®æˆä¸å“ã‚’**åˆè¨ˆ**ã—ã¦åˆ†æã—ã¾ã™")
        else:
            st.info(f"ğŸ“Š {len(st.session_state.selected_products)}ä»¶ã®æˆä¸å“ã‚’**å€‹åˆ¥**ã«åˆ†æã—ã¾ã™")


def render_product_selection():
    """æˆä¸å“é¸æŠã‚»ã‚¯ã‚·ãƒ§ãƒ³"""
    st.markdown('<p class="section-header">â‘  æˆä¸å“ã‚’é¸ã¶</p>', unsafe_allow_html=True)
    
    tab1, tab2 = st.tabs(["ğŸ” åå‰ã§æ¤œç´¢", "ğŸ“ ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‹ã‚‰é¸ã¶"])
    
    with tab1:
        render_search_tab()
    
    with tab2:
        render_category_tab()
    
    render_selected_products()


def render_search_tab():
    """åå‰æ¤œç´¢ã‚¿ãƒ–ï¼ˆéƒµé€ã‚·ãƒ¼ãƒˆã®å•†å“åã‚‚æ¤œç´¢å¯¾è±¡ã«å«ã‚€ï¼‰"""
    search_query = st.text_input(
        "æˆä¸å“åã‚’å…¥åŠ›",
        placeholder="ä¾‹: é‡‘é‹ã€ãŠå®ˆã‚Šã€å¾¡æœ±å°å¸³...",
        key="search_input"
    )
    
    if search_query and st.session_state.normalizer:
        # Airãƒ¬ã‚¸ã®æ¤œç´¢çµæœ
        airregi_results = st.session_state.normalizer.search(search_query, limit=20)
        
        # éƒµé€ã‚·ãƒ¼ãƒˆã‹ã‚‰ã‚‚æ¤œç´¢
        mail_results = []
        try:
            mail_order_enabled = hasattr(config, 'MAIL_ORDER_SPREADSHEET_ID') and config.MAIL_ORDER_SPREADSHEET_ID
            if mail_order_enabled:
                df_mail = st.session_state.data_loader.get_mail_order_summary()
                if not df_mail.empty and 'å•†å“å' in df_mail.columns:
                    # éƒµé€ã‚·ãƒ¼ãƒˆã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå•†å“åã‚’å–å¾—
                    mail_products = df_mail['å•†å“å'].unique()
                    for mp in mail_products:
                        mp_str = str(mp).strip()
                        if search_query.lower() in mp_str.lower():
                            # æ—¢ã«Airãƒ¬ã‚¸çµæœã«å«ã¾ã‚Œã¦ã„ãªã„ã‹ç¢ºèª
                            already_in_airregi = any(
                                mp_str in r.get('normalized_name', '') or 
                                r.get('normalized_name', '') in mp_str
                                for r in airregi_results
                            )
                            if not already_in_airregi:
                                mail_results.append({
                                    'name': mp_str,
                                    'source': 'mail'
                                })
        except Exception as e:
            pass  # éƒµé€ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        
        total_results = len(airregi_results) + len(mail_results)
        
        if total_results > 0:
            st.write(f"**{total_results}ä»¶** è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
            
            # Airãƒ¬ã‚¸ã®çµæœ
            if airregi_results:
                st.write("**ğŸª Airãƒ¬ã‚¸ã®å•†å“ï¼š**")
                cols = st.columns(3)
                for i, result in enumerate(airregi_results):
                    name = result['normalized_name']
                    bracket = result.get('bracket_content', '')
                    
                    with cols[i % 3]:
                        is_selected = name in st.session_state.selected_products
                        label = f"{name}"
                        if bracket:
                            label += f" ({bracket})"
                        
                        if st.checkbox(label, value=is_selected, key=f"search_{name}"):
                            if name not in st.session_state.selected_products:
                                st.session_state.selected_products.append(name)
                        else:
                            if name in st.session_state.selected_products:
                                st.session_state.selected_products.remove(name)
            
            # éƒµé€ã®çµæœï¼ˆAirãƒ¬ã‚¸ã«ãªã„å•†å“ï¼‰
            if mail_results:
                st.write("**ğŸ“¬ éƒµé€ã‚·ãƒ¼ãƒˆã®ã¿ã®å•†å“ï¼š**")
                st.caption("â€»ã“ã‚Œã‚‰ã¯Airãƒ¬ã‚¸ã«ç™»éŒ²ã•ã‚Œã¦ã„ãªã„å•†å“åã§ã™")
                cols = st.columns(3)
                for i, result in enumerate(mail_results):
                    name = result['name']
                    
                    with cols[i % 3]:
                        is_selected = name in st.session_state.selected_products
                        
                        if st.checkbox(f"ğŸ“¬ {name}", value=is_selected, key=f"mail_search_{name}"):
                            if name not in st.session_state.selected_products:
                                st.session_state.selected_products.append(name)
                        else:
                            if name in st.session_state.selected_products:
                                st.session_state.selected_products.remove(name)
            
            # åˆç®—ã‚°ãƒ«ãƒ¼ãƒ—æ©Ÿèƒ½ã®èª¬æ˜
            if len(st.session_state.selected_products) > 1:
                st.info("""
                ğŸ’¡ **ãƒ’ãƒ³ãƒˆ**: è¤‡æ•°ã®å•†å“ã‚’é¸æŠã—ãŸå ´åˆã€ã€Œåˆ†æãƒ¢ãƒ¼ãƒ‰ã€ã§ã€Œåˆç®—ã€ã‹ã€Œå€‹åˆ¥ã€ã‚’é¸ã¹ã¾ã™ã€‚
                - **åˆç®—**: é¸æŠã—ãŸã™ã¹ã¦ã®å•†å“ã‚’åˆè¨ˆã—ã¦åˆ†æ
                - **å€‹åˆ¥**: å•†å“ã”ã¨ã«åˆ¥ã€…ã«åˆ†æ
                """)
        else:
            st.info("è©²å½“ã™ã‚‹æˆä¸å“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")


def render_category_tab():
    """ã‚«ãƒ†ã‚´ãƒªãƒ¼é¸æŠã‚¿ãƒ–"""
    if not st.session_state.categories:
        st.info("ã‚«ãƒ†ã‚´ãƒªãƒ¼æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    st.write("**ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’é¸æŠã—ã¦ä¸€æ‹¬è¿½åŠ ï¼š**")
    
    cols = st.columns(4)
    
    sorted_categories = sorted(
        st.session_state.categories.items(),
        key=lambda x: len(x[1]),
        reverse=True
    )
    
    for i, (category, products) in enumerate(sorted_categories[:12]):
        with cols[i % 4]:
            if st.button(f"ğŸ“ {category} ({len(products)}ä»¶)", key=f"cat_{category}"):
                for p in products:
                    if p not in st.session_state.selected_products:
                        st.session_state.selected_products.append(p)
                st.rerun()


def clear_all_selected_products():
    """ã™ã¹ã¦ã®é¸æŠã‚’ã‚¯ãƒªã‚¢ï¼ˆcallbackç”¨ï¼‰"""
    st.session_state.selected_products = []
    st.session_state.product_groups = {}  # ã‚°ãƒ«ãƒ¼ãƒ—æƒ…å ±ã‚‚ã‚¯ãƒªã‚¢
    st.session_state.analysis_mode = "åˆç®—"
    st.session_state.sales_data = None
    st.session_state.forecast_data = None
    st.session_state.individual_sales_data = {}
    st.session_state.individual_forecast_results = []
    st.session_state.individual_all_methods_results = {}


def remove_single_product(product: str):
    """å˜ä¸€ã®æˆä¸å“ã‚’å‰Šé™¤ï¼ˆcallbackç”¨ï¼‰"""
    if product in st.session_state.selected_products:
        st.session_state.selected_products.remove(product)
    # ã‚°ãƒ«ãƒ¼ãƒ—æƒ…å ±ã‹ã‚‰ã‚‚å‰Šé™¤
    if product in st.session_state.product_groups:
        del st.session_state.product_groups[product]
    st.session_state.sales_data = None
    st.session_state.forecast_data = None
    st.session_state.individual_sales_data = {}
    st.session_state.individual_forecast_results = []
    st.session_state.individual_all_methods_results = {}


def render_selected_products():
    """é¸æŠä¸­ã®æˆä¸å“ã‚’è¡¨ç¤ºï¼ˆÃ—ãƒœã‚¿ãƒ³ã§å‰Šé™¤ã€ã‚°ãƒ«ãƒ¼ãƒ—é¸æŠæ©Ÿèƒ½ä»˜ãï¼‰"""
    st.divider()
    
    if st.session_state.selected_products:
        col1, col2 = st.columns([3, 1])
        with col1:
            st.write(f"**âœ… é¸æŠä¸­ã®æˆä¸å“ï¼ˆ{len(st.session_state.selected_products)}ä»¶ï¼‰**")
        with col2:
            # ã™ã¹ã¦ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
            if st.button("ğŸ—‘ï¸ ã™ã¹ã¦ã‚¯ãƒªã‚¢", key="clear_all_btn_main"):
                # å…¨å•†å“ã®ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
                for product in st.session_state.selected_products:
                    checkbox_key = f"search_{product}"
                    if checkbox_key in st.session_state:
                        st.session_state[checkbox_key] = False
                    mail_checkbox_key = f"mail_search_{product}"
                    if mail_checkbox_key in st.session_state:
                        st.session_state[mail_checkbox_key] = False
                
                st.session_state.selected_products = []
                st.session_state.product_groups = {}
                st.session_state.analysis_mode = "åˆç®—"
                st.session_state.sales_data = None
                st.session_state.forecast_data = None
                st.session_state.individual_sales_data = {}
                st.session_state.individual_forecast_results = []
                st.session_state.individual_all_methods_results = {}
                st.rerun()
        
        # ã‚°ãƒ«ãƒ¼ãƒ—æ©Ÿèƒ½ã®èª¬æ˜
        if len(st.session_state.selected_products) > 1:
            st.caption("ğŸ’¡ åŒã˜ã‚°ãƒ«ãƒ¼ãƒ—ç•ªå·ã®å•†å“ã¯åˆç®—ã—ã¦åˆ†æã•ã‚Œã¾ã™ã€‚ã‚°ãƒ«ãƒ¼ãƒ—0ã¯å˜ç‹¬æ‰±ã„ã§ã™ã€‚")
        
        # é¸æŠä¸­ã®å•†å“ãƒªã‚¹ãƒˆï¼ˆÃ—ãƒœã‚¿ãƒ³ï¼‹ã‚°ãƒ«ãƒ¼ãƒ—é¸æŠä»˜ãï¼‰
        st.markdown('<div style="background: #e3f2fd; border-radius: 10px; padding: 15px; margin: 10px 0;">', unsafe_allow_html=True)
        
        products_copy = st.session_state.selected_products.copy()
        
        # å„å•†å“ã«Ã—ãƒœã‚¿ãƒ³ã¨ã‚°ãƒ«ãƒ¼ãƒ—é¸æŠã‚’ä»˜ã‘ã‚‹
        for i, product in enumerate(products_copy):
            # ç¾åœ¨ã®ã‚°ãƒ«ãƒ¼ãƒ—ç•ªå·ã‚’å–å¾—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯0=å˜ç‹¬ï¼‰
            current_group = st.session_state.product_groups.get(product, 0)
            
            col_product, col_group, col_delete = st.columns([4, 2, 1])
            
            with col_product:
                st.markdown(f"ğŸ“¦ **{product}**")
            
            with col_group:
                # ã‚°ãƒ«ãƒ¼ãƒ—é¸æŠãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³
                new_group = st.selectbox(
                    "ã‚°ãƒ«ãƒ¼ãƒ—",
                    options=[0, 1, 2, 3, 4, 5],
                    index=current_group,
                    format_func=lambda x: "å˜ç‹¬" if x == 0 else f"ã‚°ãƒ«ãƒ¼ãƒ—{x}",
                    key=f"group_select_{i}_{hash(product) % 10000}",
                    label_visibility="collapsed"
                )
                # ã‚°ãƒ«ãƒ¼ãƒ—ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã€session_stateã‚’æ›´æ–°
                if new_group != current_group:
                    st.session_state.product_groups[product] = new_group
                    st.rerun()
            
            with col_delete:
                # Ã—ãƒœã‚¿ãƒ³ï¼ˆãƒ•ãƒ©ã‚°æ–¹å¼ + ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹çŠ¶æ…‹ãƒªã‚»ãƒƒãƒˆï¼‰
                if st.button("âœ•", key=f"del_{i}_{hash(product) % 10000}", help=f"{product}ã‚’å‰Šé™¤"):
                    # æ¤œç´¢çµæœã®ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
                    checkbox_key = f"search_{product}"
                    if checkbox_key in st.session_state:
                        st.session_state[checkbox_key] = False
                    mail_checkbox_key = f"mail_search_{product}"
                    if mail_checkbox_key in st.session_state:
                        st.session_state[mail_checkbox_key] = False
                    
                    # å•†å“ã‚’å‰Šé™¤
                    if product in st.session_state.selected_products:
                        st.session_state.selected_products.remove(product)
                    if product in st.session_state.product_groups:
                        del st.session_state.product_groups[product]
                    
                    # é–¢é€£ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢
                    st.session_state.sales_data = None
                    st.session_state.forecast_data = None
                    st.session_state.individual_sales_data = {}
                    st.session_state.individual_forecast_results = []
                    st.session_state.individual_all_methods_results = {}
                    st.rerun()
        
        st.markdown("</div>", unsafe_allow_html=True)
        
        # ã‚°ãƒ«ãƒ¼ãƒ—ã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
        groups_summary = {}
        for product in st.session_state.selected_products:
            group_num = st.session_state.product_groups.get(product, 0)
            if group_num not in groups_summary:
                groups_summary[group_num] = []
            groups_summary[group_num].append(product)
        
        # ã‚°ãƒ«ãƒ¼ãƒ—ãŒ1ã¤ä»¥ä¸Šã‚ã‚‹å ´åˆã®ã¿è¡¨ç¤º
        has_groups = any(g != 0 for g in groups_summary.keys())
        if has_groups:
            st.write("**ğŸ“Š ã‚°ãƒ«ãƒ¼ãƒ—æ§‹æˆ:**")
            for group_num, products in sorted(groups_summary.items()):
                if group_num == 0:
                    for p in products:
                        st.write(f"  - å˜ç‹¬: {p}")
                else:
                    st.write(f"  - ã‚°ãƒ«ãƒ¼ãƒ—{group_num}: {', '.join(products)}ï¼ˆåˆç®—ï¼‰")
    else:
        st.warning("ğŸ‘† ä¸Šã‹ã‚‰æˆä¸å“ã‚’é¸ã‚“ã§ãã ã•ã„")


def render_period_selection():
    """æœŸé–“é¸æŠã‚»ã‚¯ã‚·ãƒ§ãƒ³"""
    st.markdown('<p class="section-header">â‘¡ æœŸé–“ã‚’é¸ã¶</p>', unsafe_allow_html=True)
    
    today = date.today()
    
    col1, col2 = st.columns([1, 3])
    
    with col1:
        preset = st.selectbox(
            "ãƒ—ãƒªã‚»ãƒƒãƒˆ",
            ["ã‚«ã‚¹ã‚¿ãƒ ", "éå»1ãƒ¶æœˆ", "éå»3ãƒ¶æœˆ", "éå»6ãƒ¶æœˆ", "éå»1å¹´", "éå»2å¹´", "å…¨æœŸé–“"],
            index=4
        )
    
    if preset == "éå»1ãƒ¶æœˆ":
        default_start = today - timedelta(days=30)
        default_end = today
    elif preset == "éå»3ãƒ¶æœˆ":
        default_start = today - timedelta(days=90)
        default_end = today
    elif preset == "éå»6ãƒ¶æœˆ":
        default_start = today - timedelta(days=180)
        default_end = today
    elif preset == "éå»1å¹´":
        default_start = today - timedelta(days=365)
        default_end = today
    elif preset == "éå»2å¹´":
        default_start = today - timedelta(days=730)
        default_end = today
    elif preset == "å…¨æœŸé–“":
        default_start = date(2022, 8, 1)
        default_end = today
    else:
        default_start = today - timedelta(days=365)
        default_end = today
    
    with col2:
        # é–‹å§‹æ—¥
        st.write("**é–‹å§‹æ—¥**")
        col_sy, col_sm, col_sd = st.columns(3)
        
        years = list(range(2022, today.year + 2))
        months_jp = ["1æœˆ", "2æœˆ", "3æœˆ", "4æœˆ", "5æœˆ", "6æœˆ", "7æœˆ", "8æœˆ", "9æœˆ", "10æœˆ", "11æœˆ", "12æœˆ"]
        
        with col_sy:
            start_year = st.selectbox(
                "å¹´",
                years,
                index=years.index(default_start.year) if default_start.year in years else 0,
                key="start_year",
                label_visibility="collapsed"
            )
            st.caption("å¹´")
        with col_sm:
            start_month = st.selectbox(
                "æœˆ",
                list(range(1, 13)),
                index=default_start.month - 1,
                format_func=lambda x: months_jp[x-1],
                key="start_month",
                label_visibility="collapsed"
            )
            st.caption("æœˆ")
        with col_sd:
            max_day_start = calendar.monthrange(start_year, start_month)[1]
            start_day = st.number_input(
                "æ—¥",
                min_value=1,
                max_value=max_day_start,
                value=min(default_start.day, max_day_start),
                key="start_day",
                label_visibility="collapsed"
            )
            st.caption("æ—¥")
        
        # çµ‚äº†æ—¥
        st.write("**çµ‚äº†æ—¥**")
        col_ey, col_em, col_ed = st.columns(3)
        
        with col_ey:
            end_year = st.selectbox(
                "å¹´",
                years,
                index=years.index(default_end.year) if default_end.year in years else 0,
                key="end_year",
                label_visibility="collapsed"
            )
            st.caption("å¹´")
        with col_em:
            end_month = st.selectbox(
                "æœˆ",
                list(range(1, 13)),
                index=default_end.month - 1,
                format_func=lambda x: months_jp[x-1],
                key="end_month",
                label_visibility="collapsed"
            )
            st.caption("æœˆ")
        with col_ed:
            max_day_end = calendar.monthrange(end_year, end_month)[1]
            end_day = st.number_input(
                "æ—¥",
                min_value=1,
                max_value=max_day_end,
                value=min(default_end.day, max_day_end),
                key="end_day",
                label_visibility="collapsed"
            )
            st.caption("æ—¥")
    
    start_date = date(start_year, start_month, start_day)
    end_date = date(end_year, end_month, end_day)
    
    if start_date > end_date:
        st.error("âš ï¸ é–‹å§‹æ—¥ãŒçµ‚äº†æ—¥ã‚ˆã‚Šå¾Œã«ãªã£ã¦ã„ã¾ã™")
        end_date = start_date
    
    return start_date, end_date


def render_sales_analysis(start_date: date, end_date: date):
    """å£²ä¸Šåˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³"""
    st.markdown('<p class="section-header">â‘¢ å£²ä¸Šã‚’è¦‹ã‚‹</p>', unsafe_allow_html=True)
    
    if not st.session_state.selected_products:
        st.info("æˆä¸å“ã‚’é¸æŠã™ã‚‹ã¨ã€ã“ã“ã«å£²ä¸ŠãŒè¡¨ç¤ºã•ã‚Œã¾ã™")
        return None
    
    df_items = st.session_state.data_loader.load_item_sales()
    
    if df_items.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return None
    
    # Airãƒ¬ã‚¸ãƒ‡ãƒ¼ã‚¿ã«sourceåˆ—ã‚’è¿½åŠ 
    if 'source' not in df_items.columns:
        df_items = df_items.copy()
        df_items['source'] = 'airregi'
    
    # éƒµé€ãƒ‡ãƒ¼ã‚¿çµ±åˆã‚ªãƒ—ã‚·ãƒ§ãƒ³
    mail_order_enabled = hasattr(config, 'MAIL_ORDER_SPREADSHEET_ID') and config.MAIL_ORDER_SPREADSHEET_ID
    include_mail_orders = False
    airregi_count = 0
    mail_order_count = 0
    
    if mail_order_enabled:
        include_mail_orders = st.checkbox(
            "ğŸ“¬ éƒµé€æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚ã‚‹",
            value=True,
            help="Googleãƒ•ã‚©ãƒ¼ãƒ ã‹ã‚‰ã®éƒµé€ä¾é ¼ã‚‚éœ€è¦ã«å«ã‚ã¾ã™"
        )
    
    # é¸æŠã•ã‚ŒãŸå•†å“ã®ã‚ªãƒªã‚¸ãƒŠãƒ«åã‚’å–å¾—
    original_names = st.session_state.normalizer.get_all_original_names(
        st.session_state.selected_products
    )
    
    # Airãƒ¬ã‚¸ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿
    mask = (df_items['date'] >= pd.Timestamp(start_date)) & (df_items['date'] <= pd.Timestamp(end_date))
    df_filtered_airregi = df_items[mask]
    df_agg_airregi = aggregate_by_products(df_filtered_airregi, original_names, aggregate=True)
    
    if not df_agg_airregi.empty:
        airregi_count = int(df_agg_airregi['è²©å£²å•†å“æ•°'].sum())
    
    # éƒµé€ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
    df_mail_matched = pd.DataFrame()
    if include_mail_orders:
        df_mail = st.session_state.data_loader.get_mail_order_summary()
        
        if not df_mail.empty:
            # éƒµé€ãƒ‡ãƒ¼ã‚¿ã®å•†å“åã‚’Airãƒ¬ã‚¸ã®å•†å“åï¼ˆã‚ªãƒªã‚¸ãƒŠãƒ«åï¼‰ã«ãƒãƒƒãƒãƒ³ã‚°
            matched_rows = []
            
            for _, mail_row in df_mail.iterrows():
                mail_product = str(mail_row['å•†å“å']).strip()
                
                # å…±é€šãƒãƒƒãƒãƒ³ã‚°é–¢æ•°ã‚’ä½¿ç”¨
                matched_name = match_mail_product_to_airregi(mail_product, original_names)
                
                if matched_name:
                    new_row = mail_row.copy()
                    new_row['å•†å“å'] = matched_name
                    matched_rows.append(new_row)
            
            if matched_rows:
                df_mail_matched = pd.DataFrame(matched_rows)
                # æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿
                if 'date' in df_mail_matched.columns:
                    df_mail_matched['date'] = pd.to_datetime(df_mail_matched['date'], errors='coerce')
                    mail_mask = (df_mail_matched['date'] >= pd.Timestamp(start_date)) & \
                               (df_mail_matched['date'] <= pd.Timestamp(end_date))
                    df_mail_matched = df_mail_matched[mail_mask]
                mail_order_count = int(df_mail_matched['è²©å£²å•†å“æ•°'].sum()) if not df_mail_matched.empty else 0
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
    if not df_mail_matched.empty and include_mail_orders:
        # éƒµé€ãƒ‡ãƒ¼ã‚¿ã‚’Airãƒ¬ã‚¸å½¢å¼ã«å¤‰æ›ã—ã¦çµåˆ
        df_mail_for_merge = df_mail_matched[['date', 'å•†å“å', 'è²©å£²å•†å“æ•°', 'è²©å£²ç·å£²ä¸Š', 'è¿”å“å•†å“æ•°']].copy()
        df_mail_for_merge['source'] = 'mail_order'
        
        # Airãƒ¬ã‚¸ãƒ‡ãƒ¼ã‚¿
        df_airregi_for_merge = df_filtered_airregi[df_filtered_airregi['å•†å“å'].isin(original_names)].copy()
        if 'source' not in df_airregi_for_merge.columns:
            df_airregi_for_merge['source'] = 'airregi'
        
        # çµåˆ
        df_combined = pd.concat([df_airregi_for_merge, df_mail_for_merge], ignore_index=True)
        df_agg = df_combined.groupby('date').agg({
            'è²©å£²å•†å“æ•°': 'sum',
            'è²©å£²ç·å£²ä¸Š': 'sum',
            'è¿”å“å•†å“æ•°': 'sum'
        }).reset_index()
    else:
        df_agg = df_agg_airregi
    
    if df_agg.empty:
        st.warning("è©²å½“æœŸé–“ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return None
    
    df_agg = df_agg.sort_values('date').reset_index(drop=True)
    
    total_qty = airregi_count + mail_order_count
    total_sales = df_agg['è²©å£²ç·å£²ä¸Š'].sum()
    period_days = (end_date - start_date).days + 1
    avg_daily = total_qty / period_days if period_days > 0 else 0
    
    # å¹³æ—¥ãƒ»ä¼‘æ—¥ã®å¹³å‡ã‚’è¨ˆç®—
    df_agg['weekday'] = pd.to_datetime(df_agg['date']).dt.dayofweek
    df_weekday = df_agg[df_agg['weekday'] < 5]
    df_weekend = df_agg[df_agg['weekday'] >= 5]
    
    avg_weekday = df_weekday['è²©å£²å•†å“æ•°'].mean() if not df_weekday.empty else 0
    avg_weekend = df_weekend['è²©å£²å•†å“æ•°'].mean() if not df_weekend.empty else 0
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
    st.write("**ğŸ“Š è²©å£²å®Ÿç¸¾**")
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("ğŸ›’ è²©å£²æ•°é‡åˆè¨ˆ", f"{total_qty:,}ä½“")
    col2.metric("ğŸ’° å£²ä¸Šåˆè¨ˆ", f"Â¥{total_sales:,.0f}")
    col3.metric("ğŸ“ˆ å¹³å‡æ—¥è²©", f"{avg_daily:.1f}ä½“/æ—¥")
    col4.metric("ğŸ“… æœŸé–“", f"{period_days}æ—¥é–“")
    
    # ã‚¨ã‚¢ãƒ¬ã‚¸ã¨éƒµé€ã®å†…è¨³ã‚’è¡¨ç¤º
    if include_mail_orders:
        col5, col6, col7, col8 = st.columns(4)
        col5.metric("ğŸª Airãƒ¬ã‚¸", f"{airregi_count:,}ä½“")
        col6.metric("ğŸ“¬ éƒµé€", f"{mail_order_count:,}ä½“")
        
        # ä¼‘æ—¥/å¹³æ—¥æ¯”ç‡
        if avg_weekday > 0:
            ratio = avg_weekend / avg_weekday
            col7.metric("ğŸ“Š ä¼‘æ—¥/å¹³æ—¥æ¯”", f"{ratio:.2f}å€")
    else:
        col5, col6, col7, col8 = st.columns(4)
        col5.metric("ğŸ“… å¹³æ—¥å¹³å‡", f"{avg_weekday:.1f}ä½“/æ—¥")
        col6.metric("ğŸŒ ä¼‘æ—¥å¹³å‡", f"{avg_weekend:.1f}ä½“/æ—¥")
        if avg_weekday > 0:
            ratio = avg_weekend / avg_weekday
            col7.metric("ğŸ“Š ä¼‘æ—¥/å¹³æ—¥æ¯”", f"{ratio:.2f}å€")
    
    # ========== éå»ã¨ã®æ¯”è¼ƒã‚»ã‚¯ã‚·ãƒ§ãƒ³ ==========
    render_period_comparison(df_items, original_names, start_date, end_date, total_qty)
    
    st.session_state.sales_data = df_agg
    
    return df_agg


def render_period_comparison(df_items: pd.DataFrame, original_names: list, start_date: date, end_date: date, current_total: int):
    """éå»ã¨ã®æ¯”è¼ƒï¼ˆæœˆæ¬¡ãƒ»å¹´æ¬¡ï¼‰ã‚’è¡¨ç¤º - å¸¸ã«è¡¨ç¤ºç‰ˆ"""
    
    st.markdown('<p class="section-header">ğŸ“Š éå»ã¨ã®æ¯”è¼ƒ</p>', unsafe_allow_html=True)
    
    comparison_type = st.radio(
        "æ¯”è¼ƒã‚¿ã‚¤ãƒ—",
        ["æ˜¨å¹´åŒæœŸæ¯”è¼ƒ", "æœˆæ¬¡æ¨ç§»", "å¹´æ¬¡æ¨ç§»"],
        horizontal=True,
        key="comparison_type"
    )
    
    if comparison_type == "æ˜¨å¹´åŒæœŸæ¯”è¼ƒ":
        render_year_over_year_comparison(df_items, original_names, start_date, end_date, current_total)
    elif comparison_type == "æœˆæ¬¡æ¨ç§»":
        render_monthly_trend(df_items, original_names)
    else:
        render_yearly_trend(df_items, original_names)


def render_year_over_year_comparison(df_items: pd.DataFrame, original_names: list, start_date: date, end_date: date, current_total: int):
    """æ˜¨å¹´åŒæœŸã¨ã®æ¯”è¼ƒ"""
    st.write("### ğŸ“ˆ æ˜¨å¹´åŒæœŸã¨ã®æ¯”è¼ƒ")
    
    # æ˜¨å¹´åŒæœŸã®æœŸé–“ã‚’è¨ˆç®—
    last_year_start = date(start_date.year - 1, start_date.month, start_date.day)
    last_year_end = date(end_date.year - 1, end_date.month, min(end_date.day, 28))  # æœˆæœ«å¯¾ç­–
    
    # æ˜¨å¹´åŒæœŸã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    mask_last_year = (df_items['date'] >= pd.Timestamp(last_year_start)) & \
                     (df_items['date'] <= pd.Timestamp(last_year_end))
    df_last_year = df_items[mask_last_year]
    df_last_year_agg = aggregate_by_products(df_last_year, original_names, aggregate=True)
    
    last_year_total = int(df_last_year_agg['è²©å£²å•†å“æ•°'].sum()) if not df_last_year_agg.empty else 0
    
    # å¢—æ¸›ã‚’è¨ˆç®—
    if last_year_total > 0:
        diff = current_total - last_year_total
        diff_pct = (diff / last_year_total) * 100
        
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("ğŸ“… ä»ŠæœŸ", f"{current_total:,}ä½“")
        col2.metric("ğŸ“… æ˜¨å¹´åŒæœŸ", f"{last_year_total:,}ä½“")
        col3.metric("ğŸ“Š å¢—æ¸›æ•°", f"{diff:+,}ä½“", delta=f"{diff_pct:+.1f}%")
        
        if diff > 0:
            col4.metric("ğŸ“ˆ è©•ä¾¡", "å¢—åŠ  â¬†ï¸", delta=f"{diff_pct:.1f}%å¢—")
        elif diff < 0:
            col4.metric("ğŸ“‰ è©•ä¾¡", "æ¸›å°‘ â¬‡ï¸", delta=f"{diff_pct:.1f}%æ¸›")
        else:
            col4.metric("â¡ï¸ è©•ä¾¡", "æ¨ªã°ã„")
        
        # è©³ç´°èª¬æ˜
        st.info(f"""
        **æ¯”è¼ƒæœŸé–“**
        - ä»ŠæœŸ: {start_date.strftime('%Yå¹´%mæœˆ%dæ—¥')} ã€œ {end_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}
        - æ˜¨å¹´åŒæœŸ: {last_year_start.strftime('%Yå¹´%mæœˆ%dæ—¥')} ã€œ {last_year_end.strftime('%Yå¹´%mæœˆ%dæ—¥')}
        
        **çµæœ**: æ˜¨å¹´åŒæœŸã¨æ¯”ã¹ã¦ **{abs(diff):,}ä½“** {'å¢—åŠ ' if diff > 0 else 'æ¸›å°‘'}ï¼ˆ{abs(diff_pct):.1f}%{'å¢—' if diff > 0 else 'æ¸›'}ï¼‰
        """)
    else:
        st.warning("æ˜¨å¹´åŒæœŸã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")


def render_monthly_trend(df_items: pd.DataFrame, original_names: list):
    """æœˆæ¬¡æ¨ç§»ã‚’è¡¨ç¤º"""
    st.write("### ğŸ“Š æœˆæ¬¡æ¨ç§»")
    
    # å…¨æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’æœˆåˆ¥ã«é›†è¨ˆ
    df_all = aggregate_by_products(df_items, original_names, aggregate=True)
    
    if df_all.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    df_all['date'] = pd.to_datetime(df_all['date'])
    df_all['å¹´æœˆ'] = df_all['date'].dt.to_period('M')
    
    monthly = df_all.groupby('å¹´æœˆ').agg({
        'è²©å£²å•†å“æ•°': 'sum',
        'è²©å£²ç·å£²ä¸Š': 'sum'
    }).reset_index()
    monthly['å¹´æœˆ'] = monthly['å¹´æœˆ'].astype(str)
    
    # ç›´è¿‘12ãƒ¶æœˆã«çµã‚‹
    monthly = monthly.tail(24)
    
    # å‰æœˆæ¯”ã‚’è¨ˆç®—
    monthly['å‰æœˆæ¯”'] = monthly['è²©å£²å•†å“æ•°'].pct_change() * 100
    
    # ã‚°ãƒ©ãƒ•
    fig = go.Figure()
    fig.add_trace(go.Bar(
        x=monthly['å¹´æœˆ'],
        y=monthly['è²©å£²å•†å“æ•°'],
        name='è²©å£²æ•°',
        marker_color='#4285F4'
    ))
    
    fig.update_layout(
        title='æœˆåˆ¥è²©å£²æ•°æ¨ç§»',
        xaxis_title='å¹´æœˆ',
        yaxis_title='è²©å£²æ•°ï¼ˆä½“ï¼‰',
        height=350
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # è¡¨å½¢å¼ã§ã‚‚è¡¨ç¤º
    st.write("**æœˆåˆ¥ãƒ‡ãƒ¼ã‚¿**")
    display_df = monthly[['å¹´æœˆ', 'è²©å£²å•†å“æ•°', 'å‰æœˆæ¯”']].copy()
    display_df.columns = ['å¹´æœˆ', 'è²©å£²æ•°ï¼ˆä½“ï¼‰', 'å‰æœˆæ¯”ï¼ˆ%ï¼‰']
    display_df['è²©å£²æ•°ï¼ˆä½“ï¼‰'] = display_df['è²©å£²æ•°ï¼ˆä½“ï¼‰'].apply(lambda x: f"{int(x):,}")
    display_df['å‰æœˆæ¯”ï¼ˆ%ï¼‰'] = display_df['å‰æœˆæ¯”ï¼ˆ%ï¼‰'].apply(lambda x: f"{x:+.1f}%" if pd.notna(x) else "-")
    st.dataframe(display_df.tail(12), use_container_width=True, hide_index=True)


def render_yearly_trend(df_items: pd.DataFrame, original_names: list):
    """å¹´æ¬¡æ¨ç§»ã‚’è¡¨ç¤ºï¼ˆè¡¨å½¢å¼ã‚’é‡è¦–ï¼‰"""
    st.write("### ğŸ“Š å¹´æ¬¡æ¨ç§»ï¼ˆå¹´åˆ¥æ¯”è¼ƒè¡¨ï¼‰")
    
    # å…¨æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’å¹´åˆ¥ã«é›†è¨ˆ
    df_all = aggregate_by_products(df_items, original_names, aggregate=True)
    
    if df_all.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    df_all['date'] = pd.to_datetime(df_all['date'])
    df_all['å¹´'] = df_all['date'].dt.year
    
    yearly = df_all.groupby('å¹´').agg({
        'è²©å£²å•†å“æ•°': 'sum',
        'è²©å£²ç·å£²ä¸Š': 'sum'
    }).reset_index()
    
    # å‰å¹´æ¯”ã‚’è¨ˆç®—
    yearly['å‰å¹´æ¯”'] = yearly['è²©å£²å•†å“æ•°'].pct_change() * 100
    yearly['å¢—æ¸›æ•°'] = yearly['è²©å£²å•†å“æ•°'].diff()
    
    # ========== è¡¨å½¢å¼ã‚’æœ€åˆã«å¤§ããè¡¨ç¤º ==========
    st.write("**ğŸ“‹ å¹´åˆ¥æ¯”è¼ƒè¡¨**")
    
    # è¦‹ã‚„ã™ã„è¡¨å½¢å¼ã§è¡¨ç¤º
    table_data = []
    for idx, row in yearly.iterrows():
        year = int(row['å¹´'])
        qty = int(row['è²©å£²å•†å“æ•°'])
        diff = row['å¢—æ¸›æ•°']
        pct = row['å‰å¹´æ¯”']
        
        # å¢—æ¸›ã®è¡¨ç¤º
        if pd.notna(diff):
            diff_str = f"{int(diff):+,}ä½“"
            pct_str = f"{pct:+.1f}%"
            if diff > 0:
                eval_str = "ğŸ“ˆ å¢—åŠ "
            elif diff < 0:
                eval_str = "ğŸ“‰ æ¸›å°‘"
            else:
                eval_str = "â¡ï¸ åŒã˜"
        else:
            diff_str = "-"
            pct_str = "-"
            eval_str = "-"
        
        table_data.append({
            'å¹´': f"{year}å¹´",
            'è²©å£²æ•°': f"{qty:,}ä½“",
            'å‰å¹´æ¯”ï¼ˆæ•°ï¼‰': diff_str,
            'å‰å¹´æ¯”ï¼ˆ%ï¼‰': pct_str,
            'è©•ä¾¡': eval_str
        })
    
    display_df = pd.DataFrame(table_data)
    st.dataframe(display_df, use_container_width=True, hide_index=True)
    
    # ========== ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã§æœ€æ–°å¹´ã¨å‰å¹´ã‚’æ¯”è¼ƒ ==========
    if len(yearly) >= 2:
        latest = yearly.iloc[-1]
        prev = yearly.iloc[-2]
        diff = int(latest['è²©å£²å•†å“æ•°'] - prev['è²©å£²å•†å“æ•°'])
        diff_pct = latest['å‰å¹´æ¯”']
        
        st.write("**ğŸ“Š ç›´è¿‘ã®å¹´æ¬¡æ¯”è¼ƒ**")
        col1, col2, col3, col4 = st.columns(4)
        col1.metric(f"ğŸ“… {int(prev['å¹´'])}å¹´", f"{int(prev['è²©å£²å•†å“æ•°']):,}ä½“")
        col2.metric(f"ğŸ“… {int(latest['å¹´'])}å¹´", f"{int(latest['è²©å£²å•†å“æ•°']):,}ä½“")
        col3.metric("ğŸ“Š å¢—æ¸›æ•°", f"{diff:+,}ä½“")
        col4.metric("ğŸ“Š å¢—æ¸›ç‡", f"{diff_pct:+.1f}%")
        
        # ã‚µãƒãƒªãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        if diff > 0:
            st.success(f"âœ… {int(latest['å¹´'])}å¹´ã¯{int(prev['å¹´'])}å¹´ã‚ˆã‚Š **{diff:,}ä½“** å¤šãè²©å£²ï¼ˆ{diff_pct:+.1f}%å¢—ï¼‰")
        elif diff < 0:
            st.warning(f"âš ï¸ {int(latest['å¹´'])}å¹´ã¯{int(prev['å¹´'])}å¹´ã‚ˆã‚Š **{abs(diff):,}ä½“** å°‘ãªãè²©å£²ï¼ˆ{abs(diff_pct):.1f}%æ¸›ï¼‰")
        else:
            st.info(f"â¡ï¸ {int(latest['å¹´'])}å¹´ã¯{int(prev['å¹´'])}å¹´ã¨åŒã˜è²©å£²æ•°")
    
    # ========== ã‚°ãƒ©ãƒ•ã¯è£œåŠ©çš„ã«è¡¨ç¤º ==========
    with st.expander("ğŸ“ˆ ã‚°ãƒ©ãƒ•ã§è¦‹ã‚‹", expanded=False):
        fig = go.Figure()
        fig.add_trace(go.Bar(
            x=yearly['å¹´'].astype(str),
            y=yearly['è²©å£²å•†å“æ•°'],
            name='è²©å£²æ•°',
            marker_color='#4CAF50',
            text=yearly['è²©å£²å•†å“æ•°'].apply(lambda x: f"{int(x):,}"),
            textposition='outside'
        ))
        
        fig.update_layout(
            title='å¹´åˆ¥è²©å£²æ•°æ¨ç§»',
            xaxis_title='å¹´',
            yaxis_title='è²©å£²æ•°ï¼ˆä½“ï¼‰',
            height=350
        )
        st.plotly_chart(fig, use_container_width=True)


def render_forecast_section(sales_data: pd.DataFrame):
    """éœ€è¦äºˆæ¸¬ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆVertex AIå¯¾å¿œï¼‰"""
    st.markdown('<p class="section-header">â‘£ éœ€è¦ã‚’äºˆæ¸¬ã™ã‚‹</p>', unsafe_allow_html=True)
    
    if sales_data is None or sales_data.empty:
        st.info("å£²ä¸Šãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã¨ã€éœ€è¦äºˆæ¸¬ãŒã§ãã¾ã™")
        return
    
    col1, col2 = st.columns(2)
    
    with col1:
        forecast_mode = st.radio(
            "äºˆæ¸¬æœŸé–“ã®æŒ‡å®šæ–¹æ³•",
            ["æ—¥æ•°ã§æŒ‡å®š", "æœŸé–“ã§æŒ‡å®š"],
            horizontal=True,
            key="forecast_mode_existing",
            help="ã€ŒæœŸé–“ã§æŒ‡å®šã€ã¯æœŸé–“é™å®šå“ã®äºˆæ¸¬ã«ä¾¿åˆ©ã§ã™"
        )
    
    with col2:
        available_methods = get_available_forecast_methods()
        default_idx = 0  # Vertex AIãŒã‚ã‚Œã°0ã€ãªã‘ã‚Œã°å­£ç¯€æ€§è€ƒæ…®
        if "ğŸš€ Vertex AIï¼ˆæ¨å¥¨ï¼‰" not in available_methods:
            default_idx = available_methods.index("å­£ç¯€æ€§è€ƒæ…®ï¼ˆçµ±è¨ˆï¼‰") if "å­£ç¯€æ€§è€ƒæ…®ï¼ˆçµ±è¨ˆï¼‰" in available_methods else 0
        
        method = st.selectbox(
            "äºˆæ¸¬æ–¹æ³•",
            available_methods,
            index=default_idx,
            key="forecast_method_existing"
        )
    
    # äºˆæ¸¬æœŸé–“ã®è¨­å®š
    if forecast_mode == "æ—¥æ•°ã§æŒ‡å®š":
        forecast_days = st.slider("äºˆæ¸¬æ—¥æ•°", 30, 365, 180, key="forecast_days_existing")
        forecast_start_date = None
        forecast_end_date = None
    else:
        # æœŸé–“æŒ‡å®šUIï¼ˆåˆ†ææœŸé–“ã¨åŒã˜ã‚¹ã‚¿ã‚¤ãƒ«ï¼‰
        today = date.today()
        default_start = today + timedelta(days=1)
        default_end = today + timedelta(days=180)
        
        st.write("**äºˆæ¸¬æœŸé–“æŒ‡å®š**")
        col_s1, col_s2, col_s3, col_e1, col_e2, col_e3 = st.columns([1, 1, 1, 1, 1, 1])
        
        with col_s1:
            start_year = st.selectbox(
                "äºˆæ¸¬é–‹å§‹å¹´",
                list(range(2025, 2028)),
                index=list(range(2025, 2028)).index(default_start.year) if default_start.year in range(2025, 2028) else 0,
                key="forecast_start_year"
            )
        with col_s2:
            start_month = st.selectbox(
                "äºˆæ¸¬é–‹å§‹æœˆ",
                list(range(1, 13)),
                index=default_start.month - 1,
                format_func=lambda x: f"{x}æœˆ",
                key="forecast_start_month"
            )
        with col_s3:
            max_day_start = calendar.monthrange(start_year, start_month)[1]
            start_day = st.selectbox(
                "äºˆæ¸¬é–‹å§‹æ—¥",
                list(range(1, max_day_start + 1)),
                index=min(default_start.day - 1, max_day_start - 1),
                format_func=lambda x: f"{x}æ—¥",
                key="forecast_start_day"
            )
        
        with col_e1:
            end_year = st.selectbox(
                "äºˆæ¸¬çµ‚äº†å¹´",
                list(range(2025, 2028)),
                index=list(range(2025, 2028)).index(default_end.year) if default_end.year in range(2025, 2028) else 0,
                key="forecast_end_year"
            )
        with col_e2:
            end_month = st.selectbox(
                "äºˆæ¸¬çµ‚äº†æœˆ",
                list(range(1, 13)),
                index=default_end.month - 1,
                format_func=lambda x: f"{x}æœˆ",
                key="forecast_end_month"
            )
        with col_e3:
            max_day_end = calendar.monthrange(end_year, end_month)[1]
            end_day = st.selectbox(
                "äºˆæ¸¬çµ‚äº†æ—¥",
                list(range(1, max_day_end + 1)),
                index=min(default_end.day - 1, max_day_end - 1),
                format_func=lambda x: f"{x}æ—¥",
                key="forecast_end_day"
            )
        
        forecast_start_date = date(start_year, start_month, start_day)
        forecast_end_date = date(end_year, end_month, end_day)
        
        if forecast_end_date <= forecast_start_date:
            st.error("âš ï¸ çµ‚äº†æ—¥ã¯é–‹å§‹æ—¥ã‚ˆã‚Šå¾Œã«ã—ã¦ãã ã•ã„")
            return
        
        forecast_days = (forecast_end_date - forecast_start_date).days + 1
        st.info(f"ğŸ“… äºˆæ¸¬æœŸé–“: {forecast_start_date.strftime('%Yå¹´%mæœˆ%dæ—¥')} ã€œ {forecast_end_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}ï¼ˆ{forecast_days}æ—¥é–“ï¼‰")
    
    # äºˆæ¸¬æ–¹æ³•ã®èª¬æ˜ã‚’è¡¨ç¤º
    method_info = FORECAST_METHODS[method]
    css_class = "vertex-ai" if "Vertex" in method else "seasonality" if "å­£ç¯€" in method else "moving-avg" if "ç§»å‹•" in method else "exponential"
    
    st.markdown(f"""
    <div class="method-card method-{css_class}">
        <strong>{method_info['icon']} {method}</strong><br>
        {method_info['description']}
    </div>
    """, unsafe_allow_html=True)
    
    # å…±å¤‰é‡ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆVertex AIé¸æŠæ™‚ï¼‰
    use_covariates = False
    if "Vertex AI" in method and VERTEX_AI_AVAILABLE:
        use_covariates = st.checkbox(
            "å…±å¤‰é‡ã‚’ä½¿ç”¨ï¼ˆå¤©æ°—ãƒ»å…­æ›œãƒ»ã‚¤ãƒ™ãƒ³ãƒˆï¼‰",
            value=True,
            help="äºˆæ¸¬ç²¾åº¦ãŒå‘ä¸Šã—ã¾ã™ãŒã€å‡¦ç†æ™‚é–“ãŒé•·ããªã‚‹å ´åˆãŒã‚ã‚Šã¾ã™"
        )
    
    if st.button("ğŸ”® éœ€è¦ã‚’äºˆæ¸¬", type="primary", use_container_width=True, key="forecast_btn_existing"):
        with st.spinner("äºˆæ¸¬ä¸­..."):
            try:
                if method == "ğŸ”„ ã™ã¹ã¦ã®æ–¹æ³•ã§æ¯”è¼ƒ":
                    # ã™ã¹ã¦ã®æ–¹æ³•ã§äºˆæ¸¬
                    product_id = "_".join(st.session_state.selected_products[:3])
                    all_results = forecast_all_methods_with_vertex_ai(sales_data, forecast_days, product_id)
                    display_comparison_results_v12(all_results, forecast_days, sales_data)
                else:
                    # å˜ä¸€ã®äºˆæ¸¬æ–¹æ³•
                    product_id = "_".join(st.session_state.selected_products[:3])
                    forecast, method_message = forecast_with_vertex_ai(sales_data, forecast_days, method, product_id)
                    
                    if forecast is not None and not forecast.empty:
                        display_single_forecast_result_v12(forecast, forecast_days, method, method_message, sales_data)
                    else:
                        st.error("äºˆæ¸¬çµæœãŒç©ºã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            except Exception as e:
                st.error(f"äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
                logger.error(f"äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")


def display_single_forecast_result_v12(forecast: pd.DataFrame, forecast_days: int, method: str, method_message: str, sales_data: pd.DataFrame = None):
    """å˜ä¸€ã®äºˆæ¸¬çµæœã‚’è¡¨ç¤ºï¼ˆv12 ã‚¹ãƒãƒ›æœ€é©åŒ– + ãƒ­ã‚¸ãƒƒã‚¯èª¬æ˜ï¼‰"""
    raw_total = int(forecast['predicted'].sum())
    rounded_total = round_up_to_50(raw_total)
    avg_predicted = forecast['predicted'].mean()
    
    # Vertex AIä½¿ç”¨æ™‚ã¯ç‰¹åˆ¥è¡¨ç¤º
    if "Vertex AI" in method_message:
        st.success(f"âœ… äºˆæ¸¬å®Œäº†ï¼ï¼ˆğŸš€ {method_message}ï¼‰")
    else:
        st.success(f"âœ… äºˆæ¸¬å®Œäº†ï¼ï¼ˆ{method_message}ï¼‰")
    
    st.session_state.last_forecast_method = method_message
    
    col1, col2, col3 = st.columns(3)
    col1.metric("ğŸ“¦ äºˆæ¸¬è²©å£²ç·æ•°", f"{rounded_total:,}ä½“")
    col2.metric("ğŸ“ˆ å¹³å‡æ—¥è²©ï¼ˆäºˆæ¸¬ï¼‰", f"{avg_predicted:.1f}ä½“/æ—¥")
    col3.metric("ğŸ“… äºˆæ¸¬æœŸé–“", f"{forecast_days}æ—¥é–“")
    
    # äºˆæ¸¬ãƒ­ã‚¸ãƒƒã‚¯ã®èª¬æ˜ã‚’è¿½åŠ 
    with st.expander("ğŸ“Š äºˆæ¸¬ãƒ­ã‚¸ãƒƒã‚¯ã®è©³ç´°", expanded=False):
        display_forecast_logic_explanation(method, sales_data, forecast, forecast_days, avg_predicted)
    
    # ã‚°ãƒ©ãƒ•è¡¨ç¤ºï¼ˆã‚¹ãƒãƒ›æœ€é©åŒ–ï¼‰
    method_info = FORECAST_METHODS.get(method, {"color": "#4285F4"})
    
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=forecast['date'],
        y=forecast['predicted'],
        mode='lines',
        name='äºˆæ¸¬',
        line=dict(color=method_info.get('color', '#4285F4'), width=2)
    ))
    
    # ä¿¡é ¼åŒºé–“ãŒã‚ã‚Œã°è¡¨ç¤º
    if 'confidence_lower' in forecast.columns and forecast['confidence_lower'].notna().any():
        fig.add_trace(go.Scatter(
            x=forecast['date'],
            y=forecast['confidence_upper'],
            mode='lines',
            name='ä¸Šé™',
            line=dict(color='rgba(66, 133, 244, 0.3)', dash='dash'),
            showlegend=True
        ))
        fig.add_trace(go.Scatter(
            x=forecast['date'],
            y=forecast['confidence_lower'],
            mode='lines',
            name='ä¸‹é™',
            line=dict(color='rgba(66, 133, 244, 0.3)', dash='dash'),
            fill='tonexty',
            fillcolor='rgba(66, 133, 244, 0.1)',
            showlegend=True
        ))
    
    # ã‚¹ãƒãƒ›æœ€é©åŒ–ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
    layout = get_mobile_chart_layout(f'{method}ã«ã‚ˆã‚‹æ—¥åˆ¥äºˆæ¸¬', height=280)
    layout['xaxis_title'] = 'æ—¥ä»˜'
    layout['yaxis_title'] = 'äºˆæ¸¬è²©å£²æ•°ï¼ˆä½“ï¼‰'
    fig.update_layout(**layout)
    
    st.plotly_chart(fig, use_container_width=True, config=get_mobile_chart_config())
    
    st.session_state.forecast_data = forecast
    st.session_state.forecast_total = rounded_total


def display_forecast_logic_explanation(method: str, sales_data: pd.DataFrame, forecast: pd.DataFrame, forecast_days: int, avg_predicted: float):
    """äºˆæ¸¬ãƒ­ã‚¸ãƒƒã‚¯ã®è©³ç´°èª¬æ˜ã‚’è¡¨ç¤º"""
    
    if sales_data is None or sales_data.empty:
        st.write("å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆ
    total_days = len(sales_data)
    total_qty = int(sales_data['è²©å£²å•†å“æ•°'].sum())
    avg_daily = sales_data['è²©å£²å•†å“æ•°'].mean()
    max_daily = sales_data['è²©å£²å•†å“æ•°'].max()
    min_daily = sales_data['è²©å£²å•†å“æ•°'].min()
    
    st.write("#### ğŸ“¥ å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ï¼ˆéå»ã®å®Ÿç¸¾ï¼‰")
    st.write(f"""
    - **åˆ†ææœŸé–“**: {total_days}æ—¥é–“
    - **ç·è²©å£²æ•°**: {total_qty:,}ä½“
    - **å¹³å‡æ—¥è²©**: {avg_daily:.1f}ä½“/æ—¥
    - **æœ€å¤§æ—¥è²©**: {max_daily:.0f}ä½“/æ—¥
    - **æœ€å°æ—¥è²©**: {min_daily:.0f}ä½“/æ—¥
    """)
    
    st.write("#### ğŸ”® äºˆæ¸¬ãƒ­ã‚¸ãƒƒã‚¯")
    
    if "Vertex AI" in method:
        st.write(f"""
        **Vertex AI AutoML Forecasting**
        1. éå»{total_days}æ—¥é–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã«å…¥åŠ›
        2. æ™‚ç³»åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»å‘¨æœŸæ€§ï¼‰ã‚’è‡ªå‹•æ¤œå‡º
        3. å¤©æ°—ãƒ»å…­æ›œãƒ»ã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±ã‚‚è€ƒæ…®ï¼ˆå…±å¤‰é‡ï¼‰
        4. {forecast_days}æ—¥é–“ã®æ—¥åˆ¥äºˆæ¸¬ã‚’ç”Ÿæˆ
        
        **è¨ˆç®—çµæœ**:
        - äºˆæ¸¬å¹³å‡æ—¥è²©: {avg_predicted:.1f}ä½“/æ—¥
        - å®Ÿç¸¾å¹³å‡ã¨ã®å·®: {avg_predicted - avg_daily:+.1f}ä½“/æ—¥ ({((avg_predicted/avg_daily)-1)*100:+.1f}%)
        """)
    
    elif "å­£ç¯€æ€§" in method:
        # æ›œæ—¥åˆ¥å¹³å‡ã‚’è¨ˆç®—
        if 'date' in sales_data.columns:
            sales_data_copy = sales_data.copy()
            sales_data_copy['weekday'] = pd.to_datetime(sales_data_copy['date']).dt.dayofweek
            weekday_avg = sales_data_copy.groupby('weekday')['è²©å£²å•†å“æ•°'].mean()
            weekday_names = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']
            weekday_str = ", ".join([f"{weekday_names[i]}:{weekday_avg.get(i, 0):.1f}" for i in range(7)])
        else:
            weekday_str = "ãƒ‡ãƒ¼ã‚¿ãªã—"
        
        st.write(f"""
        **å­£ç¯€æ€§è€ƒæ…®äºˆæ¸¬**
        1. æ›œæ—¥åˆ¥ã®å¹³å‡è²©å£²æ•°ã‚’è¨ˆç®—
        2. æœˆåˆ¥ã®å­£ç¯€ä¿‚æ•°ã‚’ç®—å‡º
        3. æ›œæ—¥ãƒ‘ã‚¿ãƒ¼ãƒ³ Ã— å­£ç¯€ä¿‚æ•°ã§æ—¥åˆ¥äºˆæ¸¬
        
        **æ›œæ—¥åˆ¥å¹³å‡**: {weekday_str}
        
        **è¨ˆç®—çµæœ**:
        - äºˆæ¸¬å¹³å‡æ—¥è²©: {avg_predicted:.1f}ä½“/æ—¥
        - å®Ÿç¸¾å¹³å‡ã¨ã®å·®: {avg_predicted - avg_daily:+.1f}ä½“/æ—¥ ({((avg_predicted/avg_daily)-1)*100:+.1f}%)
        """)
    
    elif "ç§»å‹•å¹³å‡" in method:
        # ç›´è¿‘30æ—¥ã®å¹³å‡
        recent_30 = sales_data.tail(30)['è²©å£²å•†å“æ•°'].mean() if len(sales_data) >= 30 else avg_daily
        
        st.write(f"""
        **ç§»å‹•å¹³å‡æ³•**
        1. ç›´è¿‘30æ—¥é–“ã®è²©å£²ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
        2. 30æ—¥é–“ã®å¹³å‡å€¤ã‚’åŸºæº–ã¨ã—ã¦äºˆæ¸¬
        
        **ç›´è¿‘30æ—¥å¹³å‡**: {recent_30:.1f}ä½“/æ—¥
        
        **è¨ˆç®—å¼**: äºˆæ¸¬æ—¥è²© = ç›´è¿‘30æ—¥å¹³å‡ = {recent_30:.1f}ä½“/æ—¥
        **äºˆæ¸¬ç·æ•°**: {recent_30:.1f} Ã— {forecast_days}æ—¥ = {recent_30 * forecast_days:.0f}ä½“
        """)
    
    elif "æŒ‡æ•°å¹³æ»‘" in method:
        alpha = 0.3  # å¹³æ»‘åŒ–ä¿‚æ•°
        recent_7 = sales_data.tail(7)['è²©å£²å•†å“æ•°'].mean() if len(sales_data) >= 7 else avg_daily
        
        st.write(f"""
        **æŒ‡æ•°å¹³æ»‘æ³•**
        1. ç›´è¿‘ã®ãƒ‡ãƒ¼ã‚¿ã‚’é‡è¦–ï¼ˆå¹³æ»‘åŒ–ä¿‚æ•° Î±={alpha}ï¼‰
        2. æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã»ã©é«˜ã„é‡ã¿ã§è¨ˆç®—
        
        **ç›´è¿‘7æ—¥å¹³å‡**: {recent_7:.1f}ä½“/æ—¥
        **å…¨æœŸé–“å¹³å‡**: {avg_daily:.1f}ä½“/æ—¥
        
        **è¨ˆç®—å¼**: äºˆæ¸¬ = Î±Ã—ç›´è¿‘ + (1-Î±)Ã—å…¨ä½“ = {alpha}Ã—{recent_7:.1f} + {1-alpha}Ã—{avg_daily:.1f} = {alpha*recent_7 + (1-alpha)*avg_daily:.1f}ä½“/æ—¥
        """)
    
    else:
        st.write(f"""
        **äºˆæ¸¬æ–¹æ³•**: {method}
        - å…¥åŠ›ãƒ‡ãƒ¼ã‚¿: {total_days}æ—¥é–“ã®å®Ÿç¸¾
        - äºˆæ¸¬æœŸé–“: {forecast_days}æ—¥é–“
        - äºˆæ¸¬å¹³å‡æ—¥è²©: {avg_predicted:.1f}ä½“/æ—¥
        """)


def display_comparison_results_v12(all_results: Dict[str, Tuple[pd.DataFrame, str]], forecast_days: int, sales_data: pd.DataFrame = None):
    """ã™ã¹ã¦ã®äºˆæ¸¬æ–¹æ³•ã®æ¯”è¼ƒçµæœã‚’è¡¨ç¤ºï¼ˆv12 ã‚¹ãƒãƒ›æœ€é©åŒ– + äºˆæ¸¬ç·æ•°ä¸€è¦§ï¼‰"""
    st.success("âœ… ã™ã¹ã¦ã®äºˆæ¸¬æ–¹æ³•ã§æ¯”è¼ƒå®Œäº†ï¼")
    
    # å„äºˆæ¸¬æ–¹æ³•ã®äºˆæ¸¬ç·æ•°ã‚’è¨ˆç®—
    method_totals = {}
    for method_name, (forecast, message) in all_results.items():
        raw_total = int(forecast['predicted'].sum())
        rounded_total = round_up_to_50(raw_total)
        avg_predicted = forecast['predicted'].mean()
        method_totals[method_name] = {
            'raw': raw_total,
            'rounded': rounded_total,
            'avg': avg_predicted
        }
    
    # ========== å„äºˆæ¸¬æ–¹æ³•ã®äºˆæ¸¬ç·æ•°ã‚’æ˜ç¢ºã«è¡¨ç¤º ==========
    st.write("### ğŸ“Š å„äºˆæ¸¬æ–¹æ³•ã®äºˆæ¸¬ç·æ•°ï¼ˆç™ºæ³¨æ¨å¥¨æ•°ï¼‰")
    
    # åˆ†ã‹ã‚Šã‚„ã™ã„ãƒªã‚¹ãƒˆå½¢å¼ã§è¡¨ç¤º
    st.markdown("---")
    for method_name, totals in method_totals.items():
        icon = "ğŸš€" if "Vertex" in method_name else "ğŸ“ˆ" if "å­£ç¯€" in method_name else "ğŸ“Š" if "ç§»å‹•" in method_name else "ğŸ“‰"
        short_name = method_name.replace("ï¼ˆçµ±è¨ˆï¼‰", "").replace("ï¼ˆæ¨å¥¨ï¼‰", "")
        st.markdown(f"""
        **{icon} {short_name}**: **{totals['rounded']:,}ä½“**ï¼ˆæ—¥è²© {totals['avg']:.1f}ä½“ã€ç”Ÿå€¤ {totals['raw']:,}ä½“ï¼‰
        """)
    st.markdown("---")
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã§å¤§ããè¡¨ç¤º
    num_methods = len(method_totals)
    cols = st.columns(num_methods)
    
    for i, (method_name, totals) in enumerate(method_totals.items()):
        icon = "ğŸš€" if "Vertex" in method_name else "ğŸ“ˆ" if "å­£ç¯€" in method_name else "ğŸ“Š" if "ç§»å‹•" in method_name else "ğŸ“‰"
        short_name = method_name.replace("ï¼ˆçµ±è¨ˆï¼‰", "").replace("ï¼ˆæ¨å¥¨ï¼‰", "")
        with cols[i]:
            st.metric(
                f"{icon} {short_name}",
                f"{totals['rounded']:,}ä½“",
                f"æ—¥è²© {totals['avg']:.1f}ä½“"
            )
    
    # è©³ç´°è¡¨
    with st.expander("ğŸ“‹ è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º", expanded=False):
        summary_rows = []
        for method_name, totals in method_totals.items():
            icon = "ğŸš€" if "Vertex" in method_name else "ğŸ“ˆ" if "å­£ç¯€" in method_name else "ğŸ“Š" if "ç§»å‹•" in method_name else "ğŸ“‰"
            summary_rows.append({
                'äºˆæ¸¬æ–¹æ³•': f"{icon} {method_name}",
                'äºˆæ¸¬ç·æ•°ï¼ˆç”Ÿå€¤ï¼‰': f"{totals['raw']:,}ä½“",
                'ç™ºæ³¨æ¨å¥¨æ•°ï¼ˆ50å€æ•°ï¼‰': f"{totals['rounded']:,}ä½“",
                'å¹³å‡æ—¥è²©': f"{totals['avg']:.1f}ä½“/æ—¥"
            })
        
        summary_df = pd.DataFrame(summary_rows)
        st.dataframe(summary_df, use_container_width=True, hide_index=True)
    
    # çµ±è¨ˆã‚µãƒãƒªãƒ¼
    all_rounded = [t['rounded'] for t in method_totals.values()]
    all_raw = [t['raw'] for t in method_totals.values()]
    
    st.write("### ğŸ“ˆ äºˆæ¸¬å€¤ã®çµ±è¨ˆ")
    
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("ğŸ“‰ æœ€å°", f"{min(all_rounded):,}ä½“")
    col2.metric("ğŸ“ˆ æœ€å¤§", f"{max(all_rounded):,}ä½“")
    col3.metric("ğŸ“Š å¹³å‡", f"{round_up_to_50(int(sum(all_raw) / len(all_raw))):,}ä½“")
    col4.metric("ğŸ“Š ä¸­å¤®å€¤", f"{round_up_to_50(int(sorted(all_raw)[len(all_raw)//2])):,}ä½“")
    
    # å·®åˆ†ã®è¡¨ç¤º
    if len(all_rounded) >= 2:
        diff = max(all_rounded) - min(all_rounded)
        diff_pct = (max(all_raw) - min(all_raw)) / min(all_raw) * 100 if min(all_raw) > 0 else 0
        st.info(f"ğŸ“ **äºˆæ¸¬å€¤ã®å¹…**: æœ€å°ã€œæœ€å¤§ã§ **{diff:,}ä½“** ã®å·®ï¼ˆ{diff_pct:.1f}%ï¼‰")
    
    method_colors = {
        'Vertex AI': '#4285F4',
        'å­£ç¯€æ€§è€ƒæ…®': '#4CAF50',
        'ç§»å‹•å¹³å‡æ³•': '#1E88E5',
        'æŒ‡æ•°å¹³æ»‘æ³•': '#FF9800'
    }
    
    # æ¯”è¼ƒã‚°ãƒ©ãƒ•ï¼ˆã‚¹ãƒãƒ›æœ€é©åŒ–ï¼‰
    st.write("### ğŸ“ˆ æ—¥åˆ¥äºˆæ¸¬æ¯”è¼ƒã‚°ãƒ©ãƒ•")
    
    fig = go.Figure()
    
    for method_name, (forecast, message) in all_results.items():
        fig.add_trace(go.Scatter(
            x=forecast['date'],
            y=forecast['predicted'],
            mode='lines',
            name=method_name,
            line=dict(color=method_colors.get(method_name, '#666666'), width=2)
        ))
    
    layout = get_mobile_chart_layout('äºˆæ¸¬æ–¹æ³•åˆ¥ã®æ—¥åˆ¥äºˆæ¸¬æ¯”è¼ƒ', height=300)
    layout['xaxis_title'] = 'æ—¥ä»˜'
    layout['yaxis_title'] = 'äºˆæ¸¬è²©å£²æ•°ï¼ˆä½“ï¼‰'
    fig.update_layout(**layout)
    
    st.plotly_chart(fig, use_container_width=True, config=get_mobile_chart_config())
    
    # æ¨å¥¨
    if 'Vertex AI' in all_results:
        st.info("ğŸ’¡ **ãŠã™ã™ã‚**: Vertex AI AutoML Forecastingã¯æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã§å­¦ç¿’æ¸ˆã¿ã®ãŸã‚ã€æœ€ã‚‚ç²¾åº¦ãŒé«˜ã„å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚")
    else:
        st.info("ğŸ’¡ **ãŠã™ã™ã‚**: å­£ç¯€æ€§è€ƒæ…®ã¯æœˆåˆ¥ãƒ»æ›œæ—¥åˆ¥ã®å‚¾å‘ã‚’è€ƒæ…®ã™ã‚‹ãŸã‚ã€çµ±è¨ˆãƒ¢ãƒ‡ãƒ«ã®ä¸­ã§ã¯æœ€ã‚‚ç²¾åº¦ãŒé«˜ã„å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚")
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜ï¼ˆVertex AIãŒã‚ã‚Œã°ãã‚Œã€ãªã‘ã‚Œã°å­£ç¯€æ€§è€ƒæ…®ï¼‰
    if 'Vertex AI' in all_results:
        st.session_state.forecast_data = all_results['Vertex AI'][0]
        st.session_state.forecast_total = method_totals['Vertex AI']['rounded']
    elif 'å­£ç¯€æ€§è€ƒæ…®' in all_results:
        st.session_state.forecast_data = all_results['å­£ç¯€æ€§è€ƒæ…®'][0]
        st.session_state.forecast_total = method_totals['å­£ç¯€æ€§è€ƒæ…®']['rounded']
    
    st.session_state.forecast_results = {k: v[0] for k, v in all_results.items()}


def render_individual_analysis(start_date: date, end_date: date):
    """å€‹åˆ¥åˆ†æãƒ¢ãƒ¼ãƒ‰ï¼ˆã‚°ãƒ«ãƒ¼ãƒ—å¯¾å¿œãƒ»å¹´æ¬¡æ¯”è¼ƒãƒ»éƒµé€ã®ã¿å•†å“å¯¾å¿œï¼‰"""
    st.markdown('<p class="section-header">â‘¢ å€‹åˆ¥å£²ä¸Šåˆ†æ</p>', unsafe_allow_html=True)
    
    if not st.session_state.selected_products:
        st.info("æˆä¸å“ã‚’é¸æŠã™ã‚‹ã¨ã€ã“ã“ã«å£²ä¸ŠãŒè¡¨ç¤ºã•ã‚Œã¾ã™")
        return
    
    df_items = st.session_state.data_loader.load_item_sales()
    
    # éƒµé€ãƒ‡ãƒ¼ã‚¿çµ±åˆã‚ªãƒ—ã‚·ãƒ§ãƒ³
    mail_order_enabled = hasattr(config, 'MAIL_ORDER_SPREADSHEET_ID') and config.MAIL_ORDER_SPREADSHEET_ID
    include_mail_orders = False
    
    if mail_order_enabled:
        include_mail_orders = st.checkbox(
            "ğŸ“¬ éƒµé€æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚ã‚‹",
            value=True,
            help="Googleãƒ•ã‚©ãƒ¼ãƒ ã‹ã‚‰ã®éƒµé€ä¾é ¼ã‚‚éœ€è¦ã«å«ã‚ã¾ã™",
            key="individual_include_mail"
        )
    
    # Airãƒ¬ã‚¸ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    if not df_items.empty:
        mask = (df_items['date'] >= pd.Timestamp(start_date)) & (df_items['date'] <= pd.Timestamp(end_date))
        df_filtered = df_items[mask]
    else:
        df_filtered = pd.DataFrame()
    
    # éƒµé€ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    df_mail = pd.DataFrame()
    if include_mail_orders or mail_order_enabled:
        df_mail = st.session_state.data_loader.get_mail_order_summary()
    
    # ã‚°ãƒ«ãƒ¼ãƒ—æ§‹æˆã‚’å–å¾—
    groups_dict = {}  # {ã‚°ãƒ«ãƒ¼ãƒ—ç•ªå·: [å•†å“ãƒªã‚¹ãƒˆ]}
    for product in st.session_state.selected_products:
        group_num = st.session_state.product_groups.get(product, 0)
        if group_num not in groups_dict:
            groups_dict[group_num] = []
        groups_dict[group_num].append(product)
    
    individual_data = {}
    individual_counts = {}
    
    # åˆ†æå˜ä½ã‚’æ§‹ç¯‰ï¼ˆã‚°ãƒ«ãƒ¼ãƒ—0ã®å•†å“ã¯å€‹åˆ¥ã€ãã‚Œä»¥å¤–ã¯ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ï¼‰
    analysis_units = []
    for group_num, products in sorted(groups_dict.items()):
        if group_num == 0:
            # å˜ç‹¬ã®å•†å“ã¯å€‹åˆ¥ã«åˆ†æ
            for product in products:
                analysis_units.append({
                    'name': product,
                    'products': [product],
                    'is_group': False
                })
        else:
            # ã‚°ãƒ«ãƒ¼ãƒ—ã¯ã¾ã¨ã‚ã¦åˆ†æ
            analysis_units.append({
                'name': f"ã‚°ãƒ«ãƒ¼ãƒ—{group_num}: {', '.join(products)}",
                'products': products,
                'is_group': True
            })
    
    # å„åˆ†æå˜ä½ã®ãƒ‡ãƒ¼ã‚¿ã‚’é›†è¨ˆ
    for unit in analysis_units:
        unit_name = unit['name']
        products_in_unit = unit['products']
        
        airregi_count = 0
        mail_order_count = 0
        df_agg_combined = pd.DataFrame()
        
        for product in products_in_unit:
            # Airãƒ¬ã‚¸ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’è©¦ã¿ã‚‹
            original_names = []
            if st.session_state.normalizer:
                original_names = st.session_state.normalizer.get_all_original_names([product])
            
            # Airãƒ¬ã‚¸ãƒ‡ãƒ¼ã‚¿ã®é›†è¨ˆ
            df_agg_airregi = pd.DataFrame()
            if not df_filtered.empty and original_names:
                df_agg_airregi = aggregate_by_products(df_filtered, original_names, aggregate=True)
            
            product_airregi_count = int(df_agg_airregi['è²©å£²å•†å“æ•°'].sum()) if not df_agg_airregi.empty else 0
            airregi_count += product_airregi_count
            
            # éƒµé€ãƒ‡ãƒ¼ã‚¿ã®é›†è¨ˆ
            df_mail_matched = pd.DataFrame()
            if (include_mail_orders or (product_airregi_count == 0 and mail_order_enabled)) and not df_mail.empty:
                matched_rows = []
                
                for _, mail_row in df_mail.iterrows():
                    mail_product = str(mail_row['å•†å“å']).strip()
                    
                    # å•†å“åãŒå®Œå…¨ä¸€è‡´ï¼ˆéƒµé€ã‚·ãƒ¼ãƒˆã®ã¿ã®å•†å“ã®å ´åˆï¼‰
                    if mail_product == product:
                        matched_rows.append(mail_row.copy())
                    # Airãƒ¬ã‚¸ã®å•†å“åã¨ãƒãƒƒãƒãƒ³ã‚°
                    elif original_names:
                        matched_name = match_mail_product_to_airregi(mail_product, original_names)
                        if matched_name:
                            new_row = mail_row.copy()
                            new_row['å•†å“å'] = matched_name
                            matched_rows.append(new_row)
                
                if matched_rows:
                    df_mail_matched = pd.DataFrame(matched_rows)
                    if 'date' in df_mail_matched.columns:
                        df_mail_matched['date'] = pd.to_datetime(df_mail_matched['date'], errors='coerce')
                        mail_mask = (df_mail_matched['date'] >= pd.Timestamp(start_date)) & \
                                   (df_mail_matched['date'] <= pd.Timestamp(end_date))
                        df_mail_matched = df_mail_matched[mail_mask]
                    product_mail_count = int(df_mail_matched['è²©å£²å•†å“æ•°'].sum()) if not df_mail_matched.empty else 0
                    mail_order_count += product_mail_count
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
            if not df_agg_airregi.empty:
                if df_agg_combined.empty:
                    df_agg_combined = df_agg_airregi.copy()
                else:
                    df_agg_combined = pd.concat([df_agg_combined, df_agg_airregi], ignore_index=True)
            
            if not df_mail_matched.empty and (include_mail_orders or product_airregi_count == 0):
                required_cols = ['date', 'è²©å£²å•†å“æ•°', 'è²©å£²ç·å£²ä¸Š', 'è¿”å“å•†å“æ•°']
                available_cols = [c for c in required_cols if c in df_mail_matched.columns]
                if 'date' in available_cols and 'è²©å£²å•†å“æ•°' in available_cols:
                    df_mail_for_merge = df_mail_matched[available_cols].copy()
                    if 'è²©å£²ç·å£²ä¸Š' not in df_mail_for_merge.columns:
                        df_mail_for_merge['è²©å£²ç·å£²ä¸Š'] = 0
                    if 'è¿”å“å•†å“æ•°' not in df_mail_for_merge.columns:
                        df_mail_for_merge['è¿”å“å•†å“æ•°'] = 0
                    if df_agg_combined.empty:
                        df_agg_combined = df_mail_for_merge.copy()
                    else:
                        df_agg_combined = pd.concat([df_agg_combined, df_mail_for_merge], ignore_index=True)
        
        # æ—¥ä»˜ã”ã¨ã«é›†ç´„
        if not df_agg_combined.empty:
            df_agg = df_agg_combined.groupby('date').agg({
                'è²©å£²å•†å“æ•°': 'sum',
                'è²©å£²ç·å£²ä¸Š': 'sum',
                'è¿”å“å•†å“æ•°': 'sum'
            }).reset_index()
            df_agg = df_agg.sort_values('date').reset_index(drop=True)
            individual_data[unit_name] = df_agg
            individual_counts[unit_name] = {'airregi': airregi_count, 'mail': mail_order_count}
    
    st.session_state.individual_sales_data = individual_data
    
    # å„åˆ†æå˜ä½ã®çµæœã‚’è¡¨ç¤º
    for unit_name, df_agg in individual_data.items():
        counts = individual_counts.get(unit_name, {'airregi': 0, 'mail': 0})
        total_qty = counts['airregi'] + counts['mail']
        
        with st.expander(f"ğŸ“¦ **{unit_name}**ï¼ˆåˆè¨ˆ: {total_qty:,}ä½“ï¼‰", expanded=True):
            total_sales = df_agg['è²©å£²ç·å£²ä¸Š'].sum()
            period_days = (end_date - start_date).days + 1
            avg_daily = total_qty / period_days if period_days > 0 else 0
            
            # å¹³æ—¥ãƒ»ä¼‘æ—¥ã®å¹³å‡ã‚’è¨ˆç®—
            df_agg['weekday'] = pd.to_datetime(df_agg['date']).dt.dayofweek
            df_weekday = df_agg[df_agg['weekday'] < 5]
            df_weekend = df_agg[df_agg['weekday'] >= 5]
            avg_weekday = df_weekday['è²©å£²å•†å“æ•°'].mean() if not df_weekday.empty else 0
            avg_weekend = df_weekend['è²©å£²å•†å“æ•°'].mean() if not df_weekend.empty else 0
            
            # åŸºæœ¬ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("ğŸ›’ è²©å£²æ•°é‡åˆè¨ˆ", f"{total_qty:,}ä½“")
            col2.metric("ğŸ’° å£²ä¸Šåˆè¨ˆ", f"Â¥{total_sales:,.0f}")
            col3.metric("ğŸ“ˆ å¹³å‡æ—¥è²©", f"{avg_daily:.1f}ä½“/æ—¥")
            col4.metric("ğŸ“… æœŸé–“", f"{period_days}æ—¥é–“")
            
            # ã‚¨ã‚¢ãƒ¬ã‚¸ã¨éƒµé€ã®å†…è¨³
            col5, col6, col7, col8 = st.columns(4)
            col5.metric("ğŸª Airãƒ¬ã‚¸", f"{counts['airregi']:,}ä½“")
            col6.metric("ğŸ“¬ éƒµé€", f"{counts['mail']:,}ä½“")
            if avg_weekday > 0:
                ratio = avg_weekend / avg_weekday
                col7.metric("ğŸ“Š ä¼‘æ—¥/å¹³æ—¥æ¯”", f"{ratio:.2f}å€")
            
            # ========== å¹´æ¬¡æ¯”è¼ƒï¼ˆå€‹åˆ¥ãƒ¢ãƒ¼ãƒ‰ç”¨ï¼‰ ==========
            render_individual_year_comparison(df_agg, unit_name, start_date, end_date, total_qty)
    
    render_individual_forecast_section()
    render_delivery_section()


def render_individual_year_comparison(df_agg: pd.DataFrame, unit_name: str, start_date: date, end_date: date, current_total: int):
    """å€‹åˆ¥åˆ†æãƒ¢ãƒ¼ãƒ‰ç”¨ã®å¹´æ¬¡æ¯”è¼ƒ"""
    
    with st.expander("ğŸ“Š å¹´æ¬¡æ¯”è¼ƒ", expanded=False):
        if df_agg.empty:
            st.warning("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        df_all = df_agg.copy()
        df_all['date'] = pd.to_datetime(df_all['date'])
        df_all['å¹´'] = df_all['date'].dt.year
        
        yearly = df_all.groupby('å¹´').agg({
            'è²©å£²å•†å“æ•°': 'sum',
            'è²©å£²ç·å£²ä¸Š': 'sum'
        }).reset_index()
        
        if len(yearly) < 1:
            st.info("å¹´æ¬¡æ¯”è¼ƒã«ã¯è¤‡æ•°å¹´ã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™")
            return
        
        # å‰å¹´æ¯”ã‚’è¨ˆç®—
        yearly['å‰å¹´æ¯”'] = yearly['è²©å£²å•†å“æ•°'].pct_change() * 100
        yearly['å¢—æ¸›æ•°'] = yearly['è²©å£²å•†å“æ•°'].diff()
        
        # è¡¨å½¢å¼ã§è¡¨ç¤º
        st.write("**ğŸ“‹ å¹´åˆ¥æ¯”è¼ƒè¡¨**")
        
        table_data = []
        for idx, row in yearly.iterrows():
            year = int(row['å¹´'])
            qty = int(row['è²©å£²å•†å“æ•°'])
            diff = row['å¢—æ¸›æ•°']
            pct = row['å‰å¹´æ¯”']
            
            if pd.notna(diff):
                diff_str = f"{int(diff):+,}ä½“"
                pct_str = f"{pct:+.1f}%"
                eval_str = "ğŸ“ˆ å¢—åŠ " if diff > 0 else ("ğŸ“‰ æ¸›å°‘" if diff < 0 else "â¡ï¸ åŒã˜")
            else:
                diff_str = "-"
                pct_str = "-"
                eval_str = "-"
            
            table_data.append({
                'å¹´': f"{year}å¹´",
                'è²©å£²æ•°': f"{qty:,}ä½“",
                'å‰å¹´æ¯”ï¼ˆæ•°ï¼‰': diff_str,
                'å‰å¹´æ¯”ï¼ˆ%ï¼‰': pct_str,
                'è©•ä¾¡': eval_str
            })
        
        display_df = pd.DataFrame(table_data)
        st.dataframe(display_df, use_container_width=True, hide_index=True)
        
        # ç›´è¿‘ã®å¹´æ¬¡æ¯”è¼ƒ
        if len(yearly) >= 2:
            latest = yearly.iloc[-1]
            prev = yearly.iloc[-2]
            diff = int(latest['è²©å£²å•†å“æ•°'] - prev['è²©å£²å•†å“æ•°'])
            diff_pct = latest['å‰å¹´æ¯”']
            
            if diff > 0:
                st.success(f"âœ… {int(latest['å¹´'])}å¹´ã¯{int(prev['å¹´'])}å¹´ã‚ˆã‚Š **{diff:,}ä½“** å¢—åŠ ï¼ˆ{diff_pct:+.1f}%ï¼‰")
            elif diff < 0:
                st.warning(f"âš ï¸ {int(latest['å¹´'])}å¹´ã¯{int(prev['å¹´'])}å¹´ã‚ˆã‚Š **{abs(diff):,}ä½“** æ¸›å°‘ï¼ˆ{diff_pct:.1f}%ï¼‰")
            else:
                st.info(f"â¡ï¸ {int(latest['å¹´'])}å¹´ã¯{int(prev['å¹´'])}å¹´ã¨åŒã˜è²©å£²æ•°")


def render_individual_forecast_section():
    """å€‹åˆ¥äºˆæ¸¬ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆæœŸé–“æŒ‡å®šå¯¾å¿œï¼‰"""
    st.markdown('<p class="section-header">â‘£ å€‹åˆ¥éœ€è¦äºˆæ¸¬</p>', unsafe_allow_html=True)
    
    if not st.session_state.individual_sales_data:
        st.info("å£²ä¸Šãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã¨ã€éœ€è¦äºˆæ¸¬ãŒã§ãã¾ã™")
        return
    
    col1, col2 = st.columns(2)
    
    with col1:
        forecast_mode = st.radio(
            "äºˆæ¸¬æœŸé–“ã®æŒ‡å®šæ–¹æ³•",
            ["æ—¥æ•°ã§æŒ‡å®š", "æœŸé–“ã§æŒ‡å®š"],
            horizontal=True,
            key="individual_forecast_mode",
            help="ã€ŒæœŸé–“ã§æŒ‡å®šã€ã¯æœŸé–“é™å®šå“ã®äºˆæ¸¬ã«ä¾¿åˆ©ã§ã™"
        )
    
    with col2:
        available_methods = get_available_forecast_methods()
        # å€‹åˆ¥ãƒ¢ãƒ¼ãƒ‰ã§ã‚‚ã€Œã™ã¹ã¦ã®æ–¹æ³•ã§æ¯”è¼ƒã€ã‚’ä½¿ç”¨å¯èƒ½ã«
        
        method = st.selectbox(
            "äºˆæ¸¬æ–¹æ³•",
            available_methods,
            index=0,
            key="individual_forecast_method"
        )
    
    # äºˆæ¸¬æœŸé–“ã®è¨­å®š
    if forecast_mode == "æ—¥æ•°ã§æŒ‡å®š":
        forecast_days = st.slider("äºˆæ¸¬æ—¥æ•°", 30, 365, 180, key="individual_forecast_days")
        forecast_start_date = None
        forecast_end_date = None
    else:
        # æœŸé–“æŒ‡å®šUIï¼ˆåˆ†ææœŸé–“ã¨åŒã˜ã‚¹ã‚¿ã‚¤ãƒ«ï¼‰
        today = date.today()
        default_start = today + timedelta(days=1)
        default_end = today + timedelta(days=180)
        
        st.write("**äºˆæ¸¬æœŸé–“æŒ‡å®š**")
        col_s1, col_s2, col_s3, col_e1, col_e2, col_e3 = st.columns([1, 1, 1, 1, 1, 1])
        
        with col_s1:
            start_year = st.selectbox(
                "äºˆæ¸¬é–‹å§‹å¹´",
                list(range(2025, 2028)),
                index=list(range(2025, 2028)).index(default_start.year) if default_start.year in range(2025, 2028) else 0,
                key="ind_forecast_start_year"
            )
        with col_s2:
            start_month = st.selectbox(
                "äºˆæ¸¬é–‹å§‹æœˆ",
                list(range(1, 13)),
                index=default_start.month - 1,
                format_func=lambda x: f"{x}æœˆ",
                key="ind_forecast_start_month"
            )
        with col_s3:
            max_day_start = calendar.monthrange(start_year, start_month)[1]
            start_day = st.selectbox(
                "äºˆæ¸¬é–‹å§‹æ—¥",
                list(range(1, max_day_start + 1)),
                index=min(default_start.day - 1, max_day_start - 1),
                format_func=lambda x: f"{x}æ—¥",
                key="ind_forecast_start_day"
            )
        
        with col_e1:
            end_year = st.selectbox(
                "äºˆæ¸¬çµ‚äº†å¹´",
                list(range(2025, 2028)),
                index=list(range(2025, 2028)).index(default_end.year) if default_end.year in range(2025, 2028) else 0,
                key="ind_forecast_end_year"
            )
        with col_e2:
            end_month = st.selectbox(
                "äºˆæ¸¬çµ‚äº†æœˆ",
                list(range(1, 13)),
                index=default_end.month - 1,
                format_func=lambda x: f"{x}æœˆ",
                key="ind_forecast_end_month"
            )
        with col_e3:
            max_day_end = calendar.monthrange(end_year, end_month)[1]
            end_day = st.selectbox(
                "äºˆæ¸¬çµ‚äº†æ—¥",
                list(range(1, max_day_end + 1)),
                index=min(default_end.day - 1, max_day_end - 1),
                format_func=lambda x: f"{x}æ—¥",
                key="ind_forecast_end_day"
            )
        
        forecast_start_date = date(start_year, start_month, start_day)
        forecast_end_date = date(end_year, end_month, end_day)
        
        if forecast_end_date <= forecast_start_date:
            st.error("âš ï¸ çµ‚äº†æ—¥ã¯é–‹å§‹æ—¥ã‚ˆã‚Šå¾Œã«ã—ã¦ãã ã•ã„")
            return
        
        forecast_days = (forecast_end_date - forecast_start_date).days + 1
        st.info(f"ğŸ“… äºˆæ¸¬æœŸé–“: {forecast_start_date.strftime('%Yå¹´%mæœˆ%dæ—¥')} ã€œ {forecast_end_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}ï¼ˆ{forecast_days}æ—¥é–“ï¼‰")
    
    method_info = FORECAST_METHODS[method]
    st.markdown(f"""
    <div class="analysis-card">
        <strong>{method_info['icon']} {method}</strong><br>
        {method_info['description']}
    </div>
    """, unsafe_allow_html=True)
    
    if st.button("ğŸ”® å€‹åˆ¥ã«éœ€è¦äºˆæ¸¬ã‚’å®Ÿè¡Œ", type="primary", use_container_width=True, key="individual_forecast_btn"):
        with st.spinner("äºˆæ¸¬ä¸­..."):
            # ã€Œã™ã¹ã¦ã®æ–¹æ³•ã§æ¯”è¼ƒã€ãŒé¸ã°ã‚ŒãŸå ´åˆ
            if method == "ğŸ”„ ã™ã¹ã¦ã®æ–¹æ³•ã§æ¯”è¼ƒ":
                # ãƒãƒˆãƒªãƒƒã‚¯ã‚¹å½¢å¼ã§çµæœã‚’ä¿å­˜: {å•†å“å: {äºˆæ¸¬æ–¹æ³•: äºˆæ¸¬æ•°}}
                matrix_results = {}
                method_names = []
                
                for product, sales_data in st.session_state.individual_sales_data.items():
                    try:
                        # ã™ã¹ã¦ã®æ–¹æ³•ã§äºˆæ¸¬
                        method_results = forecast_all_methods_with_vertex_ai(sales_data, forecast_days, product)
                        
                        matrix_results[product] = {}
                        for method_name, (forecast_df, message) in method_results.items():
                            if method_name not in method_names:
                                method_names.append(method_name)
                            
                            raw_total = int(forecast_df['predicted'].sum())
                            rounded_total = round_up_to_50(raw_total)
                            matrix_results[product][method_name] = rounded_total
                    except Exception as e:
                        st.warning(f"{product}ã®äºˆæ¸¬ã«å¤±æ•—: {e}")
                
                if matrix_results:
                    st.success("âœ… ã™ã¹ã¦ã®äºˆæ¸¬æ–¹æ³•ã§æ¯”è¼ƒå®Œäº†ï¼")
                    
                    # ========== ãƒãƒˆãƒªãƒƒã‚¯ã‚¹å½¢å¼ã®è¡¨ã‚’ä½œæˆ ==========
                    st.write("### ğŸ“Š å•†å“Ã—äºˆæ¸¬æ–¹æ³• ãƒãƒˆãƒªãƒƒã‚¯ã‚¹è¡¨")
                    
                    # è¡¨ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰
                    table_data = []
                    method_totals = {m: 0 for m in method_names}
                    
                    for product, methods in matrix_results.items():
                        row = {'å•†å“å': product}
                        for method_name in method_names:
                            value = methods.get(method_name, 0)
                            row[method_name] = f"{value:,}ä½“"
                            method_totals[method_name] += value
                        table_data.append(row)
                    
                    # åˆè¨ˆè¡Œã‚’è¿½åŠ 
                    total_row = {'å•†å“å': '**åˆè¨ˆ**'}
                    for method_name in method_names:
                        total_row[method_name] = f"**{method_totals[method_name]:,}ä½“**"
                    table_data.append(total_row)
                    
                    # DataFrameã§è¡¨ç¤º
                    df_matrix = pd.DataFrame(table_data)
                    st.dataframe(df_matrix, use_container_width=True, hide_index=True)
                    
                    # ========== äºˆæ¸¬æ–¹æ³•ã”ã¨ã®åˆè¨ˆã‚’ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã§è¡¨ç¤º ==========
                    st.write("### ğŸ“ˆ äºˆæ¸¬æ–¹æ³•åˆ¥ åˆè¨ˆ")
                    
                    num_methods = len(method_names)
                    cols = st.columns(min(num_methods, 4))
                    for i, method_name in enumerate(method_names):
                        icon = "ğŸš€" if "Vertex" in method_name else "ğŸ“ˆ" if "å­£ç¯€" in method_name else "ğŸ“Š" if "ç§»å‹•" in method_name else "ğŸ“‰"
                        short_name = method_name.replace("ï¼ˆçµ±è¨ˆï¼‰", "").replace("ï¼ˆæ¨å¥¨ï¼‰", "")
                        with cols[i % 4]:
                            st.metric(f"{icon} {short_name}", f"{method_totals[method_name]:,}ä½“")
                    
                    # session_stateã«ä¿å­˜
                    st.session_state.individual_all_methods_results = matrix_results
                    
                    # ç´å“è¨ˆç”»ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¨­å®šï¼ˆå­£ç¯€æ€§è€ƒæ…®ã‚’å„ªå…ˆï¼‰
                    preferred_method = 'å­£ç¯€æ€§è€ƒæ…®' if 'å­£ç¯€æ€§è€ƒæ…®' in method_names else method_names[0]
                    
                    # individual_forecast_resultsã‚’è¨­å®šï¼ˆç´å“è¨ˆç”»ã§ä½¿ç”¨ï¼‰
                    forecast_results_for_delivery = []
                    for product, methods in matrix_results.items():
                        forecast_results_for_delivery.append({
                            'product': product,
                            'forecast': None,  # æ—¥åˆ¥ãƒ‡ãƒ¼ã‚¿ã¯ç„¡ã„ãŒã€åˆè¨ˆã¯ä½¿ãˆã‚‹
                            'raw_total': methods.get(preferred_method, 0),
                            'rounded_total': methods.get(preferred_method, 0),
                            'avg_predicted': methods.get(preferred_method, 0) / forecast_days if forecast_days > 0 else 0,
                            'method_message': f'{preferred_method}ï¼ˆã™ã¹ã¦ã®æ–¹æ³•ã§æ¯”è¼ƒã‹ã‚‰ï¼‰'
                        })
                    
                    st.session_state.individual_forecast_results = forecast_results_for_delivery
                    
                    # å­£ç¯€æ€§è€ƒæ…®ã®çµæœã‚’ä¿å­˜ï¼ˆç´å“è¨ˆç”»ç”¨ï¼‰
                    if 'å­£ç¯€æ€§è€ƒæ…®' in method_totals:
                        st.session_state.forecast_total = method_totals['å­£ç¯€æ€§è€ƒæ…®']
                    elif method_totals:
                        first_method = method_names[0]
                        st.session_state.forecast_total = method_totals[first_method]
                    
                    st.session_state.last_forecast_method = f'{preferred_method}ï¼ˆã™ã¹ã¦ã®æ–¹æ³•ã§æ¯”è¼ƒï¼‰'
                    st.rerun()
            else:
                # é€šå¸¸ã®å˜ä¸€äºˆæ¸¬æ–¹æ³•ã®å ´åˆ
                results = []
                
                for product, sales_data in st.session_state.individual_sales_data.items():
                    try:
                        forecast, method_message = forecast_with_vertex_ai(sales_data, forecast_days, method, product)
                        
                        if forecast is not None and not forecast.empty:
                            raw_total = int(forecast['predicted'].sum())
                            rounded_total = round_up_to_50(raw_total)
                            avg_predicted = forecast['predicted'].mean()
                            
                            results.append({
                                'product': product,
                                'forecast': forecast,
                                'raw_total': raw_total,
                                'rounded_total': rounded_total,
                                'avg_predicted': avg_predicted,
                                'method_message': method_message
                            })
                    except Exception as e:
                        st.warning(f"{product}ã®äºˆæ¸¬ã«å¤±æ•—: {e}")
                
                if results:
                    # ç´å“è¨ˆç”»ã§ä½¿ãˆã‚‹ã‚ˆã†ã«session_stateã«ä¿å­˜
                    if len(results) == 1:
                        st.session_state.forecast_data = results[0]['forecast']
                    else:
                        # è¤‡æ•°å•†å“ã®å ´åˆã¯æ—¥ä»˜ã”ã¨ã«åˆç®—
                        combined_forecast = results[0]['forecast'].copy()
                        combined_forecast = combined_forecast.rename(columns={'predicted': 'predicted_sum'})
                        
                        for r in results[1:]:
                            merged = combined_forecast.merge(
                                r['forecast'][['date', 'predicted']], 
                                on='date', 
                                how='outer'
                            )
                            merged['predicted_sum'] = merged['predicted_sum'].fillna(0) + merged['predicted'].fillna(0)
                            merged = merged.drop(columns=['predicted'])
                            combined_forecast = merged
                        
                        combined_forecast = combined_forecast.rename(columns={'predicted_sum': 'predicted'})
                        st.session_state.forecast_data = combined_forecast
                    
                    total_all = sum(r['rounded_total'] for r in results)
                    st.session_state.forecast_total = total_all
                    st.session_state.last_forecast_method = results[0]['method_message'] if results else ""
                    st.session_state.individual_forecast_results = results  # çµæœã‚’ä¿å­˜
                    st.rerun()  # ç´å“ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ›´æ–°ã™ã‚‹ãŸã‚å†æç”»
    
    # äºˆæ¸¬çµæœã®è¡¨ç¤ºï¼ˆsession_stateã‹ã‚‰ï¼‰
    # ã€Œã™ã¹ã¦ã®æ–¹æ³•ã§æ¯”è¼ƒã€ã®ãƒãƒˆãƒªãƒƒã‚¯ã‚¹çµæœãŒã‚ã‚‹å ´åˆ
    if st.session_state.get('individual_all_methods_results'):
        matrix_results = st.session_state.individual_all_methods_results
        method_names = []
        for product_methods in matrix_results.values():
            for method_name in product_methods.keys():
                if method_name not in method_names:
                    method_names.append(method_name)
        
        st.success("âœ… ã™ã¹ã¦ã®äºˆæ¸¬æ–¹æ³•ã§æ¯”è¼ƒå®Œäº†ï¼")
        
        # ãƒãƒˆãƒªãƒƒã‚¯ã‚¹å½¢å¼ã®è¡¨ã‚’ä½œæˆ
        st.write("### ğŸ“Š å•†å“Ã—äºˆæ¸¬æ–¹æ³• ãƒãƒˆãƒªãƒƒã‚¯ã‚¹è¡¨")
        
        table_data = []
        method_totals = {m: 0 for m in method_names}
        
        for product, methods in matrix_results.items():
            row = {'å•†å“å': product}
            for method_name in method_names:
                value = methods.get(method_name, 0)
                row[method_name] = f"{value:,}ä½“"
                method_totals[method_name] += value
            table_data.append(row)
        
        # åˆè¨ˆè¡Œã‚’è¿½åŠ 
        total_row = {'å•†å“å': '**åˆè¨ˆ**'}
        for method_name in method_names:
            total_row[method_name] = f"**{method_totals[method_name]:,}ä½“**"
        table_data.append(total_row)
        
        df_matrix = pd.DataFrame(table_data)
        st.dataframe(df_matrix, use_container_width=True, hide_index=True)
        
        # äºˆæ¸¬æ–¹æ³•ã”ã¨ã®åˆè¨ˆã‚’ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã§è¡¨ç¤º
        st.write("### ğŸ“ˆ äºˆæ¸¬æ–¹æ³•åˆ¥ åˆè¨ˆ")
        
        num_methods = len(method_names)
        cols = st.columns(min(num_methods, 4))
        for i, method_name in enumerate(method_names):
            icon = "ğŸš€" if "Vertex" in method_name else "ğŸ“ˆ" if "å­£ç¯€" in method_name else "ğŸ“Š" if "ç§»å‹•" in method_name else "ğŸ“‰"
            short_name = method_name.replace("ï¼ˆçµ±è¨ˆï¼‰", "").replace("ï¼ˆæ¨å¥¨ï¼‰", "")
            with cols[i % 4]:
                st.metric(f"{icon} {short_name}", f"{method_totals[method_name]:,}ä½“")
    
    # é€šå¸¸ã®äºˆæ¸¬çµæœãŒã‚ã‚‹å ´åˆ
    elif 'individual_forecast_results' in st.session_state and st.session_state.individual_forecast_results:
        results = st.session_state.individual_forecast_results
        st.success(f"âœ… {len(results)}ä»¶ã®æˆä¸å“ã®äºˆæ¸¬ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        
        summary_df = pd.DataFrame([
            {
                'æˆä¸å“': r['product'],
                'äºˆæ¸¬ç·æ•°': f"{r['rounded_total']:,}ä½“",
                'å¹³å‡æ—¥è²©': f"{r['avg_predicted']:.1f}ä½“/æ—¥",
                'ç™ºæ³¨æ¨å¥¨æ•°ï¼ˆ50å€æ•°ï¼‰': r['rounded_total']
            }
            for r in results
        ])
        st.dataframe(summary_df, use_container_width=True, hide_index=True)
        
        total_all = sum(r['rounded_total'] for r in results)
        st.metric("ğŸ“¦ å…¨ä½“ã®äºˆæ¸¬ç·æ•°", f"{total_all:,}ä½“")


def render_delivery_section():
    """ç´å“è¨ˆç”»ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆå€‹åˆ¥ãƒ¢ãƒ¼ãƒ‰å¯¾å¿œï¼‰"""
    st.markdown('<p class="section-header">â‘¤ ç´å“è¨ˆç”»ã‚’ç«‹ã¦ã‚‹</p>', unsafe_allow_html=True)
    
    # äºˆæ¸¬çµæœãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    individual_results = st.session_state.get('individual_forecast_results', [])
    forecast = st.session_state.get('forecast_data')
    forecast_total = st.session_state.get('forecast_total', 0)
    all_methods_results = st.session_state.get('individual_all_methods_results', {})
    
    # äºˆæ¸¬çµæœãŒãªã„å ´åˆï¼ˆindividual_resultsã€forecastã€forecast_totalã€all_methods_resultsã®ã„ãšã‚Œã‚‚ãªã„ï¼‰
    has_any_forecast = (
        (individual_results and len(individual_results) > 0) or
        (forecast is not None and not (isinstance(forecast, pd.DataFrame) and forecast.empty)) or
        (forecast_total > 0) or
        (all_methods_results and len(all_methods_results) > 0)
    )
    
    if not has_any_forecast:
        st.info("éœ€è¦äºˆæ¸¬ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€ç´å“è¨ˆç”»ã‚’ç«‹ã¦ã‚‰ã‚Œã¾ã™")
        return
    
    # è¤‡æ•°å•†å“ã®å€‹åˆ¥äºˆæ¸¬çµæœãŒã‚ã‚‹å ´åˆ
    if individual_results and len(individual_results) >= 1:
        if len(individual_results) > 1:
            st.success(f"ğŸ“¦ **{len(individual_results)}ä»¶ã®å•†å“**ã®äºˆæ¸¬çµæœãŒã‚ã‚Šã¾ã™")
            
            delivery_view = st.radio(
                "ç´å“è¨ˆç”»ã®è¡¨ç¤ºæ–¹æ³•",
                ["ğŸ“Š å…¨å•†å“ã‚’åˆç®—ã—ã¦è¨ˆç”»", "ğŸ“¦ å•†å“ã”ã¨ã«å€‹åˆ¥è¨ˆç”»"],
                horizontal=True,
                key="delivery_view_mode_main"
            )
            
            if delivery_view == "ğŸ“¦ å•†å“ã”ã¨ã«å€‹åˆ¥è¨ˆç”»":
                st.divider()
                for idx, r in enumerate(individual_results):
                    product = r['product']
                    forecast_df = r['forecast']
                    rounded_total = r['rounded_total']
                    avg_predicted = r['avg_predicted']
                    
                    with st.expander(f"ğŸ“¦ **{product}**ï¼ˆäºˆæ¸¬: {rounded_total:,}ä½“ã€æ—¥è²©: {avg_predicted:.1f}ä½“ï¼‰", expanded=(idx==0)):
                        render_delivery_inputs_and_schedule(
                            total_demand=rounded_total,
                            forecast_data=forecast_df,
                            product_name=product,
                            avg_daily=avg_predicted
                        )
                return
        else:
            # 1å•†å“ã®ã¿ã®å ´åˆ
            r = individual_results[0]
            st.success(f"ğŸ“¦ **{r['product']}** ã®äºˆæ¸¬çµæœ")
    
    # åˆç®—ãƒ¢ãƒ¼ãƒ‰
    total_demand = st.session_state.get('forecast_total', 0)
    method_used = st.session_state.get('last_forecast_method', '')
    forecast_data = forecast
    
    # å¹³å‡æ—¥è²©ã‚’è¨ˆç®—
    forecast_days = len(forecast_data) if forecast_data is not None and not forecast_data.empty else 180
    avg_daily = total_demand / forecast_days if forecast_days > 0 else 0
    
    if method_used:
        st.info(f"ğŸ“¦ äºˆæ¸¬ã•ã‚ŒãŸéœ€è¦æ•°: **{total_demand:,}ä½“**ï¼ˆ{forecast_days}æ—¥é–“ã€æ—¥è²©{avg_daily:.1f}ä½“ï¼‰ - {method_used}")
    else:
        st.info(f"ğŸ“¦ äºˆæ¸¬ã•ã‚ŒãŸéœ€è¦æ•°: **{total_demand:,}ä½“**ï¼ˆ{forecast_days}æ—¥é–“ã€æ—¥è²©{avg_daily:.1f}ä½“ï¼‰")
    
    render_delivery_inputs_and_schedule(total_demand, forecast_data, "åˆç®—", avg_daily)


def render_individual_delivery_plans(results: list):
    """å€‹åˆ¥å•†å“ã”ã¨ã®ç´å“è¨ˆç”»ã‚’è¡¨ç¤º"""
    for idx, r in enumerate(results):
        product = r['product']
        forecast = r['forecast']
        rounded_total = r['rounded_total']
        avg_predicted = r['avg_predicted']
        
        with st.expander(f"ğŸ“¦ **{product}** ã®ç´å“è¨ˆç”»ï¼ˆäºˆæ¸¬: {rounded_total:,}ä½“ï¼‰", expanded=(idx==0)):
            render_delivery_inputs_and_schedule(
                total_demand=rounded_total,
                forecast_data=forecast,
                product_name=product,
                avg_daily=avg_predicted
            )


def render_delivery_inputs_and_schedule(total_demand: int, forecast_data: pd.DataFrame, product_name: str, avg_daily: float = 0):
    """ç´å“è¨ˆç”»ã®å…¥åŠ›ã¨è¨ˆç®—ã‚’è¡¨ç¤º"""
    
    key_suffix = f"{product_name.replace(' ', '_')[:8]}_{hash(product_name) % 999}"
    
    # äºˆæ¸¬æœŸé–“ï¼ˆæ—¥æ•°ï¼‰ã‚’å–å¾—
    forecast_days = len(forecast_data) if forecast_data is not None and not forecast_data.empty else 180
    if avg_daily == 0:
        avg_daily = total_demand / forecast_days if forecast_days > 0 else 0
    
    # å…¥åŠ›ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.write("**ğŸ“ åœ¨åº«ãƒ»ç™ºæ³¨æƒ…å ±ã‚’å…¥åŠ›**")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        current_stock = st.number_input(
            "ğŸ  ç¾åœ¨ã®åœ¨åº«æ•°", 
            min_value=0, 
            value=500, 
            step=50, 
            key=f"stk_{key_suffix}"
        )
    
    with col2:
        min_stock = st.number_input(
            "âš ï¸ å®‰å…¨åœ¨åº«æ•°", 
            min_value=0, 
            value=100, 
            step=50, 
            key=f"minstk_{key_suffix}"
        )
    
    with col3:
        lead_time = st.number_input(
            "ğŸšš ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ (æ—¥)", 
            min_value=1, 
            value=14, 
            step=1, 
            key=f"lt_{key_suffix}",
            help="ç™ºæ³¨ã‹ã‚‰ç´å“ã¾ã§ã®æ—¥æ•°"
        )
    
    # ç™ºæ³¨æ•°ã®è¨ˆç®—
    needed = total_demand + min_stock - current_stock
    recommended_order = round_up_to_50(max(0, needed))
    
    # æ¨å¥¨ç™ºæ³¨æ•°ã¨è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ã‚’å¸¸ã«è¡¨ç¤º
    st.divider()
    st.write("**ğŸ§® ç™ºæ³¨æ¨å¥¨æ•°ã®è¨ˆç®—**")
    
    # è¨ˆç®—éç¨‹ã‚’è¡¨å½¢å¼ã§è¡¨ç¤º
    col_calc1, col_calc2 = st.columns([2, 1])
    
    with col_calc1:
        st.markdown(f"""
        | è¨ˆç®—é …ç›® | æ•°å€¤ | èª¬æ˜ |
        |:---------|-----:|:-----|
        | â‘  äºˆæ¸¬éœ€è¦ | **{total_demand:,}ä½“** | {forecast_days}æ—¥é–“ Ã— {avg_daily:.1f}ä½“/æ—¥ |
        | â‘¡ å®‰å…¨åœ¨åº« | **+{min_stock:,}ä½“** | æ¬ å“é˜²æ­¢ã®ä½™è£•åˆ† |
        | â‘¢ ç¾åœ¨åœ¨åº« | **-{current_stock:,}ä½“** | æ—¢ã«ã‚ã‚‹åœ¨åº« |
        | **å¿…è¦æ•°é‡** | **{needed:,}ä½“** | â‘  + â‘¡ - â‘¢ |
        | **ç™ºæ³¨æ¨å¥¨æ•°** | **{recommended_order:,}ä½“** | 50ã®å€æ•°ã«åˆ‡ã‚Šä¸Šã’ |
        """)
    
    with col_calc2:
        if needed <= 0:
            st.success(f"âœ… ç™ºæ³¨ä¸è¦\n\nåœ¨åº«ã§{forecast_days}æ—¥é–“ã‚«ãƒãƒ¼å¯èƒ½")
        else:
            days_until_stockout = int(current_stock / avg_daily) if avg_daily > 0 else 999
            st.warning(f"âš ï¸ è¦ç™ºæ³¨\n\nç´„{days_until_stockout}æ—¥ã§åœ¨åº«åˆ‡ã‚Œ")
    
    # ç™ºæ³¨æ•°å…¥åŠ›æ–¹æ³•
    order_mode = st.radio(
        "ç™ºæ³¨æ•°ã®æ±ºã‚æ–¹",
        ["ğŸ”® äºˆæ¸¬ã‹ã‚‰è‡ªå‹•è¨ˆç®—", "âœï¸ æ‰‹å…¥åŠ›ã§æŒ‡å®š"],
        horizontal=True,
        key=f"ordmode_{key_suffix}"
    )
    
    if order_mode == "ğŸ”® äºˆæ¸¬ã‹ã‚‰è‡ªå‹•è¨ˆç®—":
        order_quantity = recommended_order
        st.metric("ğŸ›’ ç™ºæ³¨æ•°ï¼ˆè‡ªå‹•è¨ˆç®—ï¼‰", f"{recommended_order:,}ä½“")
    else:
        order_quantity = st.number_input(
            "âœï¸ ç™ºæ³¨æ•°ã‚’å…¥åŠ›",
            min_value=0,
            value=recommended_order,
            step=50,
            key=f"manord_{key_suffix}"
        )
    
    # ç´å“ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ææ¡ˆ
    st.divider()
    st.write("**ğŸ“… ç´å“ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ææ¡ˆ**")
    
    delivery_mode = st.radio(
        "ç´å“æ–¹æ³•",
        ["ä¸€æ‹¬ç´å“", "åˆ†å‰²ç´å“ï¼ˆæœˆåˆ¥ï¼‰", "åˆ†å‰²ç´å“ï¼ˆã‚«ã‚¹ã‚¿ãƒ ï¼‰"],
        horizontal=True,
        key=f"delivery_mode_{key_suffix}"
    )
    
    if st.button("ğŸ“Š ç´å“ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½œæˆ", type="primary", use_container_width=True, key=f"create_schedule_btn_{key_suffix}"):
        if order_quantity <= 0:
            st.warning("ç™ºæ³¨æ•°ãŒ0ã§ã™ã€‚ç™ºæ³¨ã®å¿…è¦ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            schedule = create_delivery_schedule(
                order_quantity=order_quantity,
                current_stock=current_stock,
                min_stock=min_stock,
                lead_time=lead_time,
                forecast_data=forecast_data,
                delivery_mode=delivery_mode
            )
            
            display_delivery_schedule(schedule, current_stock, min_stock, forecast_data)


def create_delivery_schedule(
    order_quantity: int,
    current_stock: int,
    min_stock: int,
    lead_time: int,
    forecast_data: pd.DataFrame,
    delivery_mode: str
) -> List[Dict]:
    """ç´å“ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½œæˆ"""
    
    today = date.today()
    
    if delivery_mode == "ä¸€æ‹¬ç´å“":
        delivery_date = today + timedelta(days=lead_time)
        return [{
            'date': delivery_date,
            'quantity': order_quantity,
            'type': 'ä¸€æ‹¬ç´å“'
        }]
    
    elif delivery_mode == "åˆ†å‰²ç´å“ï¼ˆæœˆåˆ¥ï¼‰":
        if forecast_data is None or forecast_data.empty:
            months = 3
        else:
            forecast_days = len(forecast_data)
            months = max(1, forecast_days // 30)
            months = min(months, 6)
        
        schedule = []
        qty_per_delivery = round_up_to_50(order_quantity // months)
        remaining = order_quantity
        
        for i in range(months):
            delivery_date = today + timedelta(days=lead_time + (i * 30))
            qty = min(qty_per_delivery, remaining)
            if qty > 0:
                schedule.append({
                    'date': delivery_date,
                    'quantity': qty,
                    'type': f'{i+1}å›ç›®'
                })
                remaining -= qty
        
        if remaining > 0 and schedule:
            schedule[-1]['quantity'] += remaining
        
        return schedule
    
    else:  # ã‚«ã‚¹ã‚¿ãƒ åˆ†å‰²
        schedule = []
        stock = current_stock
        
        if forecast_data is not None and not forecast_data.empty:
            daily_demands = forecast_data['predicted'].tolist()
        else:
            daily_demands = [5] * 180
        
        delivery_qty = round_up_to_50(order_quantity // 3)
        remaining = order_quantity
        last_delivery_date = today
        
        for i, daily_demand in enumerate(daily_demands):
            target_date = today + timedelta(days=i)
            stock -= daily_demand
            
            if stock <= min_stock and remaining > 0:
                order_date = target_date - timedelta(days=lead_time)
                if order_date < last_delivery_date:
                    order_date = last_delivery_date + timedelta(days=1)
                
                delivery_date = order_date + timedelta(days=lead_time)
                qty = min(delivery_qty, remaining)
                
                schedule.append({
                    'date': delivery_date,
                    'quantity': qty,
                    'type': f'{len(schedule)+1}å›ç›®'
                })
                
                stock += qty
                remaining -= qty
                last_delivery_date = delivery_date
        
        if not schedule and remaining > 0:
            schedule.append({
                'date': today + timedelta(days=lead_time),
                'quantity': remaining,
                'type': 'ä¸€æ‹¬ç´å“'
            })
        
        return schedule


def display_delivery_schedule(schedule: List[Dict], current_stock: int, min_stock: int, forecast_data: pd.DataFrame):
    """ç´å“ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’è¡¨ç¤º"""
    
    st.success(f"âœ… ç´å“ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸï¼ˆ{len(schedule)}å›ç´å“ï¼‰")
    
    st.write("**ğŸ“‹ ç´å“ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«**")
    
    schedule_df = pd.DataFrame([
        {
            'ç´å“æ—¥': s['date'].strftime('%Y/%m/%d'),
            'æ›œæ—¥': ['æœˆ','ç«','æ°´','æœ¨','é‡‘','åœŸ','æ—¥'][s['date'].weekday()],
            'æ•°é‡': f"{s['quantity']:,}ä½“",
            'å‚™è€ƒ': s['type']
        }
        for s in schedule
    ])
    
    st.dataframe(schedule_df, use_container_width=True, hide_index=True)
    
    total_delivery = sum(s['quantity'] for s in schedule)
    st.metric("ğŸ“¦ ç´å“åˆè¨ˆ", f"{total_delivery:,}ä½“")
    
    with st.expander("ğŸ“ˆ åœ¨åº«æ¨ç§»ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³", expanded=True):
        sim_data = simulate_inventory(
            schedule=schedule,
            current_stock=current_stock,
            min_stock=min_stock,
            forecast_data=forecast_data
        )
        
        if sim_data:
            display_inventory_chart(sim_data, min_stock)


def simulate_inventory(schedule: List[Dict], current_stock: int, min_stock: int, forecast_data: pd.DataFrame) -> List[Dict]:
    """åœ¨åº«ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ"""
    
    today = date.today()
    
    if forecast_data is None or forecast_data.empty:
        return []
    
    sim_data = []
    stock = current_stock
    
    delivery_dict = {}
    for s in schedule:
        d = s['date']
        if d not in delivery_dict:
            delivery_dict[d] = 0
        delivery_dict[d] += s['quantity']
    
    sim_days = min(len(forecast_data), 90)
    
    for i in range(sim_days):
        target_date = today + timedelta(days=i)
        
        if target_date in delivery_dict:
            stock += delivery_dict[target_date]
        
        if i < len(forecast_data):
            daily_demand = forecast_data.iloc[i]['predicted']
        else:
            daily_demand = forecast_data['predicted'].mean()
        
        stock -= daily_demand
        stock = max(0, stock)
        
        sim_data.append({
            'date': target_date,
            'stock': stock,
            'demand': daily_demand,
            'delivery': delivery_dict.get(target_date, 0)
        })
    
    return sim_data


def display_inventory_chart(sim_data: List[Dict], min_stock: int):
    """åœ¨åº«æ¨ç§»ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºï¼ˆã‚¹ãƒãƒ›æœ€é©åŒ–ï¼‰"""
    
    df = pd.DataFrame(sim_data)
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=df['date'],
        y=df['stock'],
        mode='lines',
        name='åœ¨åº«æ•°',
        line=dict(color='#1E88E5', width=2),
        fill='tozeroy',
        fillcolor='rgba(30, 136, 229, 0.1)'
    ))
    
    fig.add_hline(
        y=min_stock, 
        line_dash="dash", 
        line_color="red",
        annotation_text=f"å®‰å…¨åœ¨åº« {min_stock}",
        annotation_position="right"
    )
    
    deliveries = df[df['delivery'] > 0]
    if not deliveries.empty:
        fig.add_trace(go.Scatter(
            x=deliveries['date'],
            y=deliveries['stock'],
            mode='markers',
            name='ç´å“',
            marker=dict(color='green', size=12, symbol='triangle-up')
        ))
    
    fig.update_layout(
        title='åœ¨åº«æ¨ç§»ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³',
        xaxis_title='æ—¥ä»˜',
        yaxis_title='åœ¨åº«æ•°ï¼ˆä½“ï¼‰',
        height=300,
        margin=dict(l=10, r=10, t=40, b=10),
        legend=dict(
            orientation='h',
            yanchor='bottom',
            y=1.02,
            xanchor='center',
            x=0.5
        ),
        dragmode=False,
    )
    
    config = {
        'displayModeBar': False,
        'staticPlot': False,
        'responsive': True
    }
    
    st.plotly_chart(fig, use_container_width=True, config=config)
    
    stock_below_min = df[df['stock'] < min_stock]
    if not stock_below_min.empty:
        first_danger = stock_below_min.iloc[0]['date']
        st.warning(f"âš ï¸ {first_danger.strftime('%Y/%m/%d')}é ƒã«åœ¨åº«ãŒå®‰å…¨åœ¨åº«ã‚’ä¸‹å›ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")


# =============================================================================
# æ–°è¦æˆä¸å“ã®éœ€è¦äºˆæ¸¬
# =============================================================================

def render_new_product_forecast():
    """æ–°è¦æˆä¸å“ã®éœ€è¦äºˆæ¸¬"""
    
    st.markdown("""
    <div class="new-product-card">
        <h2>âœ¨ æ–°è¦æˆä¸å“ã®éœ€è¦äºˆæ¸¬</h2>
        <p>ã¾ã è²©å£²å®Ÿç¸¾ã®ãªã„æ–°ã—ã„æˆä¸å“ã®éœ€è¦ã‚’ã€é¡ä¼¼å•†å“ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰äºˆæ¸¬ã—ã¾ã™ã€‚</p>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown('<p class="section-header">â‘  æ–°è¦æˆä¸å“ã®æƒ…å ±ã‚’å…¥åŠ›</p>', unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        new_product_name = st.text_input(
            "æˆä¸å“å",
            placeholder="ä¾‹: ç¸çµã³æ°´æ™¶å®ˆ",
            help="æ–°ã—ãä½œã‚‹æˆä¸å“ã®åå‰"
        )
        
        new_product_category = st.selectbox(
            "ã‚«ãƒ†ã‚´ãƒªãƒ¼",
            list(CATEGORY_CHARACTERISTICS.keys()),
            help="æœ€ã‚‚è¿‘ã„ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’é¸ã‚“ã§ãã ã•ã„"
        )
        
        new_product_price = st.number_input(
            "ä¾¡æ ¼ï¼ˆå††ï¼‰",
            min_value=100,
            max_value=50000,
            value=1000,
            step=100,
            help="è²©å£²äºˆå®šä¾¡æ ¼"
        )
    
    with col2:
        new_product_description = st.text_area(
            "ç‰¹å¾´ãƒ»ã‚³ãƒ³ã‚»ãƒ—ãƒˆ",
            placeholder="ä¾‹: æ°´æ™¶ã‚’ä½¿ç”¨ã—ãŸç¸çµã³ã®ãŠå®ˆã‚Šã€‚è‹¥ã„å¥³æ€§å‘ã‘ã€‚",
            help="æˆä¸å“ã®ç‰¹å¾´ã‚’è¨˜è¿°"
        )
        
        target_audience = st.multiselect(
            "ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤",
            ["è‹¥ã„å¥³æ€§", "è‹¥ã„ç”·æ€§", "ä¸­é«˜å¹´å¥³æ€§", "ä¸­é«˜å¹´ç”·æ€§", "å®¶æ—é€£ã‚Œ", "è¦³å…‰å®¢", "åœ°å…ƒã®æ–¹"],
            default=["è‹¥ã„å¥³æ€§", "è¦³å…‰å®¢"]
        )
    
    st.markdown('<p class="section-header">â‘¡ é¡ä¼¼å•†å“ã‚’åˆ†æ</p>', unsafe_allow_html=True)
    
    if new_product_name and new_product_name.strip():
        similar_products = find_similar_products(
            new_product_name, 
            new_product_category, 
            new_product_price,
            new_product_description
        )
        
        if similar_products:
            st.write(f"**é¡ä¼¼å•†å“ãŒ {len(similar_products)} ä»¶è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ**")
            
            for i, prod in enumerate(similar_products[:5], 1):
                col1, col2, col3 = st.columns([3, 1, 1])
                with col1:
                    st.write(f"{i}. {prod['name']}")
                with col2:
                    st.write(f"å¹³å‡ {prod['avg_daily']:.1f}ä½“/æ—¥")
                with col3:
                    st.write(f"é¡ä¼¼åº¦ {prod['similarity']:.0f}%")
        else:
            st.info("é¡ä¼¼å•†å“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®å¹³å‡å€¤ã‹ã‚‰äºˆæ¸¬ã—ã¾ã™ã€‚")
    else:
        similar_products = []
        st.info("ğŸ‘† æˆä¸å“åã‚’å…¥åŠ›ã™ã‚‹ã¨ã€é¡ä¼¼å•†å“ã‚’æ¤œç´¢ã—ã¾ã™")
    
    st.markdown('<p class="section-header">â‘¢ éœ€è¦äºˆæ¸¬</p>', unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        forecast_period = st.selectbox(
            "äºˆæ¸¬æœŸé–“",
            ["1ãƒ¶æœˆ", "3ãƒ¶æœˆ", "6ãƒ¶æœˆ", "1å¹´"],
            index=2
        )
    
    with col2:
        confidence_level = st.selectbox(
            "äºˆæ¸¬ã®ä¿å®ˆæ€§",
            ["æ¥½è¦³çš„", "æ¨™æº–", "ä¿å®ˆçš„"],
            index=1
        )
    
    if st.button("ğŸ”® æ–°è¦æˆä¸å“ã®éœ€è¦ã‚’äºˆæ¸¬", type="primary", use_container_width=True):
        if not new_product_name or not new_product_name.strip():
            st.error("æˆä¸å“åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        else:
            with st.spinner("äºˆæ¸¬ä¸­..."):
                forecast_result = forecast_new_product(
                    new_product_name,
                    new_product_category,
                    new_product_price,
                    similar_products,
                    forecast_period,
                    confidence_level
                )
                
                display_new_product_forecast(forecast_result, new_product_name, new_product_price)


def find_similar_products(name: str, category: str, price: int, description: str) -> list:
    """é¡ä¼¼å•†å“ã‚’æ¢ã™"""
    
    if not name or not name.strip():
        return []
    
    if st.session_state.data_loader is None:
        return []
    
    df_items = st.session_state.data_loader.load_item_sales()
    
    if df_items.empty:
        return []
    
    product_col = 'å•†å“å'
    qty_col = 'è²©å£²å•†å“æ•°'
    sales_col = 'è²©å£²ç·å£²ä¸Š'
    
    product_stats = df_items.groupby(product_col).agg({
        qty_col: ['sum', 'mean', 'count'],
        sales_col: 'sum'
    }).reset_index()
    
    product_stats.columns = ['name', 'total_qty', 'avg_daily', 'days_count', 'total_sales']
    
    product_stats['unit_price'] = product_stats['total_sales'] / product_stats['total_qty']
    product_stats['unit_price'] = product_stats['unit_price'].fillna(0)
    
    similar = []
    
    keywords = set(re.findall(r'[\u4e00-\u9fff]+', name.lower()))
    if description:
        keywords.update(re.findall(r'[\u4e00-\u9fff]+', description.lower()))
    
    for _, row in product_stats.iterrows():
        prod_name = row['name']
        
        name_keywords = set(re.findall(r'[\u4e00-\u9fff]+', prod_name.lower()))
        name_match = len(keywords & name_keywords) / max(len(keywords), 1) * 50
        
        if row['unit_price'] > 0:
            price_diff = abs(price - row['unit_price']) / price
            price_match = max(0, (1 - price_diff)) * 30
        else:
            price_match = 0
        
        category_keywords = {
            "ãŠå®ˆã‚Š": ["å®ˆ", "ãŠå®ˆã‚Š", "ã¾ã‚‚ã‚Š"],
            "å¾¡æœ±å°": ["å¾¡æœ±å°", "æœ±å°"],
            "å¾¡æœ±å°å¸³": ["å¾¡æœ±å°å¸³", "æœ±å°å¸³"],
            "ãŠã¿ãã˜": ["ãŠã¿ãã˜", "ã¿ãã˜"],
            "çµµé¦¬": ["çµµé¦¬"],
            "ãŠæœ­": ["æœ­", "ãŠæœ­"],
            "ç¸èµ·ç‰©": ["ç¸èµ·", "ã ã‚‹ã¾", "æ‹›ãçŒ«"],
        }
        
        cat_match = 0
        for cat, kws in category_keywords.items():
            if cat == category:
                for kw in kws:
                    if kw in prod_name:
                        cat_match = 20
                        break
        
        similarity = name_match + price_match + cat_match
        
        if similarity > 10 and row['total_qty'] > 0:
            similar.append({
                'name': prod_name,
                'total_qty': row['total_qty'],
                'avg_daily': row['avg_daily'],
                'unit_price': row['unit_price'],
                'similarity': similarity
            })
    
    similar.sort(key=lambda x: x['similarity'], reverse=True)
    
    return similar[:10]


def forecast_new_product(name: str, category: str, price: int, 
                         similar_products: list, period: str, confidence: str) -> dict:
    """æ–°è¦æˆä¸å“ã®éœ€è¦ã‚’äºˆæ¸¬"""
    
    period_days = {"1ãƒ¶æœˆ": 30, "3ãƒ¶æœˆ": 90, "6ãƒ¶æœˆ": 180, "1å¹´": 365}[period]
    confidence_factor = {"æ¥½è¦³çš„": 1.2, "æ¨™æº–": 1.0, "ä¿å®ˆçš„": 0.7}[confidence]
    
    if similar_products:
        weighted_sum = sum(p['avg_daily'] * p['similarity'] for p in similar_products[:5])
        weight_total = sum(p['similarity'] for p in similar_products[:5])
        base_daily = weighted_sum / weight_total if weight_total > 0 else 1.0
    else:
        base_daily = CATEGORY_CHARACTERISTICS.get(category, {}).get('base_daily', 1.0)
    
    cat_char = CATEGORY_CHARACTERISTICS.get(category, {})
    seasonality = cat_char.get('seasonality', 'medium')
    
    if seasonality == 'high':
        month_factors = {1: 3.0, 2: 0.7, 3: 0.9, 4: 0.9, 5: 1.0, 6: 0.8,
                        7: 0.9, 8: 1.1, 9: 0.9, 10: 1.0, 11: 1.2, 12: 1.5}
    elif seasonality == 'medium':
        month_factors = {1: 1.5, 2: 0.9, 3: 1.0, 4: 1.0, 5: 1.1, 6: 0.9,
                        7: 1.0, 8: 1.1, 9: 1.0, 10: 1.0, 11: 1.1, 12: 1.2}
    else:
        month_factors = {i: 1.0 for i in range(1, 13)}
    
    daily_forecast = []
    total_qty = 0
    
    for i in range(period_days):
        target_date = date.today() + timedelta(days=i)
        month = target_date.month
        weekday = target_date.weekday()
        
        weekday_factor = 1.5 if weekday >= 5 else 1.0
        month_factor = month_factors.get(month, 1.0)
        
        pred = base_daily * weekday_factor * month_factor * confidence_factor
        pred = max(0, round(pred))
        
        daily_forecast.append({
            'date': target_date,
            'predicted': pred
        })
        
        total_qty += pred
    
    total_qty_rounded = round_up_to_50(total_qty)
    
    df_forecast = pd.DataFrame(daily_forecast)
    df_forecast['month'] = pd.to_datetime(df_forecast['date']).dt.to_period('M')
    monthly = df_forecast.groupby('month')['predicted'].sum().to_dict()
    
    return {
        'daily_forecast': daily_forecast,
        'total_qty': total_qty,
        'total_qty_rounded': total_qty_rounded,
        'avg_daily': total_qty / period_days,
        'period_days': period_days,
        'monthly': monthly,
        'base_daily': base_daily,
        'confidence': confidence,
        'similar_count': len(similar_products)
    }


def display_new_product_forecast(result: dict, product_name: str, price: int):
    """æ–°è¦æˆä¸å“ã®äºˆæ¸¬çµæœã‚’è¡¨ç¤º"""
    
    st.success("âœ… äºˆæ¸¬å®Œäº†ï¼")
    
    st.write(f"### ğŸ“¦ ã€Œ{product_name}ã€ã®éœ€è¦äºˆæ¸¬")
    
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("äºˆæ¸¬è²©å£²ç·æ•°", f"{result['total_qty_rounded']:,}ä½“")
    col2.metric("äºˆæ¸¬å£²ä¸Š", f"Â¥{result['total_qty_rounded'] * price:,.0f}")
    col3.metric("å¹³å‡æ—¥è²©", f"{result['avg_daily']:.1f}ä½“/æ—¥")
    col4.metric("äºˆæ¸¬æœŸé–“", f"{result['period_days']}æ—¥é–“")
    
    if result['similar_count'] >= 3:
        st.info(f"ğŸ“Š é¡ä¼¼å•†å“ {result['similar_count']} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’åŸºã«äºˆæ¸¬ã—ã¾ã—ãŸã€‚ä¿¡é ¼åº¦: â­â­â­")
    elif result['similar_count'] >= 1:
        st.warning(f"ğŸ“Š é¡ä¼¼å•†å“ {result['similar_count']} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’åŸºã«äºˆæ¸¬ã—ã¾ã—ãŸã€‚ä¿¡é ¼åº¦: â­â­")
    else:
        st.warning("ğŸ“Š é¡ä¼¼å•†å“ãŒãªã‹ã£ãŸãŸã‚ã€ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®å¹³å‡å€¤ã‹ã‚‰äºˆæ¸¬ã—ã¾ã—ãŸã€‚ä¿¡é ¼åº¦: â­")
    
    monthly_data = []
    for period, qty in result['monthly'].items():
        monthly_data.append({'æœˆ': str(period), 'äºˆæ¸¬è²©å£²æ•°': qty})
    
    df_monthly = pd.DataFrame(monthly_data)
    
    fig = px.bar(
        df_monthly, x='æœˆ', y='äºˆæ¸¬è²©å£²æ•°',
        title='æœˆåˆ¥äºˆæ¸¬è²©å£²æ•°',
        color='äºˆæ¸¬è²©å£²æ•°',
        color_continuous_scale='Blues'
    )
    st.plotly_chart(fig, use_container_width=True)
    
    st.write("### ğŸ“‹ åˆå›ç™ºæ³¨é‡ã®ææ¡ˆ")
    
    col1, col2, col3 = st.columns(3)
    col1.metric("å°‘ãªã‚ï¼ˆ1ãƒ¶æœˆåˆ†ï¼‰", f"{round_up_to_50(int(result['avg_daily'] * 30))}ä½“")
    col2.metric("æ¨™æº–ï¼ˆ3ãƒ¶æœˆåˆ†ï¼‰", f"{round_up_to_50(int(result['avg_daily'] * 90))}ä½“")
    col3.metric("å¤šã‚ï¼ˆ6ãƒ¶æœˆåˆ†ï¼‰", f"{round_up_to_50(int(result['avg_daily'] * 180))}ä½“")


# =============================================================================
# é«˜åº¦ãªåˆ†æ
# =============================================================================

def render_advanced_analysis():
    """é«˜åº¦ãªåˆ†æã‚¿ãƒ–"""
    st.markdown('<p class="section-header">ğŸ”¬ é«˜åº¦ãªåˆ†æ</p>', unsafe_allow_html=True)
    
    if not ADVANCED_ANALYSIS_AVAILABLE:
        st.warning("demand_analyzer.pyãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    sales_data = st.session_state.get('sales_data')
    
    if sales_data is None or sales_data.empty:
        st.info("ã€Œæ—¢å­˜æˆä¸å“ã®åˆ†æãƒ»äºˆæ¸¬ã€ã‚¿ãƒ–ã§æˆä¸å“ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return
    
    try:
        df_items = st.session_state.data_loader.load_item_sales()
        internal = InternalAnalyzer(df_items)
        external = ExternalAnalyzer(df_items, None)
    except Exception as e:
        st.error(f"åˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return
    
    with st.expander("ğŸ“Š **é«˜åº¦ãªåˆ†æã‚’è¦‹ã‚‹**", expanded=False):
        tab1, tab2, tab3 = st.tabs(["ğŸ“ˆ ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ", "ğŸ—“ï¸ å­£ç¯€æ€§åˆ†æ", "ğŸŒ¤ï¸ å¤–éƒ¨è¦å› åˆ†æ"])
        
        with tab1:
            render_trend_analysis(internal)
        
        with tab2:
            render_seasonality_analysis(internal)
        
        with tab3:
            render_external_analysis(external)


def render_trend_analysis(internal):
    """ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã‚’è¡¨ç¤º"""
    st.write("### ğŸ“ˆ è²©å£²ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ")
    
    try:
        trend = internal.analyze_sales_trend()
        
        col1, col2, col3 = st.columns(3)
        col1.metric("ãƒˆãƒ¬ãƒ³ãƒ‰æ–¹å‘", trend['trend_direction'])
        col2.metric("æˆé•·ç‡", f"{trend['growth_rate']}%")
        col3.metric("å¤‰å‹•æ€§", f"{trend['volatility']:.2f}")
        
        if 'monthly_data' in trend and not trend['monthly_data'].empty:
            fig = px.line(
                trend['monthly_data'], 
                x='period', 
                y='è²©å£²å•†å“æ•°',
                title='æœˆåˆ¥è²©å£²æ¨ç§»'
            )
            st.plotly_chart(fig, use_container_width=True)
    except Exception as e:
        st.warning(f"ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")


def render_seasonality_analysis(internal):
    """å­£ç¯€æ€§åˆ†æã‚’è¡¨ç¤º"""
    st.write("### ğŸ—“ï¸ å­£ç¯€æ€§åˆ†æ")
    
    try:
        seasonality = internal.detect_seasonality()
        
        st.metric("å­£ç¯€æ€§ã®å¼·ã•", f"{seasonality['seasonality_strength']:.2f}")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**æœˆåˆ¥ä¿‚æ•°**")
            monthly = seasonality['monthly_pattern']
            df_monthly = pd.DataFrame({
                'æœˆ': list(monthly.keys()),
                'ä¿‚æ•°': list(monthly.values())
            })
            fig = px.bar(df_monthly, x='æœˆ', y='ä¿‚æ•°', title='æœˆåˆ¥è²©å£²ä¿‚æ•°')
            fig.add_hline(y=1.0, line_dash="dash", line_color="red")
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.write("**æ›œæ—¥åˆ¥ä¿‚æ•°**")
            weekday = seasonality['weekday_pattern']
            df_weekday = pd.DataFrame({
                'æ›œæ—¥': list(weekday.keys()),
                'ä¿‚æ•°': list(weekday.values())
            })
            fig = px.bar(df_weekday, x='æ›œæ—¥', y='ä¿‚æ•°', title='æ›œæ—¥åˆ¥è²©å£²ä¿‚æ•°')
            fig.add_hline(y=1.0, line_dash="dash", line_color="red")
            st.plotly_chart(fig, use_container_width=True)
    except Exception as e:
        st.warning(f"å­£ç¯€æ€§åˆ†æã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")


def render_external_analysis(external):
    """å¤–éƒ¨è¦å› åˆ†æã‚’è¡¨ç¤º"""
    st.write("### ğŸŒ¤ï¸ å¤–éƒ¨è¦å› åˆ†æ")
    
    try:
        calendar_effect = external.analyze_calendar_effect()
        
        if calendar_effect.get('available', False):
            st.metric("ä¼‘æ—¥ã®å½±éŸ¿åº¦", f"{calendar_effect['holiday_impact']:.2f}x")
        else:
            st.info("ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚ã€å¤–éƒ¨è¦å› åˆ†æã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
    except Exception as e:
        st.warning(f"å¤–éƒ¨è¦å› åˆ†æã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")


# =============================================================================
# äºˆæ¸¬ç²¾åº¦ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
# =============================================================================

def render_accuracy_dashboard():
    """äºˆæ¸¬ç²¾åº¦ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"""
    
    st.markdown('<p class="section-header">ğŸ“ˆ äºˆæ¸¬ç²¾åº¦ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰</p>', unsafe_allow_html=True)
    
    try:
        service = st.session_state.data_loader.service
        result = service.spreadsheets().values().get(
            spreadsheetId=st.session_state.data_loader.spreadsheet_id,
            range="'forecast_accuracy'!A:H"
        ).execute()
        
        values = result.get('values', [])
        
        if len(values) <= 1:
            st.info("""
            ğŸ“Š ã¾ã äºˆæ¸¬ç²¾åº¦ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚
            
            è‡ªå‹•å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ãŒç¨¼åƒã™ã‚‹ã¨ã€ã“ã“ã«äºˆæ¸¬ç²¾åº¦ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚
            """)
            return
        
        headers = values[0]
        df = pd.DataFrame(values[1:], columns=headers)
        
        df['date'] = pd.to_datetime(df['date'], errors='coerce')
        df['predicted_qty'] = pd.to_numeric(df['predicted_qty'], errors='coerce')
        df['actual_qty'] = pd.to_numeric(df['actual_qty'], errors='coerce')
        df['diff_pct'] = pd.to_numeric(df['diff_pct'], errors='coerce')
        
        st.write("### éå»30æ—¥é–“ã®äºˆæ¸¬ç²¾åº¦")
        
        recent = df[df['date'] >= (datetime.now() - timedelta(days=30))]
        
        if not recent.empty:
            avg_error = recent['diff_pct'].abs().mean()
            total_predicted = recent['predicted_qty'].sum()
            total_actual = recent['actual_qty'].sum()
            accuracy = 100 - avg_error
            
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("å¹³å‡èª¤å·®ç‡", f"{avg_error:.1f}%")
            col2.metric("äºˆæ¸¬ç²¾åº¦", f"{accuracy:.1f}%")
            col3.metric("äºˆæ¸¬åˆè¨ˆ", f"{total_predicted:.0f}ä½“")
            col4.metric("å®Ÿç¸¾åˆè¨ˆ", f"{total_actual:.0f}ä½“")
            
            fig = go.Figure()
            
            daily = recent.groupby('date').agg({
                'predicted_qty': 'sum',
                'actual_qty': 'sum'
            }).reset_index()
            
            fig.add_trace(go.Scatter(
                x=daily['date'],
                y=daily['predicted_qty'],
                mode='lines+markers',
                name='äºˆæ¸¬',
                line=dict(color='#4285F4')
            ))
            
            fig.add_trace(go.Scatter(
                x=daily['date'],
                y=daily['actual_qty'],
                mode='lines+markers',
                name='å®Ÿç¸¾',
                line=dict(color='#4CAF50')
            ))
            
            fig.update_layout(
                title='äºˆæ¸¬ vs å®Ÿç¸¾ï¼ˆæ—¥åˆ¥ï¼‰',
                xaxis_title='æ—¥ä»˜',
                yaxis_title='è²©å£²æ•°ï¼ˆä½“ï¼‰'
            )
            
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("éå»30æ—¥é–“ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
    
    except Exception as e:
        st.info("""
        ğŸ“Š äºˆæ¸¬ç²¾åº¦ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’è¡¨ç¤ºã™ã‚‹ã«ã¯ã€è‡ªå‹•å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãŒå¿…è¦ã§ã™ã€‚
        """)


# =============================================================================
# ãƒ¡ã‚¤ãƒ³é–¢æ•°
# =============================================================================

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    
    # ========== å‰Šé™¤ãƒ•ãƒ©ã‚°ã®å‡¦ç†ï¼ˆãƒšãƒ¼ã‚¸å…ˆé ­ã§å®Ÿè¡Œï¼‰ ==========
    if st.session_state.get('pending_delete_product'):
        product_to_delete = st.session_state.pending_delete_product
        if product_to_delete in st.session_state.selected_products:
            st.session_state.selected_products.remove(product_to_delete)
        if product_to_delete in st.session_state.product_groups:
            del st.session_state.product_groups[product_to_delete]
        st.session_state.sales_data = None
        st.session_state.forecast_data = None
        st.session_state.individual_sales_data = {}
        st.session_state.individual_forecast_results = []
        st.session_state.individual_all_methods_results = {}
        st.session_state.pending_delete_product = None
    
    if not init_data():
        st.stop()
    
    render_header()
    st.divider()
    render_main_tabs()
    
    st.divider()
    
    # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±
    version_info = "v17 (ã‚°ãƒ«ãƒ¼ãƒ—æ©Ÿèƒ½ãƒ»å¹´æ¬¡æ¯”è¼ƒãƒ»ãƒãƒˆãƒªãƒƒã‚¯ã‚¹äºˆæ¸¬ç‰ˆ)"
    if VERTEX_AI_AVAILABLE:
        version_info += " | ğŸš€ Vertex AI: æœ‰åŠ¹"
    else:
        version_info += " | âš ï¸ Vertex AI: æœªè¨­å®š"
    
    st.caption(f"â›©ï¸ é…’åˆ—ç£¯å‰ç¥ç¤¾ æˆä¸å“ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ  {version_info}")


if __name__ == "__main__":
    main()
