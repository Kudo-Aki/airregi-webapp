"""
Airãƒ¬ã‚¸ å£²ä¸Šåˆ†æãƒ»éœ€è¦äºˆæ¸¬ Webã‚¢ãƒ—ãƒªï¼ˆv12: Vertex AI AutoML Forecasting å®Œå…¨çµ±åˆç‰ˆï¼‰

v11ã‹ã‚‰ã®å¤‰æ›´ç‚¹:
1. google.generativeai â†’ google.cloud.aiplatform ã«å¤‰æ›´
2. APIã‚­ãƒ¼èªè¨¼ â†’ ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆJSONèªè¨¼ ã«å¤‰æ›´
3. çµ±è¨ˆãƒ™ãƒ¼ã‚¹äºˆæ¸¬ â†’ Vertex AI AutoML Forecastingã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå‘¼ã³å‡ºã—
4. å…±å¤‰é‡ï¼ˆå¤©æ°—ã€å…­æ›œã€ã‚¤ãƒ™ãƒ³ãƒˆç­‰ï¼‰å¯¾å¿œ
5. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–ï¼ˆAPIåˆ¶é™ã€æ¥ç¶šã‚¨ãƒ©ãƒ¼å¯¾å¿œï¼‰

v11ã‹ã‚‰ã®ç¶­æŒæ©Ÿèƒ½:
- è¤‡æ•°æˆä¸å“é¸æŠæ™‚ã«ã€Œåˆç®—ã€ã€Œå€‹åˆ¥ã€ã‚’é¸æŠå¯èƒ½
- äºˆæ¸¬æœŸé–“ã‚’ã€Œæ—¥æ•°æŒ‡å®šã€ã€ŒæœŸé–“æŒ‡å®šã€ã§é¸æŠå¯èƒ½
- æ–°è¦æˆä¸å“ã®éœ€è¦äºˆæ¸¬ï¼ˆé¡ä¼¼å•†å“ãƒ™ãƒ¼ã‚¹ï¼‰
- äºˆæ¸¬ç²¾åº¦ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
- é«˜åº¦ãªåˆ†æã‚¿ãƒ–
"""

import streamlit as st
import pandas as pd
import numpy as np
from datetime import date, datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
import plotly.express as px
import plotly.graph_objects as go
from collections import defaultdict
import calendar
import re
import os
import json
import logging

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import sys
sys.path.append('.')
from modules.data_loader import SheetsDataLoader, aggregate_by_products, merge_with_calendar
from modules.product_normalizer import ProductNormalizer
import config

# é«˜åº¦ãªåˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ï¼‰
try:
    from modules.demand_analyzer import InternalAnalyzer, ExternalAnalyzer, MarketAnalyzer, DemandForecastEngine
    ADVANCED_ANALYSIS_AVAILABLE = True
except ImportError:
    ADVANCED_ANALYSIS_AVAILABLE = False


# =============================================================================
# Vertex AI AutoML Forecasting çµ±åˆ
# =============================================================================

# Vertex AIè¨­å®šï¼ˆconfig.pyã¾ãŸã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼‰
VERTEX_AI_CONFIG = {
    'project_id': getattr(config, 'VERTEX_AI_PROJECT_ID', os.environ.get('VERTEX_AI_PROJECT_ID', '')),
    'location': getattr(config, 'VERTEX_AI_LOCATION', os.environ.get('VERTEX_AI_LOCATION', 'asia-northeast1')),
    'endpoint_id': getattr(config, 'VERTEX_AI_ENDPOINT_ID', os.environ.get('VERTEX_AI_ENDPOINT_ID', '')),
    'service_account_file': getattr(config, 'VERTEX_AI_SERVICE_ACCOUNT_FILE', 
                                     os.environ.get('VERTEX_AI_SERVICE_ACCOUNT_FILE', 'service_account.json')),
}

# Vertex AIåˆ©ç”¨å¯èƒ½ãƒ•ãƒ©ã‚°
VERTEX_AI_AVAILABLE = False
aiplatform = None
prediction_service_client = None

try:
    from google.cloud import aiplatform
    from google.cloud.aiplatform.gapic.schema import predict as predict_schema
    from google.protobuf import json_format
    from google.protobuf.struct_pb2 import Value
    from google.oauth2 import service_account
    from google.api_core import exceptions as google_exceptions
    
    # ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆèªè¨¼
    if os.path.exists(VERTEX_AI_CONFIG['service_account_file']):
        credentials = service_account.Credentials.from_service_account_file(
            VERTEX_AI_CONFIG['service_account_file'],
            scopes=['https://www.googleapis.com/auth/cloud-platform']
        )
        
        # Vertex AIåˆæœŸåŒ–
        if VERTEX_AI_CONFIG['project_id'] and VERTEX_AI_CONFIG['endpoint_id']:
            aiplatform.init(
                project=VERTEX_AI_CONFIG['project_id'],
                location=VERTEX_AI_CONFIG['location'],
                credentials=credentials
            )
            VERTEX_AI_AVAILABLE = True
            logger.info("Vertex AI AutoML Forecasting: åˆæœŸåŒ–æˆåŠŸ")
        else:
            logger.warning("Vertex AI: project_idã¾ãŸã¯endpoint_idãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    else:
        logger.warning(f"Vertex AI: ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {VERTEX_AI_CONFIG['service_account_file']}")
        
except ImportError as e:
    logger.warning(f"Vertex AI SDKãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“: {e}")
except Exception as e:
    logger.error(f"Vertex AIåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")


class VertexAIForecaster:
    """Vertex AI AutoML Forecastingã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’å‘¼ã³å‡ºã™ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.project_id = VERTEX_AI_CONFIG['project_id']
        self.location = VERTEX_AI_CONFIG['location']
        self.endpoint_id = VERTEX_AI_CONFIG['endpoint_id']
        self.endpoint_name = f"projects/{self.project_id}/locations/{self.location}/endpoints/{self.endpoint_id}"
        self._client = None
    
    @property
    def client(self):
        """Prediction Service Clientã‚’å–å¾—ï¼ˆé…å»¶åˆæœŸåŒ–ï¼‰"""
        if self._client is None:
            from google.cloud.aiplatform_v1.services.prediction_service import PredictionServiceClient
            from google.cloud.aiplatform_v1.types import PredictRequest
            
            client_options = {"api_endpoint": f"{self.location}-aiplatform.googleapis.com"}
            credentials = service_account.Credentials.from_service_account_file(
                VERTEX_AI_CONFIG['service_account_file'],
                scopes=['https://www.googleapis.com/auth/cloud-platform']
            )
            self._client = PredictionServiceClient(
                credentials=credentials,
                client_options=client_options
            )
        return self._client
    
    def prepare_forecast_instances(
        self,
        historical_data: pd.DataFrame,
        forecast_horizon: int,
        product_id: str,
        covariates: Optional[Dict[str, List]] = None
    ) -> List[Dict[str, Any]]:
        """
        Vertex AI Forecasting APIãŒæœŸå¾…ã™ã‚‹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å½¢å¼ã‚’æº–å‚™
        
        Args:
            historical_data: éå»ã®å£²ä¸Šãƒ‡ãƒ¼ã‚¿ï¼ˆdate, è²©å£²å•†å“æ•°ï¼‰
            forecast_horizon: äºˆæ¸¬æ—¥æ•°
            product_id: å•†å“è­˜åˆ¥å­
            covariates: å°†æ¥åˆ©ç”¨å¯èƒ½ãªå…±å¤‰é‡ï¼ˆå¤©æ°—ã€å…­æ›œã€ã‚¤ãƒ™ãƒ³ãƒˆç­‰ï¼‰
        
        Returns:
            APIãƒªã‚¯ã‚¨ã‚¹ãƒˆç”¨ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãƒªã‚¹ãƒˆ
        """
        df = historical_data.copy()
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values('date')
        
        # æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        time_series = []
        for _, row in df.iterrows():
            time_series.append({
                'timestamp': row['date'].strftime('%Y-%m-%dT00:00:00Z'),
                'target': float(row['è²©å£²å•†å“æ•°'])
            })
        
        # äºˆæ¸¬æœŸé–“ã®æº–å‚™
        last_date = df['date'].max()
        forecast_timestamps = []
        for i in range(1, forecast_horizon + 1):
            future_date = last_date + timedelta(days=i)
            forecast_timestamps.append(future_date.strftime('%Y-%m-%dT00:00:00Z'))
        
        # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ§‹é€ ã®æ§‹ç¯‰
        instance = {
            'time_series_identifier': product_id,
            'time_column': 'timestamp',
            'target_column': 'target',
            'historical_data': time_series,
            'forecast_horizon': forecast_horizon,
            'forecast_timestamps': forecast_timestamps,
        }
        
        # å…±å¤‰é‡ã®è¿½åŠ ï¼ˆå¤©æ°—ã€å…­æ›œã€ã‚¤ãƒ™ãƒ³ãƒˆç­‰ï¼‰
        if covariates:
            instance['available_at_forecast_columns'] = list(covariates.keys())
            
            # éå»ãƒ‡ãƒ¼ã‚¿ã®å…±å¤‰é‡
            if 'historical_covariates' in covariates:
                instance['historical_covariates'] = covariates['historical_covariates']
            
            # å°†æ¥ãƒ‡ãƒ¼ã‚¿ã®å…±å¤‰é‡
            if 'future_covariates' in covariates:
                instance['future_covariates'] = covariates['future_covariates']
        
        return [instance]
    
    def predict(
        self,
        historical_data: pd.DataFrame,
        forecast_horizon: int,
        product_id: str = "default",
        covariates: Optional[Dict[str, List]] = None
    ) -> Tuple[pd.DataFrame, Dict[str, Any]]:
        """
        Vertex AI AutoML Forecastingã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«äºˆæ¸¬ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
        
        Args:
            historical_data: éå»ã®å£²ä¸Šãƒ‡ãƒ¼ã‚¿
            forecast_horizon: äºˆæ¸¬æ—¥æ•°
            product_id: å•†å“è­˜åˆ¥å­
            covariates: å…±å¤‰é‡ãƒ‡ãƒ¼ã‚¿
        
        Returns:
            äºˆæ¸¬çµæœã®DataFrameã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        """
        if not VERTEX_AI_AVAILABLE:
            raise RuntimeError("Vertex AIãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        
        try:
            # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æº–å‚™
            instances = self.prepare_forecast_instances(
                historical_data, forecast_horizon, product_id, covariates
            )
            
            # Protobufå½¢å¼ã«å¤‰æ›
            instances_pb = [json_format.ParseDict(inst, Value()) for inst in instances]
            
            # äºˆæ¸¬ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡
            response = self.client.predict(
                endpoint=self.endpoint_name,
                instances=instances_pb,
            )
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æ
            predictions = []
            metadata = {
                'model_version': getattr(response, 'model_version_id', 'unknown'),
                'deployed_model_id': getattr(response, 'deployed_model_id', 'unknown'),
            }
            
            last_date = pd.to_datetime(historical_data['date']).max()
            
            for i, prediction in enumerate(response.predictions):
                pred_dict = json_format.MessageToDict(prediction)
                
                # äºˆæ¸¬å€¤ã®å–å¾—ï¼ˆAutoML Forecastingã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ã«å¿œã˜ã¦èª¿æ•´ï¼‰
                if 'value' in pred_dict:
                    pred_value = pred_dict['value']
                elif 'predicted_target' in pred_dict:
                    pred_value = pred_dict['predicted_target']
                else:
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒªã‚¹ãƒˆå½¢å¼ã®å ´åˆ
                    pred_value = list(pred_dict.values())[0] if pred_dict else 0
                
                # äºˆæ¸¬å€¤ãŒé…åˆ—ã®å ´åˆã®å‡¦ç†
                if isinstance(pred_value, list):
                    for j, val in enumerate(pred_value):
                        predictions.append({
                            'date': last_date + timedelta(days=j+1),
                            'predicted': max(0, round(float(val))),
                            'confidence_lower': pred_dict.get('lower_bound', [None])[j] if isinstance(pred_dict.get('lower_bound'), list) else None,
                            'confidence_upper': pred_dict.get('upper_bound', [None])[j] if isinstance(pred_dict.get('upper_bound'), list) else None,
                        })
                else:
                    predictions.append({
                        'date': last_date + timedelta(days=i+1),
                        'predicted': max(0, round(float(pred_value))),
                    })
            
            return pd.DataFrame(predictions), metadata
            
        except google_exceptions.ResourceExhausted as e:
            logger.error(f"Vertex AI ã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™: {e}")
            raise RuntimeError(f"APIã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚\nè©³ç´°: {e}")
        
        except google_exceptions.InvalidArgument as e:
            logger.error(f"Vertex AI ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            raise RuntimeError(f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆå½¢å¼ãŒä¸æ­£ã§ã™ã€‚\nè©³ç´°: {e}")
        
        except google_exceptions.NotFound as e:
            logger.error(f"Vertex AI ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆæœªç™ºè¦‹: {e}")
            raise RuntimeError(f"æŒ‡å®šã•ã‚ŒãŸã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚endpoint_idã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\nè©³ç´°: {e}")
        
        except google_exceptions.PermissionDenied as e:
            logger.error(f"Vertex AI æ¨©é™ã‚¨ãƒ©ãƒ¼: {e}")
            raise RuntimeError(f"ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®æ¨©é™ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\nè©³ç´°: {e}")
        
        except Exception as e:
            logger.error(f"Vertex AI äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
            raise RuntimeError(f"äºˆæ¸¬ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\nè©³ç´°: {e}")


# Vertex AIãƒ•ã‚©ã‚¢ã‚­ãƒ£ã‚¹ã‚¿ãƒ¼ã®ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
_vertex_ai_forecaster = None

def get_vertex_ai_forecaster() -> Optional[VertexAIForecaster]:
    """Vertex AIãƒ•ã‚©ã‚¢ã‚­ãƒ£ã‚¹ã‚¿ãƒ¼ã‚’å–å¾—"""
    global _vertex_ai_forecaster
    if VERTEX_AI_AVAILABLE and _vertex_ai_forecaster is None:
        _vertex_ai_forecaster = VertexAIForecaster()
    return _vertex_ai_forecaster


# =============================================================================
# å…±å¤‰é‡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆå¤©æ°—ã€å…­æ›œã€ã‚¤ãƒ™ãƒ³ãƒˆï¼‰
# =============================================================================

def generate_covariates(start_date: date, end_date: date, location: str = "hitachinaka") -> Dict[str, List]:
    """
    å°†æ¥åˆ©ç”¨å¯èƒ½ãªå…±å¤‰é‡ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
    
    Args:
        start_date: é–‹å§‹æ—¥
        end_date: çµ‚äº†æ—¥
        location: åœ°åŸŸï¼ˆå¤©æ°—äºˆå ±ç”¨ï¼‰
    
    Returns:
        å…±å¤‰é‡ãƒ‡ãƒ¼ã‚¿ã®è¾æ›¸
    """
    covariates = {
        'future_covariates': []
    }
    
    current_date = start_date
    while current_date <= end_date:
        covariate_entry = {
            'timestamp': current_date.strftime('%Y-%m-%dT00:00:00Z'),
            'weekday': current_date.weekday(),  # 0=æœˆæ›œ, 6=æ—¥æ›œ
            'is_weekend': 1 if current_date.weekday() >= 5 else 0,
            'month': current_date.month,
            'day_of_month': current_date.day,
        }
        
        # å…­æ›œï¼ˆç°¡æ˜“è¨ˆç®—ï¼‰
        rokuyou_list = ['å¤§å®‰', 'èµ¤å£', 'å…ˆå‹', 'å‹å¼•', 'å…ˆè² ', 'ä»æ»…']
        rokuyou_idx = (current_date.year + current_date.month + current_date.day) % 6
        covariate_entry['rokuyou'] = rokuyou_idx
        covariate_entry['is_taian'] = 1 if rokuyou_list[rokuyou_idx] == 'å¤§å®‰' else 0
        
        # ç‰¹åˆ¥æœŸé–“ãƒ•ãƒ©ã‚°
        covariate_entry['is_new_year'] = 1 if (current_date.month == 1 and current_date.day <= 7) else 0
        covariate_entry['is_obon'] = 1 if (current_date.month == 8 and 13 <= current_date.day <= 16) else 0
        covariate_entry['is_shichigosan'] = 1 if (current_date.month == 11 and 10 <= current_date.day <= 20) else 0
        covariate_entry['is_golden_week'] = 1 if (current_date.month == 5 and 3 <= current_date.day <= 5) else 0
        
        covariates['future_covariates'].append(covariate_entry)
        current_date += timedelta(days=1)
    
    return covariates


# =============================================================================
# äºˆæ¸¬é–¢æ•°ï¼ˆVertex AI + ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
# =============================================================================

def get_vertex_ai_prediction(
    df: pd.DataFrame,
    periods: int,
    product_id: str = "default",
    use_covariates: bool = True
) -> Tuple[pd.DataFrame, bool, str]:
    """
    Vertex AI AutoML Forecastingã«ã‚ˆã‚‹äºˆæ¸¬ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ãï¼‰
    
    Args:
        df: å£²ä¸Šãƒ‡ãƒ¼ã‚¿ï¼ˆdate, è²©å£²å•†å“æ•°ï¼‰
        periods: äºˆæ¸¬æ—¥æ•°
        product_id: å•†å“è­˜åˆ¥å­
        use_covariates: å…±å¤‰é‡ã‚’ä½¿ç”¨ã™ã‚‹ã‹
    
    Returns:
        äºˆæ¸¬DataFrame, Vertex AIä½¿ç”¨ãƒ•ãƒ©ã‚°, ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    """
    forecaster = get_vertex_ai_forecaster()
    
    if forecaster is None:
        # Vertex AIãŒåˆ©ç”¨ä¸å¯ã®å ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        return forecast_with_seasonality_fallback(df, periods), False, "Vertex AIæœªè¨­å®šã®ãŸã‚ã€çµ±è¨ˆãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬"
    
    try:
        # å…±å¤‰é‡ã®æº–å‚™
        covariates = None
        if use_covariates:
            last_date = pd.to_datetime(df['date']).max()
            start_date = (last_date + timedelta(days=1)).date()
            end_date = (last_date + timedelta(days=periods)).date()
            covariates = generate_covariates(start_date, end_date)
        
        # Vertex AIäºˆæ¸¬
        predictions, metadata = forecaster.predict(
            historical_data=df,
            forecast_horizon=periods,
            product_id=product_id,
            covariates=covariates
        )
        
        return predictions, True, f"Vertex AI AutoML Forecasting (ãƒ¢ãƒ‡ãƒ«: {metadata.get('deployed_model_id', 'N/A')})"
        
    except RuntimeError as e:
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        logger.warning(f"Vertex AIäºˆæ¸¬å¤±æ•—ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ: {e}")
        return forecast_with_seasonality_fallback(df, periods), False, f"Vertex AIã‚¨ãƒ©ãƒ¼: {str(e)[:100]}... çµ±è¨ˆãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬"
    except Exception as e:
        logger.error(f"äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
        return forecast_with_seasonality_fallback(df, periods), False, f"ã‚¨ãƒ©ãƒ¼: {str(e)[:100]}... çµ±è¨ˆãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬"


def forecast_with_seasonality_fallback(df: pd.DataFrame, periods: int) -> pd.DataFrame:
    """
    ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®å­£ç¯€æ€§è€ƒæ…®äºˆæ¸¬ï¼ˆçµ±è¨ˆãƒ™ãƒ¼ã‚¹ï¼‰
    
    Vertex AIãŒåˆ©ç”¨ã§ããªã„å ´åˆã«ä½¿ç”¨
    """
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'])
    df = df.sort_values('date')
    
    overall_mean = df['è²©å£²å•†å“æ•°'].mean()
    
    if pd.isna(overall_mean) or overall_mean == 0:
        overall_mean = 1
    
    # æ›œæ—¥ä¿‚æ•°
    df['weekday'] = df['date'].dt.dayofweek
    weekday_means = df.groupby('weekday')['è²©å£²å•†å“æ•°'].mean()
    weekday_factor = {}
    for wd in range(7):
        if wd in weekday_means.index and weekday_means[wd] > 0:
            weekday_factor[wd] = weekday_means[wd] / overall_mean
        else:
            weekday_factor[wd] = 1.0
    
    # æœˆä¿‚æ•°
    df['month'] = df['date'].dt.month
    month_means = df.groupby('month')['è²©å£²å•†å“æ•°'].mean()
    month_factor = {}
    for m in range(1, 13):
        if m in month_means.index and month_means[m] > 0:
            month_factor[m] = month_means[m] / overall_mean
        else:
            month_factor[m] = 1.0
    
    # äºˆæ¸¬
    last_date = df['date'].max()
    future_dates = pd.date_range(start=last_date + timedelta(days=1), periods=periods, freq='D')
    
    predictions = []
    for d in future_dates:
        weekday_f = weekday_factor.get(d.dayofweek, 1.0)
        month_f = month_factor.get(d.month, 1.0)
        
        # ç‰¹åˆ¥æœŸé–“ã®èª¿æ•´
        special_factor = 1.0
        if d.month == 1 and d.day <= 7:  # æ­£æœˆ
            special_factor = 3.0
        elif d.month == 8 and 13 <= d.day <= 16:  # ãŠç›†
            special_factor = 1.5
        elif d.month == 11 and 10 <= d.day <= 20:  # ä¸ƒäº”ä¸‰
            special_factor = 1.3
        
        pred = overall_mean * weekday_f * month_f * special_factor
        pred = max(0.1, pred)
        
        predictions.append({
            'date': d,
            'predicted': round(pred)
        })
    
    return pd.DataFrame(predictions)


# =============================================================================
# äºˆæ¸¬æ–¹æ³•ã®çµ±åˆï¼ˆVertex AIå¯¾å¿œï¼‰
# =============================================================================

def forecast_with_vertex_ai(
    df: pd.DataFrame,
    periods: int,
    method: str = "Vertex AI",
    product_id: str = "default"
) -> Tuple[pd.DataFrame, str]:
    """
    äºˆæ¸¬æ–¹æ³•ã«å¿œã˜ãŸäºˆæ¸¬ã‚’å®Ÿè¡Œ
    
    Args:
        df: å£²ä¸Šãƒ‡ãƒ¼ã‚¿
        periods: äºˆæ¸¬æ—¥æ•°
        method: äºˆæ¸¬æ–¹æ³•
        product_id: å•†å“è­˜åˆ¥å­
    
    Returns:
        äºˆæ¸¬DataFrame, ä½¿ç”¨ã—ãŸäºˆæ¸¬æ–¹æ³•ã®èª¬æ˜
    """
    if method == "ğŸš€ Vertex AIï¼ˆæ¨å¥¨ï¼‰":
        predictions, used_vertex_ai, message = get_vertex_ai_prediction(df, periods, product_id, use_covariates=True)
        return predictions, message
    
    elif method == "ç§»å‹•å¹³å‡æ³•ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ï¼‰":
        return forecast_moving_average(df, periods), "ç§»å‹•å¹³å‡æ³•ï¼ˆçµ±è¨ˆãƒ¢ãƒ‡ãƒ«ï¼‰"
    
    elif method == "å­£ç¯€æ€§è€ƒæ…®ï¼ˆçµ±è¨ˆï¼‰":
        return forecast_with_seasonality_fallback(df, periods), "å­£ç¯€æ€§è€ƒæ…®ï¼ˆçµ±è¨ˆãƒ¢ãƒ‡ãƒ«ï¼‰"
    
    elif method == "æŒ‡æ•°å¹³æ»‘æ³•":
        return forecast_exponential_smoothing(df, periods), "æŒ‡æ•°å¹³æ»‘æ³•ï¼ˆçµ±è¨ˆãƒ¢ãƒ‡ãƒ«ï¼‰"
    
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯Vertex AI
        predictions, used_vertex_ai, message = get_vertex_ai_prediction(df, periods, product_id, use_covariates=True)
        return predictions, message


def forecast_moving_average(df: pd.DataFrame, periods: int, window: int = 30) -> pd.DataFrame:
    """ç§»å‹•å¹³å‡æ³•ã«ã‚ˆã‚‹äºˆæ¸¬"""
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'])
    df = df.sort_values('date')
    
    recent_data = df.tail(window)
    base_mean = recent_data['è²©å£²å•†å“æ•°'].mean()
    
    if pd.isna(base_mean) or base_mean <= 0:
        base_mean = 1.0
    
    last_date = df['date'].max()
    future_dates = pd.date_range(start=last_date + timedelta(days=1), periods=periods, freq='D')
    
    predictions = []
    for d in future_dates:
        pred = max(0.1, base_mean)
        predictions.append({
            'date': d,
            'predicted': round(pred)
        })
    
    return pd.DataFrame(predictions)


def forecast_exponential_smoothing(df: pd.DataFrame, periods: int, alpha: float = 0.3) -> pd.DataFrame:
    """æŒ‡æ•°å¹³æ»‘æ³•ã«ã‚ˆã‚‹äºˆæ¸¬"""
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'])
    df = df.sort_values('date')
    
    values = df['è²©å£²å•†å“æ•°'].values
    
    if len(values) == 0:
        return pd.DataFrame({'date': [], 'predicted': []})
    
    smoothed = [values[0]]
    for i in range(1, len(values)):
        smoothed_value = alpha * values[i] + (1 - alpha) * smoothed[-1]
        smoothed.append(smoothed_value)
    
    base_prediction = smoothed[-1] if smoothed else 1.0
    
    if pd.isna(base_prediction) or base_prediction <= 0:
        base_prediction = 1.0
    
    if len(smoothed) >= 7:
        recent_trend = (smoothed[-1] - smoothed[-7]) / 7
    else:
        recent_trend = 0
    
    last_date = df['date'].max()
    future_dates = pd.date_range(start=last_date + timedelta(days=1), periods=periods, freq='D')
    
    predictions = []
    for i, d in enumerate(future_dates):
        decay_factor = 0.95 ** i
        pred = base_prediction + (recent_trend * i * decay_factor)
        pred = max(0.1, pred)
        
        predictions.append({
            'date': d,
            'predicted': round(pred)
        })
    
    return pd.DataFrame(predictions)


def forecast_all_methods_with_vertex_ai(df: pd.DataFrame, periods: int, product_id: str = "default") -> Dict[str, Tuple[pd.DataFrame, str]]:
    """
    ã™ã¹ã¦ã®äºˆæ¸¬æ–¹æ³•ã§äºˆæ¸¬ã‚’å®Ÿè¡Œï¼ˆVertex AIå«ã‚€ï¼‰
    """
    results = {}
    
    # Vertex AIäºˆæ¸¬
    if VERTEX_AI_AVAILABLE:
        predictions, used_vertex_ai, message = get_vertex_ai_prediction(df, periods, product_id)
        results['Vertex AI'] = (predictions, message)
    
    # çµ±è¨ˆãƒ¢ãƒ‡ãƒ«äºˆæ¸¬
    results['å­£ç¯€æ€§è€ƒæ…®'] = (forecast_with_seasonality_fallback(df, periods), "å­£ç¯€æ€§è€ƒæ…®ï¼ˆçµ±è¨ˆãƒ¢ãƒ‡ãƒ«ï¼‰")
    results['ç§»å‹•å¹³å‡æ³•'] = (forecast_moving_average(df, periods), "ç§»å‹•å¹³å‡æ³•ï¼ˆçµ±è¨ˆãƒ¢ãƒ‡ãƒ«ï¼‰")
    results['æŒ‡æ•°å¹³æ»‘æ³•'] = (forecast_exponential_smoothing(df, periods), "æŒ‡æ•°å¹³æ»‘æ³•ï¼ˆçµ±è¨ˆãƒ¢ãƒ‡ãƒ«ï¼‰")
    
    return results


# =============================================================================
# äºˆæ¸¬æ–¹æ³•ã®å®šç¾©ï¼ˆv12æ›´æ–°ï¼‰
# =============================================================================

FORECAST_METHODS = {
    "ğŸš€ Vertex AIï¼ˆæ¨å¥¨ï¼‰": {
        "description": "Google Cloud AutoML Forecastingã«ã‚ˆã‚‹é«˜ç²¾åº¦äºˆæ¸¬ã€‚å¤©æ°—ãƒ»å…­æ›œãƒ»ã‚¤ãƒ™ãƒ³ãƒˆã‚’è€ƒæ…®ã€‚",
        "icon": "ğŸš€",
        "color": "#4285F4",
        "requires_vertex_ai": True
    },
    "å­£ç¯€æ€§è€ƒæ…®ï¼ˆçµ±è¨ˆï¼‰": {
        "description": "æœˆåˆ¥ãƒ»æ›œæ—¥åˆ¥ã®å‚¾å‘ã¨ç‰¹åˆ¥æœŸé–“ã‚’è€ƒæ…®ã—ãŸçµ±è¨ˆãƒ¢ãƒ‡ãƒ«ã€‚Vertex AIæœªè¨­å®šæ™‚ã®æ¨å¥¨ã€‚",
        "icon": "ğŸ“ˆ",
        "color": "#4CAF50",
        "requires_vertex_ai": False
    },
    "ç§»å‹•å¹³å‡æ³•ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ï¼‰": {
        "description": "éå»30æ—¥é–“ã®å¹³å‡å€¤ã‚’ãƒ™ãƒ¼ã‚¹ã«äºˆæ¸¬ã€‚å®‰å®šã—ãŸå•†å“å‘ã‘ã€‚",
        "icon": "ğŸ“Š",
        "color": "#1E88E5",
        "requires_vertex_ai": False
    },
    "æŒ‡æ•°å¹³æ»‘æ³•": {
        "description": "ç›´è¿‘ã®ãƒ‡ãƒ¼ã‚¿ã‚’é‡è¦–ã—ãŸäºˆæ¸¬ã€‚ãƒˆãƒ¬ãƒ³ãƒ‰ã®å¤‰åŒ–ã«æ•æ„Ÿã€‚",
        "icon": "ğŸ“‰",
        "color": "#FF9800",
        "requires_vertex_ai": False
    },
    "ğŸ”„ ã™ã¹ã¦ã®æ–¹æ³•ã§æ¯”è¼ƒ": {
        "description": "Vertex AIã¨çµ±è¨ˆãƒ¢ãƒ‡ãƒ«ã™ã¹ã¦ã§äºˆæ¸¬ã—ã€çµæœã‚’æ¯”è¼ƒã—ã¾ã™ã€‚",
        "icon": "ğŸ”„",
        "color": "#9C27B0",
        "requires_vertex_ai": False
    }
}

# ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥ã®ç‰¹æ€§ï¼ˆæ–°è¦æˆä¸å“äºˆæ¸¬ç”¨ï¼‰
CATEGORY_CHARACTERISTICS = {
    "ãŠå®ˆã‚Š": {"seasonality": "high", "base_daily": 3.0, "price_range": (500, 1500)},
    "å¾¡æœ±å°": {"seasonality": "medium", "base_daily": 5.0, "price_range": (300, 500)},
    "å¾¡æœ±å°å¸³": {"seasonality": "low", "base_daily": 1.0, "price_range": (1500, 3000)},
    "ãŠã¿ãã˜": {"seasonality": "high", "base_daily": 10.0, "price_range": (100, 300)},
    "çµµé¦¬": {"seasonality": "high", "base_daily": 2.0, "price_range": (500, 1000)},
    "ãŠæœ­": {"seasonality": "high", "base_daily": 1.5, "price_range": (500, 3000)},
    "ç¸èµ·ç‰©": {"seasonality": "medium", "base_daily": 1.0, "price_range": (500, 5000)},
    "ãã®ä»–": {"seasonality": "low", "base_daily": 0.5, "price_range": (500, 2000)},
}


# =============================================================================
# ãƒšãƒ¼ã‚¸è¨­å®š
# =============================================================================

st.set_page_config(
    page_title="Airãƒ¬ã‚¸ å£²ä¸Šåˆ†æï¼ˆVertex AIç‰ˆï¼‰",
    page_icon="â›©ï¸",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    /* ============================================
       åŸºæœ¬ã‚¹ã‚¿ã‚¤ãƒ«
       ============================================ */
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1E88E5;
        margin-bottom: 1rem;
    }
    .section-header {
        font-size: 1.5rem;
        font-weight: bold;
        color: #333;
        border-bottom: 2px solid #1E88E5;
        padding-bottom: 0.5rem;
        margin: 1.5rem 0 1rem 0;
    }
    .accuracy-good { color: #4CAF50; font-weight: bold; }
    .accuracy-medium { color: #FF9800; font-weight: bold; }
    .accuracy-poor { color: #F44336; font-weight: bold; }
    .new-product-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        border-radius: 15px;
        padding: 20px;
        color: white;
        margin: 10px 0;
    }
    .analysis-card {
        background: linear-gradient(135deg, #f5f7fa 0%, #e4e8eb 100%);
        border-radius: 10px;
        padding: 15px;
        margin: 10px 0;
        border-left: 4px solid #1E88E5;
    }
    .method-card {
        background: #f8f9fa;
        border-radius: 8px;
        padding: 12px;
        margin: 8px 0;
        border-left: 3px solid;
    }
    .method-vertex-ai { border-left-color: #4285F4; background: #e8f0fe; }
    .method-seasonality { border-left-color: #4CAF50; }
    .method-moving-avg { border-left-color: #1E88E5; }
    .method-exponential { border-left-color: #FF9800; }
    .vertex-ai-status {
        padding: 10px 15px;
        border-radius: 8px;
        margin: 10px 0;
    }
    .vertex-ai-available {
        background: #e8f5e9;
        border: 1px solid #4CAF50;
        color: #2e7d32;
    }
    .vertex-ai-unavailable {
        background: #fff3e0;
        border: 1px solid #FF9800;
        color: #e65100;
    }
    .individual-product-box {
        background: #f0f8ff;
        border-radius: 10px;
        padding: 15px;
        margin: 10px 0;
        border: 1px solid #1E88E5;
    }
    
    /* ============================================
       ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®šï¼ˆæ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«é˜²æ­¢ï¼‰
       ============================================ */
    .main .block-container {
        max-width: 100%;
        padding-left: 1rem;
        padding-right: 1rem;
        overflow-x: hidden;
    }
    
    /* ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®æ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯¾å¿œ */
    [data-testid="stDataFrame"] {
        width: 100%;
    }
    [data-testid="stDataFrame"] > div {
        overflow-x: auto;
        -webkit-overflow-scrolling: touch;
    }
    
    /* ============================================
       ã‚¹ãƒãƒ›å¯¾å¿œï¼ˆ768pxä»¥ä¸‹ï¼‰
       ============================================ */
    @media screen and (max-width: 768px) {
        /* ãƒ˜ãƒƒãƒ€ãƒ¼ */
        .main-header {
            font-size: 1.4rem;
            text-align: center;
        }
        .section-header {
            font-size: 1.1rem;
        }
        
        /* ã‚«ãƒ©ãƒ ã‚’ç¸¦ä¸¦ã³ã« */
        [data-testid="column"] {
            width: 100% !important;
            flex: 1 1 100% !important;
            min-width: 100% !important;
        }
        
        /* ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆæ•°å€¤è¡¨ç¤ºï¼‰ã‚’ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã« */
        [data-testid="metric-container"] {
            padding: 8px 5px;
            background: #f8f9fa;
            border-radius: 8px;
            margin: 4px 0;
        }
        [data-testid="stMetricLabel"] {
            font-size: 0.75rem !important;
        }
        [data-testid="stMetricValue"] {
            font-size: 1.1rem !important;
        }
        
        /* ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’2åˆ—è¡¨ç¤ºã« */
        [data-testid="stHorizontalBlock"] {
            flex-wrap: wrap;
            gap: 8px;
        }
        [data-testid="stHorizontalBlock"] > [data-testid="column"] {
            flex: 1 1 45% !important;
            min-width: 45% !important;
            max-width: 48% !important;
        }
        
        /* ã‚¿ãƒ– */
        .stTabs [data-baseweb="tab-list"] {
            gap: 0;
            overflow-x: auto;
            -webkit-overflow-scrolling: touch;
            scrollbar-width: none;
        }
        .stTabs [data-baseweb="tab-list"]::-webkit-scrollbar {
            display: none;
        }
        .stTabs [data-baseweb="tab"] {
            font-size: 0.75rem;
            padding: 8px 10px;
            white-space: nowrap;
        }
        
        /* ãƒœã‚¿ãƒ³ */
        .stButton > button {
            width: 100%;
            padding: 12px 16px;
            font-size: 0.9rem;
        }
        
        /* å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ */
        .stSelectbox, .stNumberInput, .stTextInput {
            margin-bottom: 8px;
        }
        .stSelectbox label, .stNumberInput label, .stTextInput label {
            font-size: 0.8rem;
        }
        
        /* ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã‚’ç¸¦ä¸¦ã³ã« */
        [data-testid="stRadio"] > div {
            flex-direction: column;
            gap: 8px;
        }
        [data-testid="stRadio"] label {
            font-size: 0.85rem;
        }
        
        /* ã‚«ãƒ¼ãƒ‰ */
        .analysis-card, .method-card {
            padding: 10px;
            font-size: 0.85rem;
        }
        .new-product-card {
            padding: 15px;
        }
        .new-product-card h2 {
            font-size: 1.1rem;
        }
        .new-product-card p {
            font-size: 0.85rem;
        }
        
        /* ã‚°ãƒ©ãƒ• */
        .js-plotly-plot {
            margin: 0 -10px;
        }
        .js-plotly-plot .plotly .modebar {
            display: none !important;
        }
        
        /* Expander */
        .streamlit-expanderHeader {
            font-size: 0.9rem;
            padding: 10px;
        }
        
        /* Info/Warning/Errorãƒœãƒƒã‚¯ã‚¹ */
        [data-testid="stAlert"] {
            padding: 10px;
            font-size: 0.85rem;
        }
        
        /* Divider */
        hr {
            margin: 15px 0;
        }
        
        /* é¸æŠä¸­ã®æˆä¸å“ */
        .product-tag {
            font-size: 0.8rem;
            padding: 4px 10px;
        }
    }
    
    /* ============================================
       ã‚¿ãƒ–ãƒ¬ãƒƒãƒˆå¯¾å¿œï¼ˆ769pxã€œ1024pxï¼‰
       ============================================ */
    @media screen and (min-width: 769px) and (max-width: 1024px) {
        .main-header {
            font-size: 2rem;
        }
        [data-testid="column"] {
            min-width: 45% !important;
        }
    }
    
    /* ============================================
       é¸æŠä¸­ã®æˆä¸å“ã®å‰Šé™¤ãƒœã‚¿ãƒ³
       ============================================ */
    .product-tag {
        display: inline-flex;
        align-items: center;
        background: #e3f2fd;
        border-radius: 20px;
        padding: 5px 12px;
        margin: 3px;
        font-size: 0.9rem;
    }
    .product-tag-remove {
        margin-left: 8px;
        cursor: pointer;
        color: #666;
        font-weight: bold;
    }
    .product-tag-remove:hover {
        color: #f44336;
    }
    
    /* ============================================
       ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
       ============================================ */
    /* ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è»½é‡åŒ– */
    * {
        -webkit-tap-highlight-color: transparent;
    }
    .stApp {
        -webkit-font-smoothing: antialiased;
    }
</style>
""", unsafe_allow_html=True)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'data_loader' not in st.session_state:
    st.session_state.data_loader = None
if 'normalizer' not in st.session_state:
    st.session_state.normalizer = None
if 'selected_products' not in st.session_state:
    st.session_state.selected_products = []
if 'categories' not in st.session_state:
    st.session_state.categories = {}
if 'sales_data' not in st.session_state:
    st.session_state.sales_data = None
if 'forecast_data' not in st.session_state:
    st.session_state.forecast_data = None
if 'forecast_total' not in st.session_state:
    st.session_state.forecast_total = 0
if 'forecast_results' not in st.session_state:
    st.session_state.forecast_results = {}
if 'analysis_mode' not in st.session_state:
    st.session_state.analysis_mode = "åˆç®—"
if 'individual_sales_data' not in st.session_state:
    st.session_state.individual_sales_data = {}
if 'last_forecast_method' not in st.session_state:
    st.session_state.last_forecast_method = ""
if 'product_to_remove' not in st.session_state:
    st.session_state.product_to_remove = None
if 'clear_all_flag' not in st.session_state:
    st.session_state.clear_all_flag = False
if 'individual_forecast_results' not in st.session_state:
    st.session_state.individual_forecast_results = []


# =============================================================================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# =============================================================================

def round_up_to_50(value: int) -> int:
    """50ã®å€æ•°ã«åˆ‡ã‚Šä¸Šã’"""
    if value <= 0:
        return 0
    return ((value + 49) // 50) * 50


def get_available_forecast_methods() -> List[str]:
    """åˆ©ç”¨å¯èƒ½ãªäºˆæ¸¬æ–¹æ³•ã®ãƒªã‚¹ãƒˆã‚’å–å¾—"""
    methods = []
    for method_name, method_info in FORECAST_METHODS.items():
        if method_info.get('requires_vertex_ai', False) and not VERTEX_AI_AVAILABLE:
            continue
        methods.append(method_name)
    return methods


def get_mobile_chart_config() -> dict:
    """ã‚¹ãƒãƒ›æœ€é©åŒ–ã•ã‚ŒãŸPlotlyãƒãƒ£ãƒ¼ãƒˆè¨­å®šã‚’å–å¾—"""
    return {
        'displayModeBar': False,  # ãƒ„ãƒ¼ãƒ«ãƒãƒ¼éè¡¨ç¤º
        'staticPlot': False,      # æ“ä½œã¯å¯èƒ½
        'responsive': True,       # ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–
        'scrollZoom': False,      # ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã‚ºãƒ¼ãƒ ç„¡åŠ¹
    }


def get_mobile_chart_layout(title: str = '', height: int = 300) -> dict:
    """ã‚¹ãƒãƒ›æœ€é©åŒ–ã•ã‚ŒãŸPlotlyãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­å®šã‚’å–å¾—"""
    return {
        'title': dict(text=title, font=dict(size=14)),
        'height': height,
        'margin': dict(l=40, r=20, t=40, b=40),
        'legend': dict(
            orientation='h',
            yanchor='bottom',
            y=1.02,
            xanchor='center',
            x=0.5,
            font=dict(size=10)
        ),
        'xaxis': dict(
            tickfont=dict(size=10),
            title=dict(font=dict(size=11))
        ),
        'yaxis': dict(
            tickfont=dict(size=10),
            title=dict(font=dict(size=11))
        ),
        'dragmode': False,
        'hovermode': 'x unified',
    }


# =============================================================================
# ãƒ‡ãƒ¼ã‚¿åˆæœŸåŒ–
# =============================================================================

def init_data():
    """ãƒ‡ãƒ¼ã‚¿ã‚’åˆæœŸåŒ–"""
    if st.session_state.data_loader is None:
        try:
            st.session_state.data_loader = SheetsDataLoader()
        except Exception as e:
            st.error(f"ãƒ‡ãƒ¼ã‚¿æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    if st.session_state.normalizer is None:
        try:
            df_items = st.session_state.data_loader.load_item_sales()
            st.session_state.normalizer = ProductNormalizer()
            st.session_state.normalizer.build_master(df_items, "å•†å“å")
            build_categories()
        except Exception as e:
            st.error(f"æˆä¸å“ãƒã‚¹ã‚¿æ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {e}")
    
    return True


def build_categories():
    """ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’Dåˆ—ã‹ã‚‰å–å¾—"""
    if st.session_state.data_loader is None:
        return
    
    df_items = st.session_state.data_loader.load_item_sales()
    
    if df_items.empty:
        return
    
    categories = defaultdict(list)
    
    category_col = None
    for col in df_items.columns:
        if 'ã‚«ãƒ†ã‚´ãƒª' in col or col == 'ã‚«ãƒ†ã‚´ãƒªãƒ¼' or col == 'category':
            category_col = col
            break
    
    if category_col is None and len(df_items.columns) >= 4:
        category_col = df_items.columns[3]
    
    if category_col is None:
        return
    
    product_col = None
    for col in df_items.columns:
        if 'å•†å“å' in col or col == 'å•†å“' or col == 'product':
            product_col = col
            break
    
    if product_col is None and len(df_items.columns) >= 3:
        product_col = df_items.columns[2]
    
    if product_col is None:
        return
    
    for _, row in df_items[[product_col, category_col]].drop_duplicates().iterrows():
        product_name = row[product_col]
        category = row[category_col]
        
        if pd.isna(category) or str(category).strip() == '':
            category = 'ãã®ä»–'
        
        if st.session_state.normalizer:
            normalized = st.session_state.normalizer.normalize(product_name)
            if normalized and normalized not in categories[category]:
                categories[category].append(normalized)
    
    st.session_state.categories = dict(categories)


# =============================================================================
# ãƒ˜ãƒƒãƒ€ãƒ¼
# =============================================================================

def render_header():
    """ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æç”»"""
    col1, col2 = st.columns([4, 1])
    
    with col1:
        st.markdown('<p class="main-header">â›©ï¸ æˆä¸å“ å£²ä¸Šåˆ†æãƒ»éœ€è¦äºˆæ¸¬</p>', unsafe_allow_html=True)
    
    with col2:
        if st.button("ğŸ”„ ãƒ‡ãƒ¼ã‚¿æ›´æ–°"):
            st.cache_data.clear()
            st.session_state.data_loader = None
            st.session_state.selected_products = []
            st.session_state.sales_data = None
            st.session_state.forecast_data = None
            st.session_state.forecast_results = {}
            st.session_state.individual_sales_data = {}
            st.rerun()
    
    # Vertex AIã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
    if VERTEX_AI_AVAILABLE:
        st.markdown(f"""
        <div class="vertex-ai-status vertex-ai-available">
            âœ… <strong>Vertex AI AutoML Forecasting:</strong> æ¥ç¶šæ¸ˆã¿
            ï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {VERTEX_AI_CONFIG['project_id']}, ãƒªãƒ¼ã‚¸ãƒ§ãƒ³: {VERTEX_AI_CONFIG['location']}ï¼‰
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown("""
        <div class="vertex-ai-status vertex-ai-unavailable">
            âš ï¸ <strong>Vertex AI:</strong> æœªè¨­å®šï¼ˆçµ±è¨ˆãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ã—ã¾ã™ï¼‰
        </div>
        """, unsafe_allow_html=True)
    
    if st.session_state.data_loader:
        min_date, max_date = st.session_state.data_loader.get_date_range()
        if min_date and max_date:
            st.caption(f"ğŸ“… ãƒ‡ãƒ¼ã‚¿æœŸé–“: {min_date.strftime('%Yå¹´%mæœˆ%dæ—¥')} ã€œ {max_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}")


# =============================================================================
# ãƒ¡ã‚¤ãƒ³ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
# =============================================================================

def render_main_tabs():
    """ãƒ¡ã‚¤ãƒ³ã‚¿ãƒ–ã‚’æç”»"""
    tab_labels = [
        "ğŸ“Š æ—¢å­˜æˆä¸å“ã®åˆ†æãƒ»äºˆæ¸¬",
        "âœ¨ æ–°è¦æˆä¸å“ã®éœ€è¦äºˆæ¸¬",
        "âš™ï¸ Vertex AIè¨­å®š",
    ]
    
    if ADVANCED_ANALYSIS_AVAILABLE:
        tab_labels.append("ğŸ”¬ é«˜åº¦ãªåˆ†æ")
    
    tab_labels.append("ğŸ“ˆ äºˆæ¸¬ç²¾åº¦ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
    
    tabs = st.tabs(tab_labels)
    
    tab_idx = 0
    
    with tabs[tab_idx]:
        render_existing_product_analysis()
    tab_idx += 1
    
    with tabs[tab_idx]:
        render_new_product_forecast()
    tab_idx += 1
    
    with tabs[tab_idx]:
        render_vertex_ai_settings()
    tab_idx += 1
    
    if ADVANCED_ANALYSIS_AVAILABLE:
        with tabs[tab_idx]:
            render_advanced_analysis()
        tab_idx += 1
    
    with tabs[tab_idx]:
        render_accuracy_dashboard()


# =============================================================================
# Vertex AIè¨­å®šã‚¿ãƒ–
# =============================================================================

def render_vertex_ai_settings():
    """Vertex AIè¨­å®šã‚¿ãƒ–"""
    st.markdown('<p class="section-header">âš™ï¸ Vertex AI AutoML Forecasting è¨­å®š</p>', unsafe_allow_html=True)
    
    # ç¾åœ¨ã®è¨­å®šçŠ¶æ³
    st.write("### ğŸ“‹ ç¾åœ¨ã®è¨­å®šçŠ¶æ³")
    
    config_status = {
        'ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆID': VERTEX_AI_CONFIG['project_id'] or 'æœªè¨­å®š',
        'ãƒªãƒ¼ã‚¸ãƒ§ãƒ³': VERTEX_AI_CONFIG['location'] or 'æœªè¨­å®š',
        'ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆID': VERTEX_AI_CONFIG['endpoint_id'] or 'æœªè¨­å®š',
        'ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«': VERTEX_AI_CONFIG['service_account_file'],
        'ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨': 'âœ… ã‚ã‚Š' if os.path.exists(VERTEX_AI_CONFIG['service_account_file']) else 'âŒ ãªã—',
        'Vertex AIåˆ©ç”¨å¯èƒ½': 'âœ… ã¯ã„' if VERTEX_AI_AVAILABLE else 'âŒ ã„ã„ãˆ',
    }
    
    for key, value in config_status.items():
        st.write(f"- **{key}**: {value}")
    
    st.divider()
    
    # è¨­å®šæ–¹æ³•ã®èª¬æ˜
    st.write("### ğŸ”§ è¨­å®šæ–¹æ³•")
    
    st.markdown("""
    **æ–¹æ³•1: ç’°å¢ƒå¤‰æ•°ã§è¨­å®š**
    ```bash
    export VERTEX_AI_PROJECT_ID="your-project-id"
    export VERTEX_AI_LOCATION="asia-northeast1"
    export VERTEX_AI_ENDPOINT_ID="your-endpoint-id"
    export VERTEX_AI_SERVICE_ACCOUNT_FILE="path/to/service_account.json"
    ```
    
    **æ–¹æ³•2: config.pyã§è¨­å®š**
    ```python
    # config.py
    VERTEX_AI_PROJECT_ID = "your-project-id"
    VERTEX_AI_LOCATION = "asia-northeast1"
    VERTEX_AI_ENDPOINT_ID = "your-endpoint-id"
    VERTEX_AI_SERVICE_ACCOUNT_FILE = "service_account.json"
    ```
    """)
    
    st.divider()
    
    # AutoML Forecastingãƒ¢ãƒ‡ãƒ«ã®ä½œæˆæ‰‹é †
    st.write("### ğŸ“š AutoML Forecastingãƒ¢ãƒ‡ãƒ«ã®ä½œæˆæ‰‹é †")
    
    with st.expander("1ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™", expanded=False):
        st.markdown("""
        Vertex AI AutoML Forecastingã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿å½¢å¼ï¼š
        
        | ã‚«ãƒ©ãƒ  | èª¬æ˜ | ä¾‹ |
        |--------|------|-----|
        | timestamp | æ™‚é–“åˆ—ï¼ˆISOå½¢å¼ï¼‰ | 2025-01-01T00:00:00Z |
        | target | äºˆæ¸¬å¯¾è±¡ï¼ˆè²©å£²æ•°ï¼‰ | 15 |
        | time_series_identifier | ç³»åˆ—è­˜åˆ¥å­ï¼ˆå•†å“IDç­‰ï¼‰ | product_001 |
        | weekday | æ›œæ—¥ï¼ˆå…±å¤‰é‡ï¼‰ | 0-6 |
        | is_holiday | ä¼‘æ—¥ãƒ•ãƒ©ã‚°ï¼ˆå…±å¤‰é‡ï¼‰ | 0 or 1 |
        | weather | å¤©æ°—ï¼ˆå…±å¤‰é‡ï¼‰ | sunny, rainy, etc. |
        """)
    
    with st.expander("2ï¸âƒ£ ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°", expanded=False):
        st.markdown("""
        1. [Google Cloud Console](https://console.cloud.google.com/vertex-ai) ã«ã‚¢ã‚¯ã‚»ã‚¹
        2. ã€Œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€â†’ã€Œä½œæˆã€â†’ã€Œæ™‚ç³»åˆ—äºˆæ¸¬ã€ã‚’é¸æŠ
        3. CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ã‚«ãƒ©ãƒ ã‚’è¨­å®š
        4. ã€Œãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã€â†’ã€ŒAutoMLã€ã‚’é¸æŠ
        5. ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†ã‚’å¾…ã¤ï¼ˆæ•°æ™‚é–“ã€œï¼‰
        """)
    
    with st.expander("3ï¸âƒ£ ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ãƒ‡ãƒ—ãƒ­ã‚¤", expanded=False):
        st.markdown("""
        1. ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ
        2. ã€Œãƒ‡ãƒ—ãƒ­ã‚¤ã¨ãƒ†ã‚¹ãƒˆã€â†’ã€Œã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«ãƒ‡ãƒ—ãƒ­ã‚¤ã€
        3. ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆåã‚’è¨­å®šã—ã¦ãƒ‡ãƒ—ãƒ­ã‚¤
        4. ãƒ‡ãƒ—ãƒ­ã‚¤å®Œäº†å¾Œã€ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆIDã‚’ã‚³ãƒ”ãƒ¼
        """)
    
    with st.expander("4ï¸âƒ£ ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®è¨­å®š", expanded=False):
        st.markdown("""
        1. ã€ŒIAMã¨ç®¡ç†ã€â†’ã€Œã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã€
        2. ã€Œã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ä½œæˆã€
        3. ä»¥ä¸‹ã®ãƒ­ãƒ¼ãƒ«ã‚’ä»˜ä¸ï¼š
           - Vertex AI ãƒ¦ãƒ¼ã‚¶ãƒ¼
           - Vertex AI äºˆæ¸¬ãƒ¦ãƒ¼ã‚¶ãƒ¼
        4. ã€Œéµã‚’ä½œæˆã€â†’ JSONå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        5. ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚©ãƒ«ãƒ€ã«é…ç½®
        """)
    
    # æ¥ç¶šãƒ†ã‚¹ãƒˆ
    st.divider()
    st.write("### ğŸ§ª æ¥ç¶šãƒ†ã‚¹ãƒˆ")
    
    if st.button("ğŸ” Vertex AIæ¥ç¶šã‚’ãƒ†ã‚¹ãƒˆ", type="primary"):
        if not VERTEX_AI_AVAILABLE:
            st.error("Vertex AIãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ä¸Šè¨˜ã®è¨­å®šã‚’å®Œäº†ã—ã¦ãã ã•ã„ã€‚")
        else:
            with st.spinner("æ¥ç¶šãƒ†ã‚¹ãƒˆä¸­..."):
                try:
                    forecaster = get_vertex_ai_forecaster()
                    # ç°¡å˜ãªãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§æ¥ç¶šç¢ºèª
                    test_df = pd.DataFrame({
                        'date': pd.date_range(start='2025-01-01', periods=30, freq='D'),
                        'è²©å£²å•†å“æ•°': np.random.randint(1, 10, 30)
                    })
                    predictions, metadata = forecaster.predict(test_df, 7, "test_product")
                    st.success(f"âœ… æ¥ç¶šæˆåŠŸï¼ãƒ¢ãƒ‡ãƒ«ID: {metadata.get('deployed_model_id', 'N/A')}")
                    st.write("ãƒ†ã‚¹ãƒˆäºˆæ¸¬çµæœ:")
                    st.dataframe(predictions.head())
                except Exception as e:
                    st.error(f"âŒ æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")


# =============================================================================
# æ—¢å­˜æˆä¸å“ã®åˆ†æ
# =============================================================================

def render_existing_product_analysis():
    """æ—¢å­˜æˆä¸å“ã®åˆ†æãƒ»äºˆæ¸¬"""
    render_product_selection()
    start_date, end_date = render_period_selection()
    
    if len(st.session_state.selected_products) > 1:
        render_analysis_mode_selection()
    
    if st.session_state.analysis_mode == "å€‹åˆ¥":
        render_individual_analysis(start_date, end_date)
    else:
        sales_data = render_sales_analysis(start_date, end_date)
        render_forecast_section(sales_data)
        render_delivery_section()


def render_analysis_mode_selection():
    """åˆç®—/å€‹åˆ¥ãƒ¢ãƒ¼ãƒ‰ã®é¸æŠ"""
    st.markdown('<p class="section-header">ğŸ“Š åˆ†æãƒ¢ãƒ¼ãƒ‰</p>', unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        mode = st.radio(
            "è¤‡æ•°æˆä¸å“ã®åˆ†ææ–¹æ³•",
            ["åˆç®—", "å€‹åˆ¥"],
            index=0 if st.session_state.analysis_mode == "åˆç®—" else 1,
            horizontal=True,
            help="åˆç®—ï¼šé¸æŠã—ãŸæˆä¸å“ã®åˆè¨ˆã‚’åˆ†æ\nå€‹åˆ¥ï¼šæˆä¸å“ã”ã¨ã«åˆ¥ã€…ã«åˆ†æ"
        )
        st.session_state.analysis_mode = mode
    
    with col2:
        if mode == "åˆç®—":
            st.info(f"ğŸ“Š {len(st.session_state.selected_products)}ä»¶ã®æˆä¸å“ã‚’**åˆè¨ˆ**ã—ã¦åˆ†æã—ã¾ã™")
        else:
            st.info(f"ğŸ“Š {len(st.session_state.selected_products)}ä»¶ã®æˆä¸å“ã‚’**å€‹åˆ¥**ã«åˆ†æã—ã¾ã™")


def render_product_selection():
    """æˆä¸å“é¸æŠã‚»ã‚¯ã‚·ãƒ§ãƒ³"""
    st.markdown('<p class="section-header">â‘  æˆä¸å“ã‚’é¸ã¶</p>', unsafe_allow_html=True)
    
    tab1, tab2 = st.tabs(["ğŸ” åå‰ã§æ¤œç´¢", "ğŸ“ ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‹ã‚‰é¸ã¶"])
    
    with tab1:
        render_search_tab()
    
    with tab2:
        render_category_tab()
    
    render_selected_products()


def render_search_tab():
    """åå‰æ¤œç´¢ã‚¿ãƒ–"""
    search_query = st.text_input(
        "æˆä¸å“åã‚’å…¥åŠ›",
        placeholder="ä¾‹: é‡‘é‹ã€ãŠå®ˆã‚Šã€å¾¡æœ±å°å¸³...",
        key="search_input"
    )
    
    if search_query and st.session_state.normalizer:
        results = st.session_state.normalizer.search(search_query, limit=20)
        
        if results:
            st.write(f"**{len(results)}ä»¶** è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
            
            cols = st.columns(3)
            for i, result in enumerate(results):
                name = result['normalized_name']
                bracket = result.get('bracket_content', '')
                
                with cols[i % 3]:
                    is_selected = name in st.session_state.selected_products
                    label = f"{name}"
                    if bracket:
                        label += f" ({bracket})"
                    
                    if st.checkbox(label, value=is_selected, key=f"search_{name}"):
                        if name not in st.session_state.selected_products:
                            st.session_state.selected_products.append(name)
                    else:
                        if name in st.session_state.selected_products:
                            st.session_state.selected_products.remove(name)
        else:
            st.info("è©²å½“ã™ã‚‹æˆä¸å“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")


def render_category_tab():
    """ã‚«ãƒ†ã‚´ãƒªãƒ¼é¸æŠã‚¿ãƒ–"""
    if not st.session_state.categories:
        st.info("ã‚«ãƒ†ã‚´ãƒªãƒ¼æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    st.write("**ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’é¸æŠã—ã¦ä¸€æ‹¬è¿½åŠ ï¼š**")
    
    cols = st.columns(4)
    
    sorted_categories = sorted(
        st.session_state.categories.items(),
        key=lambda x: len(x[1]),
        reverse=True
    )
    
    for i, (category, products) in enumerate(sorted_categories[:12]):
        with cols[i % 4]:
            if st.button(f"ğŸ“ {category} ({len(products)}ä»¶)", key=f"cat_{category}"):
                for p in products:
                    if p not in st.session_state.selected_products:
                        st.session_state.selected_products.append(p)
                st.rerun()


def render_selected_products():
    """é¸æŠä¸­ã®æˆä¸å“ã‚’è¡¨ç¤ºï¼ˆå€‹åˆ¥å‰Šé™¤æ©Ÿèƒ½ä»˜ãï¼‰"""
    st.divider()
    
    if st.session_state.selected_products:
        col1, col2 = st.columns([3, 1])
        with col1:
            st.write(f"**âœ… é¸æŠä¸­ã®æˆä¸å“ï¼ˆ{len(st.session_state.selected_products)}ä»¶ï¼‰**")
        with col2:
            if st.button("ğŸ—‘ï¸ ã™ã¹ã¦ã‚¯ãƒªã‚¢", key="clear_all_btn_main"):
                st.session_state.selected_products = []
                st.session_state.analysis_mode = "åˆç®—"
                st.session_state.sales_data = None
                st.session_state.forecast_data = None
                st.session_state.individual_sales_data = {}
                st.session_state.individual_forecast_results = []
                st.rerun()
        
        # é¸æŠä¸­ã®å•†å“ã‚’è¡¨ç¤º
        st.markdown('<div style="background: #e3f2fd; border-radius: 10px; padding: 15px; margin: 10px 0;">', unsafe_allow_html=True)
        
        for product in st.session_state.selected_products:
            st.markdown(f"ğŸ“¦ **{product}**")
        
        st.markdown("</div>", unsafe_allow_html=True)
        
        # å‰Šé™¤ç”¨ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹
        st.write("**ğŸ—‘ï¸ å•†å“ã‚’å€‹åˆ¥ã«å‰Šé™¤**")
        product_to_delete = st.selectbox(
            "å‰Šé™¤ã™ã‚‹å•†å“ã‚’é¸æŠ",
            options=["ï¼ˆé¸æŠã—ã¦ãã ã•ã„ï¼‰"] + st.session_state.selected_products,
            key="product_delete_select",
            label_visibility="collapsed"
        )
        
        if product_to_delete != "ï¼ˆé¸æŠã—ã¦ãã ã•ã„ï¼‰":
            if st.button(f"ã€Œ{product_to_delete}ã€ã‚’å‰Šé™¤", key="delete_selected_product_btn", type="secondary"):
                st.session_state.selected_products.remove(product_to_delete)
                st.session_state.sales_data = None
                st.session_state.forecast_data = None
                st.session_state.individual_sales_data = {}
                st.session_state.individual_forecast_results = []
                st.rerun()
    else:
        st.warning("ğŸ‘† ä¸Šã‹ã‚‰æˆä¸å“ã‚’é¸ã‚“ã§ãã ã•ã„")


def render_period_selection():
    """æœŸé–“é¸æŠã‚»ã‚¯ã‚·ãƒ§ãƒ³"""
    st.markdown('<p class="section-header">â‘¡ æœŸé–“ã‚’é¸ã¶</p>', unsafe_allow_html=True)
    
    today = date.today()
    
    col1, col2 = st.columns([1, 3])
    
    with col1:
        preset = st.selectbox(
            "ãƒ—ãƒªã‚»ãƒƒãƒˆ",
            ["ã‚«ã‚¹ã‚¿ãƒ ", "éå»1ãƒ¶æœˆ", "éå»3ãƒ¶æœˆ", "éå»6ãƒ¶æœˆ", "éå»1å¹´", "éå»2å¹´", "å…¨æœŸé–“"],
            index=4
        )
    
    if preset == "éå»1ãƒ¶æœˆ":
        default_start = today - timedelta(days=30)
        default_end = today
    elif preset == "éå»3ãƒ¶æœˆ":
        default_start = today - timedelta(days=90)
        default_end = today
    elif preset == "éå»6ãƒ¶æœˆ":
        default_start = today - timedelta(days=180)
        default_end = today
    elif preset == "éå»1å¹´":
        default_start = today - timedelta(days=365)
        default_end = today
    elif preset == "éå»2å¹´":
        default_start = today - timedelta(days=730)
        default_end = today
    elif preset == "å…¨æœŸé–“":
        default_start = date(2022, 8, 1)
        default_end = today
    else:
        default_start = today - timedelta(days=365)
        default_end = today
    
    with col2:
        # é–‹å§‹æ—¥
        st.write("**é–‹å§‹æ—¥**")
        col_sy, col_sm, col_sd = st.columns(3)
        
        years = list(range(2022, today.year + 2))
        months_jp = ["1æœˆ", "2æœˆ", "3æœˆ", "4æœˆ", "5æœˆ", "6æœˆ", "7æœˆ", "8æœˆ", "9æœˆ", "10æœˆ", "11æœˆ", "12æœˆ"]
        
        with col_sy:
            start_year = st.selectbox(
                "å¹´",
                years,
                index=years.index(default_start.year) if default_start.year in years else 0,
                key="start_year",
                label_visibility="collapsed"
            )
            st.caption("å¹´")
        with col_sm:
            start_month = st.selectbox(
                "æœˆ",
                list(range(1, 13)),
                index=default_start.month - 1,
                format_func=lambda x: months_jp[x-1],
                key="start_month",
                label_visibility="collapsed"
            )
            st.caption("æœˆ")
        with col_sd:
            max_day_start = calendar.monthrange(start_year, start_month)[1]
            start_day = st.number_input(
                "æ—¥",
                min_value=1,
                max_value=max_day_start,
                value=min(default_start.day, max_day_start),
                key="start_day",
                label_visibility="collapsed"
            )
            st.caption("æ—¥")
        
        # çµ‚äº†æ—¥
        st.write("**çµ‚äº†æ—¥**")
        col_ey, col_em, col_ed = st.columns(3)
        
        with col_ey:
            end_year = st.selectbox(
                "å¹´",
                years,
                index=years.index(default_end.year) if default_end.year in years else 0,
                key="end_year",
                label_visibility="collapsed"
            )
            st.caption("å¹´")
        with col_em:
            end_month = st.selectbox(
                "æœˆ",
                list(range(1, 13)),
                index=default_end.month - 1,
                format_func=lambda x: months_jp[x-1],
                key="end_month",
                label_visibility="collapsed"
            )
            st.caption("æœˆ")
        with col_ed:
            max_day_end = calendar.monthrange(end_year, end_month)[1]
            end_day = st.number_input(
                "æ—¥",
                min_value=1,
                max_value=max_day_end,
                value=min(default_end.day, max_day_end),
                key="end_day",
                label_visibility="collapsed"
            )
            st.caption("æ—¥")
    
    start_date = date(start_year, start_month, start_day)
    end_date = date(end_year, end_month, end_day)
    
    if start_date > end_date:
        st.error("âš ï¸ é–‹å§‹æ—¥ãŒçµ‚äº†æ—¥ã‚ˆã‚Šå¾Œã«ãªã£ã¦ã„ã¾ã™")
        end_date = start_date
    
    return start_date, end_date


def render_sales_analysis(start_date: date, end_date: date):
    """å£²ä¸Šåˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³"""
    st.markdown('<p class="section-header">â‘¢ å£²ä¸Šã‚’è¦‹ã‚‹</p>', unsafe_allow_html=True)
    
    if not st.session_state.selected_products:
        st.info("æˆä¸å“ã‚’é¸æŠã™ã‚‹ã¨ã€ã“ã“ã«å£²ä¸ŠãŒè¡¨ç¤ºã•ã‚Œã¾ã™")
        return None
    
    df_items = st.session_state.data_loader.load_item_sales()
    
    if df_items.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return None
    
    mask = (df_items['date'] >= pd.Timestamp(start_date)) & (df_items['date'] <= pd.Timestamp(end_date))
    df_filtered = df_items[mask]
    
    original_names = st.session_state.normalizer.get_all_original_names(
        st.session_state.selected_products
    )
    
    df_agg = aggregate_by_products(df_filtered, original_names, aggregate=True)
    
    if df_agg.empty:
        st.warning("è©²å½“æœŸé–“ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return None
    
    df_agg = df_agg.sort_values('date').reset_index(drop=True)
    
    total_qty = int(df_agg['è²©å£²å•†å“æ•°'].sum())
    total_sales = df_agg['è²©å£²ç·å£²ä¸Š'].sum()
    period_days = (end_date - start_date).days + 1
    avg_daily = total_qty / period_days
    
    # å¹³æ—¥ãƒ»ä¼‘æ—¥ã®å¹³å‡ã‚’è¨ˆç®—
    df_agg['weekday'] = pd.to_datetime(df_agg['date']).dt.dayofweek
    df_weekday = df_agg[df_agg['weekday'] < 5]  # æœˆã€œé‡‘
    df_weekend = df_agg[df_agg['weekday'] >= 5]  # åœŸæ—¥
    
    avg_weekday = df_weekday['è²©å£²å•†å“æ•°'].mean() if not df_weekday.empty else 0
    avg_weekend = df_weekend['è²©å£²å•†å“æ•°'].mean() if not df_weekend.empty else 0
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤ºï¼ˆ2è¡Œã«åˆ†ã‘ã‚‹ï¼‰
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("ğŸ›’ è²©å£²æ•°é‡", f"{total_qty:,}ä½“")
    col2.metric("ğŸ’° å£²ä¸Šåˆè¨ˆ", f"Â¥{total_sales:,.0f}")
    col3.metric("ğŸ“ˆ å¹³å‡æ—¥è²©", f"{avg_daily:.1f}ä½“/æ—¥")
    col4.metric("ğŸ“… æœŸé–“", f"{period_days}æ—¥é–“")
    
    # å¹³æ—¥ãƒ»ä¼‘æ—¥ã®å¹³å‡ã‚’è¡¨ç¤º
    col5, col6, col7, col8 = st.columns(4)
    col5.metric("ğŸ“… å¹³æ—¥å¹³å‡", f"{avg_weekday:.1f}ä½“/æ—¥", help="æœˆã€œé‡‘æ›œæ—¥ã®å¹³å‡")
    col6.metric("ğŸŒ ä¼‘æ—¥å¹³å‡", f"{avg_weekend:.1f}ä½“/æ—¥", help="åœŸãƒ»æ—¥æ›œæ—¥ã®å¹³å‡")
    
    # ä¼‘æ—¥/å¹³æ—¥æ¯”ç‡
    if avg_weekday > 0:
        ratio = avg_weekend / avg_weekday
        col7.metric("ğŸ“Š ä¼‘æ—¥/å¹³æ—¥æ¯”", f"{ratio:.2f}å€")
    
    st.session_state.sales_data = df_agg
    
    return df_agg


def render_forecast_section(sales_data: pd.DataFrame):
    """éœ€è¦äºˆæ¸¬ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆVertex AIå¯¾å¿œï¼‰"""
    st.markdown('<p class="section-header">â‘£ éœ€è¦ã‚’äºˆæ¸¬ã™ã‚‹</p>', unsafe_allow_html=True)
    
    if sales_data is None or sales_data.empty:
        st.info("å£²ä¸Šãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã¨ã€éœ€è¦äºˆæ¸¬ãŒã§ãã¾ã™")
        return
    
    col1, col2 = st.columns(2)
    
    with col1:
        forecast_mode = st.radio(
            "äºˆæ¸¬æœŸé–“ã®æŒ‡å®šæ–¹æ³•",
            ["æ—¥æ•°ã§æŒ‡å®š", "æœŸé–“ã§æŒ‡å®š"],
            horizontal=True,
            key="forecast_mode_existing",
            help="ã€ŒæœŸé–“ã§æŒ‡å®šã€ã¯æœŸé–“é™å®šå“ã®äºˆæ¸¬ã«ä¾¿åˆ©ã§ã™"
        )
    
    with col2:
        available_methods = get_available_forecast_methods()
        default_idx = 0  # Vertex AIãŒã‚ã‚Œã°0ã€ãªã‘ã‚Œã°å­£ç¯€æ€§è€ƒæ…®
        if "ğŸš€ Vertex AIï¼ˆæ¨å¥¨ï¼‰" not in available_methods:
            default_idx = available_methods.index("å­£ç¯€æ€§è€ƒæ…®ï¼ˆçµ±è¨ˆï¼‰") if "å­£ç¯€æ€§è€ƒæ…®ï¼ˆçµ±è¨ˆï¼‰" in available_methods else 0
        
        method = st.selectbox(
            "äºˆæ¸¬æ–¹æ³•",
            available_methods,
            index=default_idx,
            key="forecast_method_existing"
        )
    
    # äºˆæ¸¬æœŸé–“ã®è¨­å®š
    if forecast_mode == "æ—¥æ•°ã§æŒ‡å®š":
        forecast_days = st.slider("äºˆæ¸¬æ—¥æ•°", 30, 365, 180, key="forecast_days_existing")
        forecast_start_date = None
        forecast_end_date = None
    else:
        # æœŸé–“æŒ‡å®šUIï¼ˆåˆ†ææœŸé–“ã¨åŒã˜ã‚¹ã‚¿ã‚¤ãƒ«ï¼‰
        today = date.today()
        default_start = today + timedelta(days=1)
        default_end = today + timedelta(days=180)
        
        st.write("**äºˆæ¸¬æœŸé–“æŒ‡å®š**")
        col_s1, col_s2, col_s3, col_e1, col_e2, col_e3 = st.columns([1, 1, 1, 1, 1, 1])
        
        with col_s1:
            start_year = st.selectbox(
                "äºˆæ¸¬é–‹å§‹å¹´",
                list(range(2025, 2028)),
                index=list(range(2025, 2028)).index(default_start.year) if default_start.year in range(2025, 2028) else 0,
                key="forecast_start_year"
            )
        with col_s2:
            start_month = st.selectbox(
                "äºˆæ¸¬é–‹å§‹æœˆ",
                list(range(1, 13)),
                index=default_start.month - 1,
                format_func=lambda x: f"{x}æœˆ",
                key="forecast_start_month"
            )
        with col_s3:
            max_day_start = calendar.monthrange(start_year, start_month)[1]
            start_day = st.selectbox(
                "äºˆæ¸¬é–‹å§‹æ—¥",
                list(range(1, max_day_start + 1)),
                index=min(default_start.day - 1, max_day_start - 1),
                format_func=lambda x: f"{x}æ—¥",
                key="forecast_start_day"
            )
        
        with col_e1:
            end_year = st.selectbox(
                "äºˆæ¸¬çµ‚äº†å¹´",
                list(range(2025, 2028)),
                index=list(range(2025, 2028)).index(default_end.year) if default_end.year in range(2025, 2028) else 0,
                key="forecast_end_year"
            )
        with col_e2:
            end_month = st.selectbox(
                "äºˆæ¸¬çµ‚äº†æœˆ",
                list(range(1, 13)),
                index=default_end.month - 1,
                format_func=lambda x: f"{x}æœˆ",
                key="forecast_end_month"
            )
        with col_e3:
            max_day_end = calendar.monthrange(end_year, end_month)[1]
            end_day = st.selectbox(
                "äºˆæ¸¬çµ‚äº†æ—¥",
                list(range(1, max_day_end + 1)),
                index=min(default_end.day - 1, max_day_end - 1),
                format_func=lambda x: f"{x}æ—¥",
                key="forecast_end_day"
            )
        
        forecast_start_date = date(start_year, start_month, start_day)
        forecast_end_date = date(end_year, end_month, end_day)
        
        if forecast_end_date <= forecast_start_date:
            st.error("âš ï¸ çµ‚äº†æ—¥ã¯é–‹å§‹æ—¥ã‚ˆã‚Šå¾Œã«ã—ã¦ãã ã•ã„")
            return
        
        forecast_days = (forecast_end_date - forecast_start_date).days + 1
        st.info(f"ğŸ“… äºˆæ¸¬æœŸé–“: {forecast_start_date.strftime('%Yå¹´%mæœˆ%dæ—¥')} ã€œ {forecast_end_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}ï¼ˆ{forecast_days}æ—¥é–“ï¼‰")
    
    # äºˆæ¸¬æ–¹æ³•ã®èª¬æ˜ã‚’è¡¨ç¤º
    method_info = FORECAST_METHODS[method]
    css_class = "vertex-ai" if "Vertex" in method else "seasonality" if "å­£ç¯€" in method else "moving-avg" if "ç§»å‹•" in method else "exponential"
    
    st.markdown(f"""
    <div class="method-card method-{css_class}">
        <strong>{method_info['icon']} {method}</strong><br>
        {method_info['description']}
    </div>
    """, unsafe_allow_html=True)
    
    # å…±å¤‰é‡ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆVertex AIé¸æŠæ™‚ï¼‰
    use_covariates = False
    if "Vertex AI" in method and VERTEX_AI_AVAILABLE:
        use_covariates = st.checkbox(
            "å…±å¤‰é‡ã‚’ä½¿ç”¨ï¼ˆå¤©æ°—ãƒ»å…­æ›œãƒ»ã‚¤ãƒ™ãƒ³ãƒˆï¼‰",
            value=True,
            help="äºˆæ¸¬ç²¾åº¦ãŒå‘ä¸Šã—ã¾ã™ãŒã€å‡¦ç†æ™‚é–“ãŒé•·ããªã‚‹å ´åˆãŒã‚ã‚Šã¾ã™"
        )
    
    if st.button("ğŸ”® éœ€è¦ã‚’äºˆæ¸¬", type="primary", use_container_width=True, key="forecast_btn_existing"):
        with st.spinner("äºˆæ¸¬ä¸­..."):
            try:
                if method == "ğŸ”„ ã™ã¹ã¦ã®æ–¹æ³•ã§æ¯”è¼ƒ":
                    # ã™ã¹ã¦ã®æ–¹æ³•ã§äºˆæ¸¬
                    product_id = "_".join(st.session_state.selected_products[:3])
                    all_results = forecast_all_methods_with_vertex_ai(sales_data, forecast_days, product_id)
                    display_comparison_results_v12(all_results, forecast_days, sales_data)
                else:
                    # å˜ä¸€ã®äºˆæ¸¬æ–¹æ³•
                    product_id = "_".join(st.session_state.selected_products[:3])
                    forecast, method_message = forecast_with_vertex_ai(sales_data, forecast_days, method, product_id)
                    
                    if forecast is not None and not forecast.empty:
                        display_single_forecast_result_v12(forecast, forecast_days, method, method_message, sales_data)
                    else:
                        st.error("äºˆæ¸¬çµæœãŒç©ºã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            except Exception as e:
                st.error(f"äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
                logger.error(f"äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")


def display_single_forecast_result_v12(forecast: pd.DataFrame, forecast_days: int, method: str, method_message: str, sales_data: pd.DataFrame = None):
    """å˜ä¸€ã®äºˆæ¸¬çµæœã‚’è¡¨ç¤ºï¼ˆv12 ã‚¹ãƒãƒ›æœ€é©åŒ– + ãƒ­ã‚¸ãƒƒã‚¯èª¬æ˜ï¼‰"""
    raw_total = int(forecast['predicted'].sum())
    rounded_total = round_up_to_50(raw_total)
    avg_predicted = forecast['predicted'].mean()
    
    # Vertex AIä½¿ç”¨æ™‚ã¯ç‰¹åˆ¥è¡¨ç¤º
    if "Vertex AI" in method_message:
        st.success(f"âœ… äºˆæ¸¬å®Œäº†ï¼ï¼ˆğŸš€ {method_message}ï¼‰")
    else:
        st.success(f"âœ… äºˆæ¸¬å®Œäº†ï¼ï¼ˆ{method_message}ï¼‰")
    
    st.session_state.last_forecast_method = method_message
    
    col1, col2, col3 = st.columns(3)
    col1.metric("ğŸ“¦ äºˆæ¸¬è²©å£²ç·æ•°", f"{rounded_total:,}ä½“")
    col2.metric("ğŸ“ˆ å¹³å‡æ—¥è²©ï¼ˆäºˆæ¸¬ï¼‰", f"{avg_predicted:.1f}ä½“/æ—¥")
    col3.metric("ğŸ“… äºˆæ¸¬æœŸé–“", f"{forecast_days}æ—¥é–“")
    
    # äºˆæ¸¬ãƒ­ã‚¸ãƒƒã‚¯ã®èª¬æ˜ã‚’è¿½åŠ 
    with st.expander("ğŸ“Š äºˆæ¸¬ãƒ­ã‚¸ãƒƒã‚¯ã®è©³ç´°", expanded=False):
        display_forecast_logic_explanation(method, sales_data, forecast, forecast_days, avg_predicted)
    
    # ã‚°ãƒ©ãƒ•è¡¨ç¤ºï¼ˆã‚¹ãƒãƒ›æœ€é©åŒ–ï¼‰
    method_info = FORECAST_METHODS.get(method, {"color": "#4285F4"})
    
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=forecast['date'],
        y=forecast['predicted'],
        mode='lines',
        name='äºˆæ¸¬',
        line=dict(color=method_info.get('color', '#4285F4'), width=2)
    ))
    
    # ä¿¡é ¼åŒºé–“ãŒã‚ã‚Œã°è¡¨ç¤º
    if 'confidence_lower' in forecast.columns and forecast['confidence_lower'].notna().any():
        fig.add_trace(go.Scatter(
            x=forecast['date'],
            y=forecast['confidence_upper'],
            mode='lines',
            name='ä¸Šé™',
            line=dict(color='rgba(66, 133, 244, 0.3)', dash='dash'),
            showlegend=True
        ))
        fig.add_trace(go.Scatter(
            x=forecast['date'],
            y=forecast['confidence_lower'],
            mode='lines',
            name='ä¸‹é™',
            line=dict(color='rgba(66, 133, 244, 0.3)', dash='dash'),
            fill='tonexty',
            fillcolor='rgba(66, 133, 244, 0.1)',
            showlegend=True
        ))
    
    # ã‚¹ãƒãƒ›æœ€é©åŒ–ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
    layout = get_mobile_chart_layout(f'{method}ã«ã‚ˆã‚‹æ—¥åˆ¥äºˆæ¸¬', height=280)
    layout['xaxis_title'] = 'æ—¥ä»˜'
    layout['yaxis_title'] = 'äºˆæ¸¬è²©å£²æ•°ï¼ˆä½“ï¼‰'
    fig.update_layout(**layout)
    
    st.plotly_chart(fig, use_container_width=True, config=get_mobile_chart_config())
    
    st.session_state.forecast_data = forecast
    st.session_state.forecast_total = rounded_total


def display_forecast_logic_explanation(method: str, sales_data: pd.DataFrame, forecast: pd.DataFrame, forecast_days: int, avg_predicted: float):
    """äºˆæ¸¬ãƒ­ã‚¸ãƒƒã‚¯ã®è©³ç´°èª¬æ˜ã‚’è¡¨ç¤º"""
    
    if sales_data is None or sales_data.empty:
        st.write("å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆ
    total_days = len(sales_data)
    total_qty = int(sales_data['è²©å£²å•†å“æ•°'].sum())
    avg_daily = sales_data['è²©å£²å•†å“æ•°'].mean()
    max_daily = sales_data['è²©å£²å•†å“æ•°'].max()
    min_daily = sales_data['è²©å£²å•†å“æ•°'].min()
    
    st.write("#### ğŸ“¥ å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ï¼ˆéå»ã®å®Ÿç¸¾ï¼‰")
    st.write(f"""
    - **åˆ†ææœŸé–“**: {total_days}æ—¥é–“
    - **ç·è²©å£²æ•°**: {total_qty:,}ä½“
    - **å¹³å‡æ—¥è²©**: {avg_daily:.1f}ä½“/æ—¥
    - **æœ€å¤§æ—¥è²©**: {max_daily:.0f}ä½“/æ—¥
    - **æœ€å°æ—¥è²©**: {min_daily:.0f}ä½“/æ—¥
    """)
    
    st.write("#### ğŸ”® äºˆæ¸¬ãƒ­ã‚¸ãƒƒã‚¯")
    
    if "Vertex AI" in method:
        st.write(f"""
        **Vertex AI AutoML Forecasting**
        1. éå»{total_days}æ—¥é–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã«å…¥åŠ›
        2. æ™‚ç³»åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»å‘¨æœŸæ€§ï¼‰ã‚’è‡ªå‹•æ¤œå‡º
        3. å¤©æ°—ãƒ»å…­æ›œãƒ»ã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±ã‚‚è€ƒæ…®ï¼ˆå…±å¤‰é‡ï¼‰
        4. {forecast_days}æ—¥é–“ã®æ—¥åˆ¥äºˆæ¸¬ã‚’ç”Ÿæˆ
        
        **è¨ˆç®—çµæœ**:
        - äºˆæ¸¬å¹³å‡æ—¥è²©: {avg_predicted:.1f}ä½“/æ—¥
        - å®Ÿç¸¾å¹³å‡ã¨ã®å·®: {avg_predicted - avg_daily:+.1f}ä½“/æ—¥ ({((avg_predicted/avg_daily)-1)*100:+.1f}%)
        """)
    
    elif "å­£ç¯€æ€§" in method:
        # æ›œæ—¥åˆ¥å¹³å‡ã‚’è¨ˆç®—
        if 'date' in sales_data.columns:
            sales_data_copy = sales_data.copy()
            sales_data_copy['weekday'] = pd.to_datetime(sales_data_copy['date']).dt.dayofweek
            weekday_avg = sales_data_copy.groupby('weekday')['è²©å£²å•†å“æ•°'].mean()
            weekday_names = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']
            weekday_str = ", ".join([f"{weekday_names[i]}:{weekday_avg.get(i, 0):.1f}" for i in range(7)])
        else:
            weekday_str = "ãƒ‡ãƒ¼ã‚¿ãªã—"
        
        st.write(f"""
        **å­£ç¯€æ€§è€ƒæ…®äºˆæ¸¬**
        1. æ›œæ—¥åˆ¥ã®å¹³å‡è²©å£²æ•°ã‚’è¨ˆç®—
        2. æœˆåˆ¥ã®å­£ç¯€ä¿‚æ•°ã‚’ç®—å‡º
        3. æ›œæ—¥ãƒ‘ã‚¿ãƒ¼ãƒ³ Ã— å­£ç¯€ä¿‚æ•°ã§æ—¥åˆ¥äºˆæ¸¬
        
        **æ›œæ—¥åˆ¥å¹³å‡**: {weekday_str}
        
        **è¨ˆç®—çµæœ**:
        - äºˆæ¸¬å¹³å‡æ—¥è²©: {avg_predicted:.1f}ä½“/æ—¥
        - å®Ÿç¸¾å¹³å‡ã¨ã®å·®: {avg_predicted - avg_daily:+.1f}ä½“/æ—¥ ({((avg_predicted/avg_daily)-1)*100:+.1f}%)
        """)
    
    elif "ç§»å‹•å¹³å‡" in method:
        # ç›´è¿‘30æ—¥ã®å¹³å‡
        recent_30 = sales_data.tail(30)['è²©å£²å•†å“æ•°'].mean() if len(sales_data) >= 30 else avg_daily
        
        st.write(f"""
        **ç§»å‹•å¹³å‡æ³•**
        1. ç›´è¿‘30æ—¥é–“ã®è²©å£²ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
        2. 30æ—¥é–“ã®å¹³å‡å€¤ã‚’åŸºæº–ã¨ã—ã¦äºˆæ¸¬
        
        **ç›´è¿‘30æ—¥å¹³å‡**: {recent_30:.1f}ä½“/æ—¥
        
        **è¨ˆç®—å¼**: äºˆæ¸¬æ—¥è²© = ç›´è¿‘30æ—¥å¹³å‡ = {recent_30:.1f}ä½“/æ—¥
        **äºˆæ¸¬ç·æ•°**: {recent_30:.1f} Ã— {forecast_days}æ—¥ = {recent_30 * forecast_days:.0f}ä½“
        """)
    
    elif "æŒ‡æ•°å¹³æ»‘" in method:
        alpha = 0.3  # å¹³æ»‘åŒ–ä¿‚æ•°
        recent_7 = sales_data.tail(7)['è²©å£²å•†å“æ•°'].mean() if len(sales_data) >= 7 else avg_daily
        
        st.write(f"""
        **æŒ‡æ•°å¹³æ»‘æ³•**
        1. ç›´è¿‘ã®ãƒ‡ãƒ¼ã‚¿ã‚’é‡è¦–ï¼ˆå¹³æ»‘åŒ–ä¿‚æ•° Î±={alpha}ï¼‰
        2. æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã»ã©é«˜ã„é‡ã¿ã§è¨ˆç®—
        
        **ç›´è¿‘7æ—¥å¹³å‡**: {recent_7:.1f}ä½“/æ—¥
        **å…¨æœŸé–“å¹³å‡**: {avg_daily:.1f}ä½“/æ—¥
        
        **è¨ˆç®—å¼**: äºˆæ¸¬ = Î±Ã—ç›´è¿‘ + (1-Î±)Ã—å…¨ä½“ = {alpha}Ã—{recent_7:.1f} + {1-alpha}Ã—{avg_daily:.1f} = {alpha*recent_7 + (1-alpha)*avg_daily:.1f}ä½“/æ—¥
        """)
    
    else:
        st.write(f"""
        **äºˆæ¸¬æ–¹æ³•**: {method}
        - å…¥åŠ›ãƒ‡ãƒ¼ã‚¿: {total_days}æ—¥é–“ã®å®Ÿç¸¾
        - äºˆæ¸¬æœŸé–“: {forecast_days}æ—¥é–“
        - äºˆæ¸¬å¹³å‡æ—¥è²©: {avg_predicted:.1f}ä½“/æ—¥
        """)


def display_comparison_results_v12(all_results: Dict[str, Tuple[pd.DataFrame, str]], forecast_days: int, sales_data: pd.DataFrame = None):
    """ã™ã¹ã¦ã®äºˆæ¸¬æ–¹æ³•ã®æ¯”è¼ƒçµæœã‚’è¡¨ç¤ºï¼ˆv12 ã‚¹ãƒãƒ›æœ€é©åŒ– + äºˆæ¸¬ç·æ•°ä¸€è¦§ï¼‰"""
    st.success("âœ… ã™ã¹ã¦ã®äºˆæ¸¬æ–¹æ³•ã§æ¯”è¼ƒå®Œäº†ï¼")
    
    # å„äºˆæ¸¬æ–¹æ³•ã®äºˆæ¸¬ç·æ•°ã‚’è¨ˆç®—
    method_totals = {}
    for method_name, (forecast, message) in all_results.items():
        raw_total = int(forecast['predicted'].sum())
        rounded_total = round_up_to_50(raw_total)
        avg_predicted = forecast['predicted'].mean()
        method_totals[method_name] = {
            'raw': raw_total,
            'rounded': rounded_total,
            'avg': avg_predicted
        }
    
    # ========== äºˆæ¸¬ç·æ•°ã‚µãƒãƒªãƒ¼è¡¨ ==========
    st.write("### ğŸ“Š äºˆæ¸¬æ–¹æ³•åˆ¥ äºˆæ¸¬ç·æ•°ã‚µãƒãƒªãƒ¼")
    
    # è¡¨å½¢å¼ã§è¡¨ç¤º
    summary_rows = []
    for method_name, totals in method_totals.items():
        icon = "ğŸš€" if "Vertex" in method_name else "ğŸ“ˆ" if "å­£ç¯€" in method_name else "ğŸ“Š" if "ç§»å‹•" in method_name else "ğŸ“‰"
        summary_rows.append({
            'äºˆæ¸¬æ–¹æ³•': f"{icon} {method_name}",
            'äºˆæ¸¬ç·æ•°ï¼ˆç”Ÿå€¤ï¼‰': f"{totals['raw']:,}ä½“",
            'ç™ºæ³¨æ¨å¥¨æ•°ï¼ˆ50å€æ•°ï¼‰': f"{totals['rounded']:,}ä½“",
            'å¹³å‡æ—¥è²©': f"{totals['avg']:.1f}ä½“/æ—¥"
        })
    
    summary_df = pd.DataFrame(summary_rows)
    st.dataframe(summary_df, use_container_width=True, hide_index=True)
    
    # 4ã¤ã®æ–¹æ³•ã®çµ±è¨ˆ
    all_rounded = [t['rounded'] for t in method_totals.values()]
    all_raw = [t['raw'] for t in method_totals.values()]
    
    st.write("### ğŸ“ˆ äºˆæ¸¬å€¤ã®çµ±è¨ˆ")
    
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("ğŸ“Š æœ€å°å€¤", f"{min(all_rounded):,}ä½“")
    col2.metric("ğŸ“Š æœ€å¤§å€¤", f"{max(all_rounded):,}ä½“")
    col3.metric("ğŸ“Š å¹³å‡å€¤", f"{round_up_to_50(int(sum(all_raw) / len(all_raw))):,}ä½“")
    col4.metric("ğŸ“Š ä¸­å¤®å€¤", f"{round_up_to_50(int(sorted(all_raw)[len(all_raw)//2])):,}ä½“")
    
    # å·®åˆ†ã®è¡¨ç¤º
    if len(all_rounded) >= 2:
        diff = max(all_rounded) - min(all_rounded)
        diff_pct = (max(all_raw) - min(all_raw)) / min(all_raw) * 100 if min(all_raw) > 0 else 0
        st.info(f"ğŸ“ **äºˆæ¸¬å€¤ã®å¹…**: æœ€å°ã€œæœ€å¤§ã§ **{diff:,}ä½“** ã®å·®ï¼ˆ{diff_pct:.1f}%ï¼‰")
    
    method_colors = {
        'Vertex AI': '#4285F4',
        'å­£ç¯€æ€§è€ƒæ…®': '#4CAF50',
        'ç§»å‹•å¹³å‡æ³•': '#1E88E5',
        'æŒ‡æ•°å¹³æ»‘æ³•': '#FF9800'
    }
    
    # æ¯”è¼ƒã‚°ãƒ©ãƒ•ï¼ˆã‚¹ãƒãƒ›æœ€é©åŒ–ï¼‰
    st.write("### ğŸ“ˆ æ—¥åˆ¥äºˆæ¸¬æ¯”è¼ƒã‚°ãƒ©ãƒ•")
    
    fig = go.Figure()
    
    for method_name, (forecast, message) in all_results.items():
        fig.add_trace(go.Scatter(
            x=forecast['date'],
            y=forecast['predicted'],
            mode='lines',
            name=method_name,
            line=dict(color=method_colors.get(method_name, '#666666'), width=2)
        ))
    
    layout = get_mobile_chart_layout('äºˆæ¸¬æ–¹æ³•åˆ¥ã®æ—¥åˆ¥äºˆæ¸¬æ¯”è¼ƒ', height=300)
    layout['xaxis_title'] = 'æ—¥ä»˜'
    layout['yaxis_title'] = 'äºˆæ¸¬è²©å£²æ•°ï¼ˆä½“ï¼‰'
    fig.update_layout(**layout)
    
    st.plotly_chart(fig, use_container_width=True, config=get_mobile_chart_config())
    
    # æ¨å¥¨
    if 'Vertex AI' in all_results:
        st.info("ğŸ’¡ **ãŠã™ã™ã‚**: Vertex AI AutoML Forecastingã¯æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã§å­¦ç¿’æ¸ˆã¿ã®ãŸã‚ã€æœ€ã‚‚ç²¾åº¦ãŒé«˜ã„å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚")
    else:
        st.info("ğŸ’¡ **ãŠã™ã™ã‚**: å­£ç¯€æ€§è€ƒæ…®ã¯æœˆåˆ¥ãƒ»æ›œæ—¥åˆ¥ã®å‚¾å‘ã‚’è€ƒæ…®ã™ã‚‹ãŸã‚ã€çµ±è¨ˆãƒ¢ãƒ‡ãƒ«ã®ä¸­ã§ã¯æœ€ã‚‚ç²¾åº¦ãŒé«˜ã„å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚")
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜ï¼ˆVertex AIãŒã‚ã‚Œã°ãã‚Œã€ãªã‘ã‚Œã°å­£ç¯€æ€§è€ƒæ…®ï¼‰
    if 'Vertex AI' in all_results:
        st.session_state.forecast_data = all_results['Vertex AI'][0]
        st.session_state.forecast_total = method_totals['Vertex AI']['rounded']
    elif 'å­£ç¯€æ€§è€ƒæ…®' in all_results:
        st.session_state.forecast_data = all_results['å­£ç¯€æ€§è€ƒæ…®'][0]
        st.session_state.forecast_total = method_totals['å­£ç¯€æ€§è€ƒæ…®']['rounded']
    
    st.session_state.forecast_results = {k: v[0] for k, v in all_results.items()}


def render_individual_analysis(start_date: date, end_date: date):
    """å€‹åˆ¥åˆ†æãƒ¢ãƒ¼ãƒ‰"""
    st.markdown('<p class="section-header">â‘¢ å€‹åˆ¥å£²ä¸Šåˆ†æ</p>', unsafe_allow_html=True)
    
    if not st.session_state.selected_products:
        st.info("æˆä¸å“ã‚’é¸æŠã™ã‚‹ã¨ã€ã“ã“ã«å£²ä¸ŠãŒè¡¨ç¤ºã•ã‚Œã¾ã™")
        return
    
    df_items = st.session_state.data_loader.load_item_sales()
    
    if df_items.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    mask = (df_items['date'] >= pd.Timestamp(start_date)) & (df_items['date'] <= pd.Timestamp(end_date))
    df_filtered = df_items[mask]
    
    individual_data = {}
    
    for product in st.session_state.selected_products:
        original_names = st.session_state.normalizer.get_all_original_names([product])
        df_agg = aggregate_by_products(df_filtered, original_names, aggregate=True)
        
        if not df_agg.empty:
            df_agg = df_agg.sort_values('date').reset_index(drop=True)
            individual_data[product] = df_agg
    
    st.session_state.individual_sales_data = individual_data
    
    for product, df_agg in individual_data.items():
        with st.expander(f"ğŸ“¦ **{product}**", expanded=True):
            total_qty = int(df_agg['è²©å£²å•†å“æ•°'].sum())
            total_sales = df_agg['è²©å£²ç·å£²ä¸Š'].sum()
            period_days = (end_date - start_date).days + 1
            avg_daily = total_qty / period_days if period_days > 0 else 0
            
            # å¹³æ—¥ãƒ»ä¼‘æ—¥ã®å¹³å‡ã‚’è¨ˆç®—
            df_agg['weekday'] = pd.to_datetime(df_agg['date']).dt.dayofweek
            df_weekday = df_agg[df_agg['weekday'] < 5]
            df_weekend = df_agg[df_agg['weekday'] >= 5]
            avg_weekday = df_weekday['è²©å£²å•†å“æ•°'].mean() if not df_weekday.empty else 0
            avg_weekend = df_weekend['è²©å£²å•†å“æ•°'].mean() if not df_weekend.empty else 0
            
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("ğŸ›’ è²©å£²æ•°é‡", f"{total_qty:,}ä½“")
            col2.metric("ğŸ’° å£²ä¸Šåˆè¨ˆ", f"Â¥{total_sales:,.0f}")
            col3.metric("ğŸ“… å¹³æ—¥å¹³å‡", f"{avg_weekday:.1f}ä½“/æ—¥")
            col4.metric("ğŸŒ ä¼‘æ—¥å¹³å‡", f"{avg_weekend:.1f}ä½“/æ—¥")
    
    render_individual_forecast_section()
    
    # å€‹åˆ¥ãƒ¢ãƒ¼ãƒ‰ã§ã‚‚ç´å“è¨ˆç”»ã‚’è¡¨ç¤º
    render_delivery_section()


def render_individual_forecast_section():
    """å€‹åˆ¥äºˆæ¸¬ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆæœŸé–“æŒ‡å®šå¯¾å¿œï¼‰"""
    st.markdown('<p class="section-header">â‘£ å€‹åˆ¥éœ€è¦äºˆæ¸¬</p>', unsafe_allow_html=True)
    
    if not st.session_state.individual_sales_data:
        st.info("å£²ä¸Šãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã¨ã€éœ€è¦äºˆæ¸¬ãŒã§ãã¾ã™")
        return
    
    col1, col2 = st.columns(2)
    
    with col1:
        forecast_mode = st.radio(
            "äºˆæ¸¬æœŸé–“ã®æŒ‡å®šæ–¹æ³•",
            ["æ—¥æ•°ã§æŒ‡å®š", "æœŸé–“ã§æŒ‡å®š"],
            horizontal=True,
            key="individual_forecast_mode",
            help="ã€ŒæœŸé–“ã§æŒ‡å®šã€ã¯æœŸé–“é™å®šå“ã®äºˆæ¸¬ã«ä¾¿åˆ©ã§ã™"
        )
    
    with col2:
        available_methods = get_available_forecast_methods()
        # å€‹åˆ¥ãƒ¢ãƒ¼ãƒ‰ã§ã‚‚ã€Œã™ã¹ã¦ã®æ–¹æ³•ã§æ¯”è¼ƒã€ã‚’ä½¿ç”¨å¯èƒ½ã«
        
        method = st.selectbox(
            "äºˆæ¸¬æ–¹æ³•",
            available_methods,
            index=0,
            key="individual_forecast_method"
        )
    
    # äºˆæ¸¬æœŸé–“ã®è¨­å®š
    if forecast_mode == "æ—¥æ•°ã§æŒ‡å®š":
        forecast_days = st.slider("äºˆæ¸¬æ—¥æ•°", 30, 365, 180, key="individual_forecast_days")
        forecast_start_date = None
        forecast_end_date = None
    else:
        # æœŸé–“æŒ‡å®šUIï¼ˆåˆ†ææœŸé–“ã¨åŒã˜ã‚¹ã‚¿ã‚¤ãƒ«ï¼‰
        today = date.today()
        default_start = today + timedelta(days=1)
        default_end = today + timedelta(days=180)
        
        st.write("**äºˆæ¸¬æœŸé–“æŒ‡å®š**")
        col_s1, col_s2, col_s3, col_e1, col_e2, col_e3 = st.columns([1, 1, 1, 1, 1, 1])
        
        with col_s1:
            start_year = st.selectbox(
                "äºˆæ¸¬é–‹å§‹å¹´",
                list(range(2025, 2028)),
                index=list(range(2025, 2028)).index(default_start.year) if default_start.year in range(2025, 2028) else 0,
                key="ind_forecast_start_year"
            )
        with col_s2:
            start_month = st.selectbox(
                "äºˆæ¸¬é–‹å§‹æœˆ",
                list(range(1, 13)),
                index=default_start.month - 1,
                format_func=lambda x: f"{x}æœˆ",
                key="ind_forecast_start_month"
            )
        with col_s3:
            max_day_start = calendar.monthrange(start_year, start_month)[1]
            start_day = st.selectbox(
                "äºˆæ¸¬é–‹å§‹æ—¥",
                list(range(1, max_day_start + 1)),
                index=min(default_start.day - 1, max_day_start - 1),
                format_func=lambda x: f"{x}æ—¥",
                key="ind_forecast_start_day"
            )
        
        with col_e1:
            end_year = st.selectbox(
                "äºˆæ¸¬çµ‚äº†å¹´",
                list(range(2025, 2028)),
                index=list(range(2025, 2028)).index(default_end.year) if default_end.year in range(2025, 2028) else 0,
                key="ind_forecast_end_year"
            )
        with col_e2:
            end_month = st.selectbox(
                "äºˆæ¸¬çµ‚äº†æœˆ",
                list(range(1, 13)),
                index=default_end.month - 1,
                format_func=lambda x: f"{x}æœˆ",
                key="ind_forecast_end_month"
            )
        with col_e3:
            max_day_end = calendar.monthrange(end_year, end_month)[1]
            end_day = st.selectbox(
                "äºˆæ¸¬çµ‚äº†æ—¥",
                list(range(1, max_day_end + 1)),
                index=min(default_end.day - 1, max_day_end - 1),
                format_func=lambda x: f"{x}æ—¥",
                key="ind_forecast_end_day"
            )
        
        forecast_start_date = date(start_year, start_month, start_day)
        forecast_end_date = date(end_year, end_month, end_day)
        
        if forecast_end_date <= forecast_start_date:
            st.error("âš ï¸ çµ‚äº†æ—¥ã¯é–‹å§‹æ—¥ã‚ˆã‚Šå¾Œã«ã—ã¦ãã ã•ã„")
            return
        
        forecast_days = (forecast_end_date - forecast_start_date).days + 1
        st.info(f"ğŸ“… äºˆæ¸¬æœŸé–“: {forecast_start_date.strftime('%Yå¹´%mæœˆ%dæ—¥')} ã€œ {forecast_end_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}ï¼ˆ{forecast_days}æ—¥é–“ï¼‰")
    
    method_info = FORECAST_METHODS[method]
    st.markdown(f"""
    <div class="analysis-card">
        <strong>{method_info['icon']} {method}</strong><br>
        {method_info['description']}
    </div>
    """, unsafe_allow_html=True)
    
    if st.button("ğŸ”® å€‹åˆ¥ã«éœ€è¦äºˆæ¸¬ã‚’å®Ÿè¡Œ", type="primary", use_container_width=True, key="individual_forecast_btn"):
        with st.spinner("äºˆæ¸¬ä¸­..."):
            results = []
            
            for product, sales_data in st.session_state.individual_sales_data.items():
                try:
                    forecast, method_message = forecast_with_vertex_ai(sales_data, forecast_days, method, product)
                    
                    if forecast is not None and not forecast.empty:
                        raw_total = int(forecast['predicted'].sum())
                        rounded_total = round_up_to_50(raw_total)
                        avg_predicted = forecast['predicted'].mean()
                        
                        results.append({
                            'product': product,
                            'forecast': forecast,
                            'raw_total': raw_total,
                            'rounded_total': rounded_total,
                            'avg_predicted': avg_predicted,
                            'method_message': method_message
                        })
                except Exception as e:
                    st.warning(f"{product}ã®äºˆæ¸¬ã«å¤±æ•—: {e}")
            
            if results:
                # ç´å“è¨ˆç”»ã§ä½¿ãˆã‚‹ã‚ˆã†ã«session_stateã«ä¿å­˜
                if len(results) == 1:
                    st.session_state.forecast_data = results[0]['forecast']
                else:
                    # è¤‡æ•°å•†å“ã®å ´åˆã¯æ—¥ä»˜ã”ã¨ã«åˆç®—
                    combined_forecast = results[0]['forecast'].copy()
                    combined_forecast = combined_forecast.rename(columns={'predicted': 'predicted_sum'})
                    
                    for r in results[1:]:
                        merged = combined_forecast.merge(
                            r['forecast'][['date', 'predicted']], 
                            on='date', 
                            how='outer'
                        )
                        merged['predicted_sum'] = merged['predicted_sum'].fillna(0) + merged['predicted'].fillna(0)
                        merged = merged.drop(columns=['predicted'])
                        combined_forecast = merged
                    
                    combined_forecast = combined_forecast.rename(columns={'predicted_sum': 'predicted'})
                    st.session_state.forecast_data = combined_forecast
                
                total_all = sum(r['rounded_total'] for r in results)
                st.session_state.forecast_total = total_all
                st.session_state.last_forecast_method = results[0]['method_message'] if results else ""
                st.session_state.individual_forecast_results = results  # çµæœã‚’ä¿å­˜
                st.rerun()  # ç´å“ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ›´æ–°ã™ã‚‹ãŸã‚å†æç”»
    
    # äºˆæ¸¬çµæœã®è¡¨ç¤ºï¼ˆsession_stateã‹ã‚‰ï¼‰
    if 'individual_forecast_results' in st.session_state and st.session_state.individual_forecast_results:
        results = st.session_state.individual_forecast_results
        st.success(f"âœ… {len(results)}ä»¶ã®æˆä¸å“ã®äºˆæ¸¬ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        
        summary_df = pd.DataFrame([
            {
                'æˆä¸å“': r['product'],
                'äºˆæ¸¬ç·æ•°': f"{r['rounded_total']:,}ä½“",
                'å¹³å‡æ—¥è²©': f"{r['avg_predicted']:.1f}ä½“/æ—¥",
                'ç™ºæ³¨æ¨å¥¨æ•°ï¼ˆ50å€æ•°ï¼‰': r['rounded_total']
            }
            for r in results
        ])
        st.dataframe(summary_df, use_container_width=True, hide_index=True)
        
        total_all = sum(r['rounded_total'] for r in results)
        st.metric("ğŸ“¦ å…¨ä½“ã®äºˆæ¸¬ç·æ•°", f"{total_all:,}ä½“")


def render_delivery_section():
    """ç´å“è¨ˆç”»ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆå€‹åˆ¥ãƒ¢ãƒ¼ãƒ‰å¯¾å¿œï¼‰"""
    st.markdown('<p class="section-header">â‘¤ ç´å“è¨ˆç”»ã‚’ç«‹ã¦ã‚‹</p>', unsafe_allow_html=True)
    
    # å€‹åˆ¥äºˆæ¸¬çµæœãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    individual_results = st.session_state.get('individual_forecast_results', [])
    forecast = st.session_state.get('forecast_data')
    
    if (not individual_results) and (forecast is None or (isinstance(forecast, pd.DataFrame) and forecast.empty)):
        st.info("éœ€è¦äºˆæ¸¬ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€ç´å“è¨ˆç”»ã‚’ç«‹ã¦ã‚‰ã‚Œã¾ã™")
        return
    
    # è¤‡æ•°å•†å“ã®å€‹åˆ¥äºˆæ¸¬çµæœãŒã‚ã‚‹å ´åˆ
    if individual_results and len(individual_results) >= 1:
        if len(individual_results) > 1:
            st.success(f"ğŸ“¦ **{len(individual_results)}ä»¶ã®å•†å“**ã®äºˆæ¸¬çµæœãŒã‚ã‚Šã¾ã™")
            
            delivery_view = st.radio(
                "ç´å“è¨ˆç”»ã®è¡¨ç¤ºæ–¹æ³•",
                ["ğŸ“Š å…¨å•†å“ã‚’åˆç®—ã—ã¦è¨ˆç”»", "ğŸ“¦ å•†å“ã”ã¨ã«å€‹åˆ¥è¨ˆç”»"],
                horizontal=True,
                key="delivery_view_mode_main"
            )
            
            if delivery_view == "ğŸ“¦ å•†å“ã”ã¨ã«å€‹åˆ¥è¨ˆç”»":
                st.divider()
                for idx, r in enumerate(individual_results):
                    product = r['product']
                    forecast_df = r['forecast']
                    rounded_total = r['rounded_total']
                    avg_predicted = r['avg_predicted']
                    
                    with st.expander(f"ğŸ“¦ **{product}**ï¼ˆäºˆæ¸¬: {rounded_total:,}ä½“ã€æ—¥è²©: {avg_predicted:.1f}ä½“ï¼‰", expanded=(idx==0)):
                        render_delivery_inputs_and_schedule(
                            total_demand=rounded_total,
                            forecast_data=forecast_df,
                            product_name=product,
                            avg_daily=avg_predicted
                        )
                return
        else:
            # 1å•†å“ã®ã¿ã®å ´åˆ
            r = individual_results[0]
            st.success(f"ğŸ“¦ **{r['product']}** ã®äºˆæ¸¬çµæœ")
    
    # åˆç®—ãƒ¢ãƒ¼ãƒ‰
    total_demand = st.session_state.get('forecast_total', 0)
    method_used = st.session_state.get('last_forecast_method', '')
    forecast_data = forecast
    
    # å¹³å‡æ—¥è²©ã‚’è¨ˆç®—
    forecast_days = len(forecast_data) if forecast_data is not None and not forecast_data.empty else 180
    avg_daily = total_demand / forecast_days if forecast_days > 0 else 0
    
    if method_used:
        st.info(f"ğŸ“¦ äºˆæ¸¬ã•ã‚ŒãŸéœ€è¦æ•°: **{total_demand:,}ä½“**ï¼ˆ{forecast_days}æ—¥é–“ã€æ—¥è²©{avg_daily:.1f}ä½“ï¼‰ - {method_used}")
    else:
        st.info(f"ğŸ“¦ äºˆæ¸¬ã•ã‚ŒãŸéœ€è¦æ•°: **{total_demand:,}ä½“**ï¼ˆ{forecast_days}æ—¥é–“ã€æ—¥è²©{avg_daily:.1f}ä½“ï¼‰")
    
    render_delivery_inputs_and_schedule(total_demand, forecast_data, "åˆç®—", avg_daily)


def render_individual_delivery_plans(results: list):
    """å€‹åˆ¥å•†å“ã”ã¨ã®ç´å“è¨ˆç”»ã‚’è¡¨ç¤º"""
    for idx, r in enumerate(results):
        product = r['product']
        forecast = r['forecast']
        rounded_total = r['rounded_total']
        avg_predicted = r['avg_predicted']
        
        with st.expander(f"ğŸ“¦ **{product}** ã®ç´å“è¨ˆç”»ï¼ˆäºˆæ¸¬: {rounded_total:,}ä½“ï¼‰", expanded=(idx==0)):
            render_delivery_inputs_and_schedule(
                total_demand=rounded_total,
                forecast_data=forecast,
                product_name=product,
                avg_daily=avg_predicted
            )


def render_delivery_inputs_and_schedule(total_demand: int, forecast_data: pd.DataFrame, product_name: str, avg_daily: float = 0):
    """ç´å“è¨ˆç”»ã®å…¥åŠ›ã¨è¨ˆç®—ã‚’è¡¨ç¤º"""
    
    key_suffix = f"{product_name.replace(' ', '_')[:8]}_{hash(product_name) % 999}"
    
    # äºˆæ¸¬æœŸé–“ï¼ˆæ—¥æ•°ï¼‰ã‚’å–å¾—
    forecast_days = len(forecast_data) if forecast_data is not None and not forecast_data.empty else 180
    if avg_daily == 0:
        avg_daily = total_demand / forecast_days if forecast_days > 0 else 0
    
    # å…¥åŠ›ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.write("**ğŸ“ åœ¨åº«ãƒ»ç™ºæ³¨æƒ…å ±ã‚’å…¥åŠ›**")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        current_stock = st.number_input(
            "ğŸ  ç¾åœ¨ã®åœ¨åº«æ•°", 
            min_value=0, 
            value=500, 
            step=50, 
            key=f"stk_{key_suffix}"
        )
    
    with col2:
        min_stock = st.number_input(
            "âš ï¸ å®‰å…¨åœ¨åº«æ•°", 
            min_value=0, 
            value=100, 
            step=50, 
            key=f"minstk_{key_suffix}"
        )
    
    with col3:
        lead_time = st.number_input(
            "ğŸšš ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ (æ—¥)", 
            min_value=1, 
            value=14, 
            step=1, 
            key=f"lt_{key_suffix}",
            help="ç™ºæ³¨ã‹ã‚‰ç´å“ã¾ã§ã®æ—¥æ•°"
        )
    
    # ç™ºæ³¨æ•°ã®è¨ˆç®—
    needed = total_demand + min_stock - current_stock
    recommended_order = round_up_to_50(max(0, needed))
    
    # æ¨å¥¨ç™ºæ³¨æ•°ã¨è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ã‚’å¸¸ã«è¡¨ç¤º
    st.divider()
    st.write("**ğŸ§® ç™ºæ³¨æ¨å¥¨æ•°ã®è¨ˆç®—**")
    
    # è¨ˆç®—éç¨‹ã‚’è¡¨å½¢å¼ã§è¡¨ç¤º
    col_calc1, col_calc2 = st.columns([2, 1])
    
    with col_calc1:
        st.markdown(f"""
        | è¨ˆç®—é …ç›® | æ•°å€¤ | èª¬æ˜ |
        |:---------|-----:|:-----|
        | â‘  äºˆæ¸¬éœ€è¦ | **{total_demand:,}ä½“** | {forecast_days}æ—¥é–“ Ã— {avg_daily:.1f}ä½“/æ—¥ |
        | â‘¡ å®‰å…¨åœ¨åº« | **+{min_stock:,}ä½“** | æ¬ å“é˜²æ­¢ã®ä½™è£•åˆ† |
        | â‘¢ ç¾åœ¨åœ¨åº« | **-{current_stock:,}ä½“** | æ—¢ã«ã‚ã‚‹åœ¨åº« |
        | **å¿…è¦æ•°é‡** | **{needed:,}ä½“** | â‘  + â‘¡ - â‘¢ |
        | **ç™ºæ³¨æ¨å¥¨æ•°** | **{recommended_order:,}ä½“** | 50ã®å€æ•°ã«åˆ‡ã‚Šä¸Šã’ |
        """)
    
    with col_calc2:
        if needed <= 0:
            st.success(f"âœ… ç™ºæ³¨ä¸è¦\n\nåœ¨åº«ã§{forecast_days}æ—¥é–“ã‚«ãƒãƒ¼å¯èƒ½")
        else:
            days_until_stockout = int(current_stock / avg_daily) if avg_daily > 0 else 999
            st.warning(f"âš ï¸ è¦ç™ºæ³¨\n\nç´„{days_until_stockout}æ—¥ã§åœ¨åº«åˆ‡ã‚Œ")
    
    # ç™ºæ³¨æ•°å…¥åŠ›æ–¹æ³•
    order_mode = st.radio(
        "ç™ºæ³¨æ•°ã®æ±ºã‚æ–¹",
        ["ğŸ”® äºˆæ¸¬ã‹ã‚‰è‡ªå‹•è¨ˆç®—", "âœï¸ æ‰‹å…¥åŠ›ã§æŒ‡å®š"],
        horizontal=True,
        key=f"ordmode_{key_suffix}"
    )
    
    if order_mode == "ğŸ”® äºˆæ¸¬ã‹ã‚‰è‡ªå‹•è¨ˆç®—":
        order_quantity = recommended_order
        st.metric("ğŸ›’ ç™ºæ³¨æ•°ï¼ˆè‡ªå‹•è¨ˆç®—ï¼‰", f"{recommended_order:,}ä½“")
    else:
        order_quantity = st.number_input(
            "âœï¸ ç™ºæ³¨æ•°ã‚’å…¥åŠ›",
            min_value=0,
            value=recommended_order,
            step=50,
            key=f"manord_{key_suffix}"
        )
    
    # ç´å“ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ææ¡ˆ
    st.divider()
    st.write("**ğŸ“… ç´å“ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ææ¡ˆ**")
    
    delivery_mode = st.radio(
        "ç´å“æ–¹æ³•",
        ["ä¸€æ‹¬ç´å“", "åˆ†å‰²ç´å“ï¼ˆæœˆåˆ¥ï¼‰", "åˆ†å‰²ç´å“ï¼ˆã‚«ã‚¹ã‚¿ãƒ ï¼‰"],
        horizontal=True,
        key=f"delivery_mode_{key_suffix}"
    )
    
    if st.button("ğŸ“Š ç´å“ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½œæˆ", type="primary", use_container_width=True, key=f"create_schedule_btn_{key_suffix}"):
        if order_quantity <= 0:
            st.warning("ç™ºæ³¨æ•°ãŒ0ã§ã™ã€‚ç™ºæ³¨ã®å¿…è¦ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            schedule = create_delivery_schedule(
                order_quantity=order_quantity,
                current_stock=current_stock,
                min_stock=min_stock,
                lead_time=lead_time,
                forecast_data=forecast_data,
                delivery_mode=delivery_mode
            )
            
            display_delivery_schedule(schedule, current_stock, min_stock, forecast_data)


def create_delivery_schedule(
    order_quantity: int,
    current_stock: int,
    min_stock: int,
    lead_time: int,
    forecast_data: pd.DataFrame,
    delivery_mode: str
) -> List[Dict]:
    """ç´å“ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½œæˆ"""
    
    today = date.today()
    
    if delivery_mode == "ä¸€æ‹¬ç´å“":
        delivery_date = today + timedelta(days=lead_time)
        return [{
            'date': delivery_date,
            'quantity': order_quantity,
            'type': 'ä¸€æ‹¬ç´å“'
        }]
    
    elif delivery_mode == "åˆ†å‰²ç´å“ï¼ˆæœˆåˆ¥ï¼‰":
        if forecast_data is None or forecast_data.empty:
            months = 3
        else:
            forecast_days = len(forecast_data)
            months = max(1, forecast_days // 30)
            months = min(months, 6)
        
        schedule = []
        qty_per_delivery = round_up_to_50(order_quantity // months)
        remaining = order_quantity
        
        for i in range(months):
            delivery_date = today + timedelta(days=lead_time + (i * 30))
            qty = min(qty_per_delivery, remaining)
            if qty > 0:
                schedule.append({
                    'date': delivery_date,
                    'quantity': qty,
                    'type': f'{i+1}å›ç›®'
                })
                remaining -= qty
        
        if remaining > 0 and schedule:
            schedule[-1]['quantity'] += remaining
        
        return schedule
    
    else:  # ã‚«ã‚¹ã‚¿ãƒ åˆ†å‰²
        schedule = []
        stock = current_stock
        
        if forecast_data is not None and not forecast_data.empty:
            daily_demands = forecast_data['predicted'].tolist()
        else:
            daily_demands = [5] * 180
        
        delivery_qty = round_up_to_50(order_quantity // 3)
        remaining = order_quantity
        last_delivery_date = today
        
        for i, daily_demand in enumerate(daily_demands):
            target_date = today + timedelta(days=i)
            stock -= daily_demand
            
            if stock <= min_stock and remaining > 0:
                order_date = target_date - timedelta(days=lead_time)
                if order_date < last_delivery_date:
                    order_date = last_delivery_date + timedelta(days=1)
                
                delivery_date = order_date + timedelta(days=lead_time)
                qty = min(delivery_qty, remaining)
                
                schedule.append({
                    'date': delivery_date,
                    'quantity': qty,
                    'type': f'{len(schedule)+1}å›ç›®'
                })
                
                stock += qty
                remaining -= qty
                last_delivery_date = delivery_date
        
        if not schedule and remaining > 0:
            schedule.append({
                'date': today + timedelta(days=lead_time),
                'quantity': remaining,
                'type': 'ä¸€æ‹¬ç´å“'
            })
        
        return schedule


def display_delivery_schedule(schedule: List[Dict], current_stock: int, min_stock: int, forecast_data: pd.DataFrame):
    """ç´å“ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’è¡¨ç¤º"""
    
    st.success(f"âœ… ç´å“ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸï¼ˆ{len(schedule)}å›ç´å“ï¼‰")
    
    st.write("**ğŸ“‹ ç´å“ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«**")
    
    schedule_df = pd.DataFrame([
        {
            'ç´å“æ—¥': s['date'].strftime('%Y/%m/%d'),
            'æ›œæ—¥': ['æœˆ','ç«','æ°´','æœ¨','é‡‘','åœŸ','æ—¥'][s['date'].weekday()],
            'æ•°é‡': f"{s['quantity']:,}ä½“",
            'å‚™è€ƒ': s['type']
        }
        for s in schedule
    ])
    
    st.dataframe(schedule_df, use_container_width=True, hide_index=True)
    
    total_delivery = sum(s['quantity'] for s in schedule)
    st.metric("ğŸ“¦ ç´å“åˆè¨ˆ", f"{total_delivery:,}ä½“")
    
    with st.expander("ğŸ“ˆ åœ¨åº«æ¨ç§»ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³", expanded=True):
        sim_data = simulate_inventory(
            schedule=schedule,
            current_stock=current_stock,
            min_stock=min_stock,
            forecast_data=forecast_data
        )
        
        if sim_data:
            display_inventory_chart(sim_data, min_stock)


def simulate_inventory(schedule: List[Dict], current_stock: int, min_stock: int, forecast_data: pd.DataFrame) -> List[Dict]:
    """åœ¨åº«ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ"""
    
    today = date.today()
    
    if forecast_data is None or forecast_data.empty:
        return []
    
    sim_data = []
    stock = current_stock
    
    delivery_dict = {}
    for s in schedule:
        d = s['date']
        if d not in delivery_dict:
            delivery_dict[d] = 0
        delivery_dict[d] += s['quantity']
    
    sim_days = min(len(forecast_data), 90)
    
    for i in range(sim_days):
        target_date = today + timedelta(days=i)
        
        if target_date in delivery_dict:
            stock += delivery_dict[target_date]
        
        if i < len(forecast_data):
            daily_demand = forecast_data.iloc[i]['predicted']
        else:
            daily_demand = forecast_data['predicted'].mean()
        
        stock -= daily_demand
        stock = max(0, stock)
        
        sim_data.append({
            'date': target_date,
            'stock': stock,
            'demand': daily_demand,
            'delivery': delivery_dict.get(target_date, 0)
        })
    
    return sim_data


def display_inventory_chart(sim_data: List[Dict], min_stock: int):
    """åœ¨åº«æ¨ç§»ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºï¼ˆã‚¹ãƒãƒ›æœ€é©åŒ–ï¼‰"""
    
    df = pd.DataFrame(sim_data)
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=df['date'],
        y=df['stock'],
        mode='lines',
        name='åœ¨åº«æ•°',
        line=dict(color='#1E88E5', width=2),
        fill='tozeroy',
        fillcolor='rgba(30, 136, 229, 0.1)'
    ))
    
    fig.add_hline(
        y=min_stock, 
        line_dash="dash", 
        line_color="red",
        annotation_text=f"å®‰å…¨åœ¨åº« {min_stock}",
        annotation_position="right"
    )
    
    deliveries = df[df['delivery'] > 0]
    if not deliveries.empty:
        fig.add_trace(go.Scatter(
            x=deliveries['date'],
            y=deliveries['stock'],
            mode='markers',
            name='ç´å“',
            marker=dict(color='green', size=12, symbol='triangle-up')
        ))
    
    fig.update_layout(
        title='åœ¨åº«æ¨ç§»ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³',
        xaxis_title='æ—¥ä»˜',
        yaxis_title='åœ¨åº«æ•°ï¼ˆä½“ï¼‰',
        height=300,
        margin=dict(l=10, r=10, t=40, b=10),
        legend=dict(
            orientation='h',
            yanchor='bottom',
            y=1.02,
            xanchor='center',
            x=0.5
        ),
        dragmode=False,
    )
    
    config = {
        'displayModeBar': False,
        'staticPlot': False,
        'responsive': True
    }
    
    st.plotly_chart(fig, use_container_width=True, config=config)
    
    stock_below_min = df[df['stock'] < min_stock]
    if not stock_below_min.empty:
        first_danger = stock_below_min.iloc[0]['date']
        st.warning(f"âš ï¸ {first_danger.strftime('%Y/%m/%d')}é ƒã«åœ¨åº«ãŒå®‰å…¨åœ¨åº«ã‚’ä¸‹å›ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")


# =============================================================================
# æ–°è¦æˆä¸å“ã®éœ€è¦äºˆæ¸¬
# =============================================================================

def render_new_product_forecast():
    """æ–°è¦æˆä¸å“ã®éœ€è¦äºˆæ¸¬"""
    
    st.markdown("""
    <div class="new-product-card">
        <h2>âœ¨ æ–°è¦æˆä¸å“ã®éœ€è¦äºˆæ¸¬</h2>
        <p>ã¾ã è²©å£²å®Ÿç¸¾ã®ãªã„æ–°ã—ã„æˆä¸å“ã®éœ€è¦ã‚’ã€é¡ä¼¼å•†å“ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰äºˆæ¸¬ã—ã¾ã™ã€‚</p>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown('<p class="section-header">â‘  æ–°è¦æˆä¸å“ã®æƒ…å ±ã‚’å…¥åŠ›</p>', unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        new_product_name = st.text_input(
            "æˆä¸å“å",
            placeholder="ä¾‹: ç¸çµã³æ°´æ™¶å®ˆ",
            help="æ–°ã—ãä½œã‚‹æˆä¸å“ã®åå‰"
        )
        
        new_product_category = st.selectbox(
            "ã‚«ãƒ†ã‚´ãƒªãƒ¼",
            list(CATEGORY_CHARACTERISTICS.keys()),
            help="æœ€ã‚‚è¿‘ã„ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’é¸ã‚“ã§ãã ã•ã„"
        )
        
        new_product_price = st.number_input(
            "ä¾¡æ ¼ï¼ˆå††ï¼‰",
            min_value=100,
            max_value=50000,
            value=1000,
            step=100,
            help="è²©å£²äºˆå®šä¾¡æ ¼"
        )
    
    with col2:
        new_product_description = st.text_area(
            "ç‰¹å¾´ãƒ»ã‚³ãƒ³ã‚»ãƒ—ãƒˆ",
            placeholder="ä¾‹: æ°´æ™¶ã‚’ä½¿ç”¨ã—ãŸç¸çµã³ã®ãŠå®ˆã‚Šã€‚è‹¥ã„å¥³æ€§å‘ã‘ã€‚",
            help="æˆä¸å“ã®ç‰¹å¾´ã‚’è¨˜è¿°"
        )
        
        target_audience = st.multiselect(
            "ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤",
            ["è‹¥ã„å¥³æ€§", "è‹¥ã„ç”·æ€§", "ä¸­é«˜å¹´å¥³æ€§", "ä¸­é«˜å¹´ç”·æ€§", "å®¶æ—é€£ã‚Œ", "è¦³å…‰å®¢", "åœ°å…ƒã®æ–¹"],
            default=["è‹¥ã„å¥³æ€§", "è¦³å…‰å®¢"]
        )
    
    st.markdown('<p class="section-header">â‘¡ é¡ä¼¼å•†å“ã‚’åˆ†æ</p>', unsafe_allow_html=True)
    
    if new_product_name and new_product_name.strip():
        similar_products = find_similar_products(
            new_product_name, 
            new_product_category, 
            new_product_price,
            new_product_description
        )
        
        if similar_products:
            st.write(f"**é¡ä¼¼å•†å“ãŒ {len(similar_products)} ä»¶è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ**")
            
            for i, prod in enumerate(similar_products[:5], 1):
                col1, col2, col3 = st.columns([3, 1, 1])
                with col1:
                    st.write(f"{i}. {prod['name']}")
                with col2:
                    st.write(f"å¹³å‡ {prod['avg_daily']:.1f}ä½“/æ—¥")
                with col3:
                    st.write(f"é¡ä¼¼åº¦ {prod['similarity']:.0f}%")
        else:
            st.info("é¡ä¼¼å•†å“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®å¹³å‡å€¤ã‹ã‚‰äºˆæ¸¬ã—ã¾ã™ã€‚")
    else:
        similar_products = []
        st.info("ğŸ‘† æˆä¸å“åã‚’å…¥åŠ›ã™ã‚‹ã¨ã€é¡ä¼¼å•†å“ã‚’æ¤œç´¢ã—ã¾ã™")
    
    st.markdown('<p class="section-header">â‘¢ éœ€è¦äºˆæ¸¬</p>', unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        forecast_period = st.selectbox(
            "äºˆæ¸¬æœŸé–“",
            ["1ãƒ¶æœˆ", "3ãƒ¶æœˆ", "6ãƒ¶æœˆ", "1å¹´"],
            index=2
        )
    
    with col2:
        confidence_level = st.selectbox(
            "äºˆæ¸¬ã®ä¿å®ˆæ€§",
            ["æ¥½è¦³çš„", "æ¨™æº–", "ä¿å®ˆçš„"],
            index=1
        )
    
    if st.button("ğŸ”® æ–°è¦æˆä¸å“ã®éœ€è¦ã‚’äºˆæ¸¬", type="primary", use_container_width=True):
        if not new_product_name or not new_product_name.strip():
            st.error("æˆä¸å“åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        else:
            with st.spinner("äºˆæ¸¬ä¸­..."):
                forecast_result = forecast_new_product(
                    new_product_name,
                    new_product_category,
                    new_product_price,
                    similar_products,
                    forecast_period,
                    confidence_level
                )
                
                display_new_product_forecast(forecast_result, new_product_name, new_product_price)


def find_similar_products(name: str, category: str, price: int, description: str) -> list:
    """é¡ä¼¼å•†å“ã‚’æ¢ã™"""
    
    if not name or not name.strip():
        return []
    
    if st.session_state.data_loader is None:
        return []
    
    df_items = st.session_state.data_loader.load_item_sales()
    
    if df_items.empty:
        return []
    
    product_col = 'å•†å“å'
    qty_col = 'è²©å£²å•†å“æ•°'
    sales_col = 'è²©å£²ç·å£²ä¸Š'
    
    product_stats = df_items.groupby(product_col).agg({
        qty_col: ['sum', 'mean', 'count'],
        sales_col: 'sum'
    }).reset_index()
    
    product_stats.columns = ['name', 'total_qty', 'avg_daily', 'days_count', 'total_sales']
    
    product_stats['unit_price'] = product_stats['total_sales'] / product_stats['total_qty']
    product_stats['unit_price'] = product_stats['unit_price'].fillna(0)
    
    similar = []
    
    keywords = set(re.findall(r'[\u4e00-\u9fff]+', name.lower()))
    if description:
        keywords.update(re.findall(r'[\u4e00-\u9fff]+', description.lower()))
    
    for _, row in product_stats.iterrows():
        prod_name = row['name']
        
        name_keywords = set(re.findall(r'[\u4e00-\u9fff]+', prod_name.lower()))
        name_match = len(keywords & name_keywords) / max(len(keywords), 1) * 50
        
        if row['unit_price'] > 0:
            price_diff = abs(price - row['unit_price']) / price
            price_match = max(0, (1 - price_diff)) * 30
        else:
            price_match = 0
        
        category_keywords = {
            "ãŠå®ˆã‚Š": ["å®ˆ", "ãŠå®ˆã‚Š", "ã¾ã‚‚ã‚Š"],
            "å¾¡æœ±å°": ["å¾¡æœ±å°", "æœ±å°"],
            "å¾¡æœ±å°å¸³": ["å¾¡æœ±å°å¸³", "æœ±å°å¸³"],
            "ãŠã¿ãã˜": ["ãŠã¿ãã˜", "ã¿ãã˜"],
            "çµµé¦¬": ["çµµé¦¬"],
            "ãŠæœ­": ["æœ­", "ãŠæœ­"],
            "ç¸èµ·ç‰©": ["ç¸èµ·", "ã ã‚‹ã¾", "æ‹›ãçŒ«"],
        }
        
        cat_match = 0
        for cat, kws in category_keywords.items():
            if cat == category:
                for kw in kws:
                    if kw in prod_name:
                        cat_match = 20
                        break
        
        similarity = name_match + price_match + cat_match
        
        if similarity > 10 and row['total_qty'] > 0:
            similar.append({
                'name': prod_name,
                'total_qty': row['total_qty'],
                'avg_daily': row['avg_daily'],
                'unit_price': row['unit_price'],
                'similarity': similarity
            })
    
    similar.sort(key=lambda x: x['similarity'], reverse=True)
    
    return similar[:10]


def forecast_new_product(name: str, category: str, price: int, 
                         similar_products: list, period: str, confidence: str) -> dict:
    """æ–°è¦æˆä¸å“ã®éœ€è¦ã‚’äºˆæ¸¬"""
    
    period_days = {"1ãƒ¶æœˆ": 30, "3ãƒ¶æœˆ": 90, "6ãƒ¶æœˆ": 180, "1å¹´": 365}[period]
    confidence_factor = {"æ¥½è¦³çš„": 1.2, "æ¨™æº–": 1.0, "ä¿å®ˆçš„": 0.7}[confidence]
    
    if similar_products:
        weighted_sum = sum(p['avg_daily'] * p['similarity'] for p in similar_products[:5])
        weight_total = sum(p['similarity'] for p in similar_products[:5])
        base_daily = weighted_sum / weight_total if weight_total > 0 else 1.0
    else:
        base_daily = CATEGORY_CHARACTERISTICS.get(category, {}).get('base_daily', 1.0)
    
    cat_char = CATEGORY_CHARACTERISTICS.get(category, {})
    seasonality = cat_char.get('seasonality', 'medium')
    
    if seasonality == 'high':
        month_factors = {1: 3.0, 2: 0.7, 3: 0.9, 4: 0.9, 5: 1.0, 6: 0.8,
                        7: 0.9, 8: 1.1, 9: 0.9, 10: 1.0, 11: 1.2, 12: 1.5}
    elif seasonality == 'medium':
        month_factors = {1: 1.5, 2: 0.9, 3: 1.0, 4: 1.0, 5: 1.1, 6: 0.9,
                        7: 1.0, 8: 1.1, 9: 1.0, 10: 1.0, 11: 1.1, 12: 1.2}
    else:
        month_factors = {i: 1.0 for i in range(1, 13)}
    
    daily_forecast = []
    total_qty = 0
    
    for i in range(period_days):
        target_date = date.today() + timedelta(days=i)
        month = target_date.month
        weekday = target_date.weekday()
        
        weekday_factor = 1.5 if weekday >= 5 else 1.0
        month_factor = month_factors.get(month, 1.0)
        
        pred = base_daily * weekday_factor * month_factor * confidence_factor
        pred = max(0, round(pred))
        
        daily_forecast.append({
            'date': target_date,
            'predicted': pred
        })
        
        total_qty += pred
    
    total_qty_rounded = round_up_to_50(total_qty)
    
    df_forecast = pd.DataFrame(daily_forecast)
    df_forecast['month'] = pd.to_datetime(df_forecast['date']).dt.to_period('M')
    monthly = df_forecast.groupby('month')['predicted'].sum().to_dict()
    
    return {
        'daily_forecast': daily_forecast,
        'total_qty': total_qty,
        'total_qty_rounded': total_qty_rounded,
        'avg_daily': total_qty / period_days,
        'period_days': period_days,
        'monthly': monthly,
        'base_daily': base_daily,
        'confidence': confidence,
        'similar_count': len(similar_products)
    }


def display_new_product_forecast(result: dict, product_name: str, price: int):
    """æ–°è¦æˆä¸å“ã®äºˆæ¸¬çµæœã‚’è¡¨ç¤º"""
    
    st.success("âœ… äºˆæ¸¬å®Œäº†ï¼")
    
    st.write(f"### ğŸ“¦ ã€Œ{product_name}ã€ã®éœ€è¦äºˆæ¸¬")
    
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("äºˆæ¸¬è²©å£²ç·æ•°", f"{result['total_qty_rounded']:,}ä½“")
    col2.metric("äºˆæ¸¬å£²ä¸Š", f"Â¥{result['total_qty_rounded'] * price:,.0f}")
    col3.metric("å¹³å‡æ—¥è²©", f"{result['avg_daily']:.1f}ä½“/æ—¥")
    col4.metric("äºˆæ¸¬æœŸé–“", f"{result['period_days']}æ—¥é–“")
    
    if result['similar_count'] >= 3:
        st.info(f"ğŸ“Š é¡ä¼¼å•†å“ {result['similar_count']} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’åŸºã«äºˆæ¸¬ã—ã¾ã—ãŸã€‚ä¿¡é ¼åº¦: â­â­â­")
    elif result['similar_count'] >= 1:
        st.warning(f"ğŸ“Š é¡ä¼¼å•†å“ {result['similar_count']} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’åŸºã«äºˆæ¸¬ã—ã¾ã—ãŸã€‚ä¿¡é ¼åº¦: â­â­")
    else:
        st.warning("ğŸ“Š é¡ä¼¼å•†å“ãŒãªã‹ã£ãŸãŸã‚ã€ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®å¹³å‡å€¤ã‹ã‚‰äºˆæ¸¬ã—ã¾ã—ãŸã€‚ä¿¡é ¼åº¦: â­")
    
    monthly_data = []
    for period, qty in result['monthly'].items():
        monthly_data.append({'æœˆ': str(period), 'äºˆæ¸¬è²©å£²æ•°': qty})
    
    df_monthly = pd.DataFrame(monthly_data)
    
    fig = px.bar(
        df_monthly, x='æœˆ', y='äºˆæ¸¬è²©å£²æ•°',
        title='æœˆåˆ¥äºˆæ¸¬è²©å£²æ•°',
        color='äºˆæ¸¬è²©å£²æ•°',
        color_continuous_scale='Blues'
    )
    st.plotly_chart(fig, use_container_width=True)
    
    st.write("### ğŸ“‹ åˆå›ç™ºæ³¨é‡ã®ææ¡ˆ")
    
    col1, col2, col3 = st.columns(3)
    col1.metric("å°‘ãªã‚ï¼ˆ1ãƒ¶æœˆåˆ†ï¼‰", f"{round_up_to_50(int(result['avg_daily'] * 30))}ä½“")
    col2.metric("æ¨™æº–ï¼ˆ3ãƒ¶æœˆåˆ†ï¼‰", f"{round_up_to_50(int(result['avg_daily'] * 90))}ä½“")
    col3.metric("å¤šã‚ï¼ˆ6ãƒ¶æœˆåˆ†ï¼‰", f"{round_up_to_50(int(result['avg_daily'] * 180))}ä½“")


# =============================================================================
# é«˜åº¦ãªåˆ†æ
# =============================================================================

def render_advanced_analysis():
    """é«˜åº¦ãªåˆ†æã‚¿ãƒ–"""
    st.markdown('<p class="section-header">ğŸ”¬ é«˜åº¦ãªåˆ†æ</p>', unsafe_allow_html=True)
    
    if not ADVANCED_ANALYSIS_AVAILABLE:
        st.warning("demand_analyzer.pyãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    sales_data = st.session_state.get('sales_data')
    
    if sales_data is None or sales_data.empty:
        st.info("ã€Œæ—¢å­˜æˆä¸å“ã®åˆ†æãƒ»äºˆæ¸¬ã€ã‚¿ãƒ–ã§æˆä¸å“ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return
    
    try:
        df_items = st.session_state.data_loader.load_item_sales()
        internal = InternalAnalyzer(df_items)
        external = ExternalAnalyzer(df_items, None)
    except Exception as e:
        st.error(f"åˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return
    
    with st.expander("ğŸ“Š **é«˜åº¦ãªåˆ†æã‚’è¦‹ã‚‹**", expanded=False):
        tab1, tab2, tab3 = st.tabs(["ğŸ“ˆ ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ", "ğŸ—“ï¸ å­£ç¯€æ€§åˆ†æ", "ğŸŒ¤ï¸ å¤–éƒ¨è¦å› åˆ†æ"])
        
        with tab1:
            render_trend_analysis(internal)
        
        with tab2:
            render_seasonality_analysis(internal)
        
        with tab3:
            render_external_analysis(external)


def render_trend_analysis(internal):
    """ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã‚’è¡¨ç¤º"""
    st.write("### ğŸ“ˆ è²©å£²ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ")
    
    try:
        trend = internal.analyze_sales_trend()
        
        col1, col2, col3 = st.columns(3)
        col1.metric("ãƒˆãƒ¬ãƒ³ãƒ‰æ–¹å‘", trend['trend_direction'])
        col2.metric("æˆé•·ç‡", f"{trend['growth_rate']}%")
        col3.metric("å¤‰å‹•æ€§", f"{trend['volatility']:.2f}")
        
        if 'monthly_data' in trend and not trend['monthly_data'].empty:
            fig = px.line(
                trend['monthly_data'], 
                x='period', 
                y='è²©å£²å•†å“æ•°',
                title='æœˆåˆ¥è²©å£²æ¨ç§»'
            )
            st.plotly_chart(fig, use_container_width=True)
    except Exception as e:
        st.warning(f"ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")


def render_seasonality_analysis(internal):
    """å­£ç¯€æ€§åˆ†æã‚’è¡¨ç¤º"""
    st.write("### ğŸ—“ï¸ å­£ç¯€æ€§åˆ†æ")
    
    try:
        seasonality = internal.detect_seasonality()
        
        st.metric("å­£ç¯€æ€§ã®å¼·ã•", f"{seasonality['seasonality_strength']:.2f}")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**æœˆåˆ¥ä¿‚æ•°**")
            monthly = seasonality['monthly_pattern']
            df_monthly = pd.DataFrame({
                'æœˆ': list(monthly.keys()),
                'ä¿‚æ•°': list(monthly.values())
            })
            fig = px.bar(df_monthly, x='æœˆ', y='ä¿‚æ•°', title='æœˆåˆ¥è²©å£²ä¿‚æ•°')
            fig.add_hline(y=1.0, line_dash="dash", line_color="red")
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.write("**æ›œæ—¥åˆ¥ä¿‚æ•°**")
            weekday = seasonality['weekday_pattern']
            df_weekday = pd.DataFrame({
                'æ›œæ—¥': list(weekday.keys()),
                'ä¿‚æ•°': list(weekday.values())
            })
            fig = px.bar(df_weekday, x='æ›œæ—¥', y='ä¿‚æ•°', title='æ›œæ—¥åˆ¥è²©å£²ä¿‚æ•°')
            fig.add_hline(y=1.0, line_dash="dash", line_color="red")
            st.plotly_chart(fig, use_container_width=True)
    except Exception as e:
        st.warning(f"å­£ç¯€æ€§åˆ†æã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")


def render_external_analysis(external):
    """å¤–éƒ¨è¦å› åˆ†æã‚’è¡¨ç¤º"""
    st.write("### ğŸŒ¤ï¸ å¤–éƒ¨è¦å› åˆ†æ")
    
    try:
        calendar_effect = external.analyze_calendar_effect()
        
        if calendar_effect.get('available', False):
            st.metric("ä¼‘æ—¥ã®å½±éŸ¿åº¦", f"{calendar_effect['holiday_impact']:.2f}x")
        else:
            st.info("ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚ã€å¤–éƒ¨è¦å› åˆ†æã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
    except Exception as e:
        st.warning(f"å¤–éƒ¨è¦å› åˆ†æã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")


# =============================================================================
# äºˆæ¸¬ç²¾åº¦ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
# =============================================================================

def render_accuracy_dashboard():
    """äºˆæ¸¬ç²¾åº¦ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"""
    
    st.markdown('<p class="section-header">ğŸ“ˆ äºˆæ¸¬ç²¾åº¦ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰</p>', unsafe_allow_html=True)
    
    try:
        service = st.session_state.data_loader.service
        result = service.spreadsheets().values().get(
            spreadsheetId=st.session_state.data_loader.spreadsheet_id,
            range="'forecast_accuracy'!A:H"
        ).execute()
        
        values = result.get('values', [])
        
        if len(values) <= 1:
            st.info("""
            ğŸ“Š ã¾ã äºˆæ¸¬ç²¾åº¦ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚
            
            è‡ªå‹•å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ãŒç¨¼åƒã™ã‚‹ã¨ã€ã“ã“ã«äºˆæ¸¬ç²¾åº¦ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚
            """)
            return
        
        headers = values[0]
        df = pd.DataFrame(values[1:], columns=headers)
        
        df['date'] = pd.to_datetime(df['date'], errors='coerce')
        df['predicted_qty'] = pd.to_numeric(df['predicted_qty'], errors='coerce')
        df['actual_qty'] = pd.to_numeric(df['actual_qty'], errors='coerce')
        df['diff_pct'] = pd.to_numeric(df['diff_pct'], errors='coerce')
        
        st.write("### éå»30æ—¥é–“ã®äºˆæ¸¬ç²¾åº¦")
        
        recent = df[df['date'] >= (datetime.now() - timedelta(days=30))]
        
        if not recent.empty:
            avg_error = recent['diff_pct'].abs().mean()
            total_predicted = recent['predicted_qty'].sum()
            total_actual = recent['actual_qty'].sum()
            accuracy = 100 - avg_error
            
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("å¹³å‡èª¤å·®ç‡", f"{avg_error:.1f}%")
            col2.metric("äºˆæ¸¬ç²¾åº¦", f"{accuracy:.1f}%")
            col3.metric("äºˆæ¸¬åˆè¨ˆ", f"{total_predicted:.0f}ä½“")
            col4.metric("å®Ÿç¸¾åˆè¨ˆ", f"{total_actual:.0f}ä½“")
            
            fig = go.Figure()
            
            daily = recent.groupby('date').agg({
                'predicted_qty': 'sum',
                'actual_qty': 'sum'
            }).reset_index()
            
            fig.add_trace(go.Scatter(
                x=daily['date'],
                y=daily['predicted_qty'],
                mode='lines+markers',
                name='äºˆæ¸¬',
                line=dict(color='#4285F4')
            ))
            
            fig.add_trace(go.Scatter(
                x=daily['date'],
                y=daily['actual_qty'],
                mode='lines+markers',
                name='å®Ÿç¸¾',
                line=dict(color='#4CAF50')
            ))
            
            fig.update_layout(
                title='äºˆæ¸¬ vs å®Ÿç¸¾ï¼ˆæ—¥åˆ¥ï¼‰',
                xaxis_title='æ—¥ä»˜',
                yaxis_title='è²©å£²æ•°ï¼ˆä½“ï¼‰'
            )
            
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("éå»30æ—¥é–“ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
    
    except Exception as e:
        st.info("""
        ğŸ“Š äºˆæ¸¬ç²¾åº¦ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’è¡¨ç¤ºã™ã‚‹ã«ã¯ã€è‡ªå‹•å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãŒå¿…è¦ã§ã™ã€‚
        """)


# =============================================================================
# ãƒ¡ã‚¤ãƒ³é–¢æ•°
# =============================================================================

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    
    if not init_data():
        st.stop()
    
    render_header()
    st.divider()
    render_main_tabs()
    
    st.divider()
    
    # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±
    version_info = "v16 (å€‹åˆ¥ç´å“è¨ˆç”»ãƒ»ç™ºæ³¨ãƒ­ã‚¸ãƒƒã‚¯å¼·åŒ–ç‰ˆ)"
    if VERTEX_AI_AVAILABLE:
        version_info += " | ğŸš€ Vertex AI: æœ‰åŠ¹"
    else:
        version_info += " | âš ï¸ Vertex AI: æœªè¨­å®š"
    
    st.caption(f"â›©ï¸ é…’åˆ—ç£¯å‰ç¥ç¤¾ æˆä¸å“ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ  {version_info}")


if __name__ == "__main__":
    main()
