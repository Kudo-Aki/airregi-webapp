"""
Airãƒ¬ã‚¸ å£²ä¸Šåˆ†æãƒ»éœ€è¦äºˆæ¸¬ Webã‚¢ãƒ—ãƒªï¼ˆv20: ç²¾åº¦å‘ä¸Šç‰ˆ - 0åŸ‹ã‚ãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»æ­£æœˆæ—¥åˆ¥å¯¾å¿œï¼‰

v19ã‹ã‚‰ã®å¤‰æ›´ç‚¹ï¼ˆv20æ–°æ©Ÿèƒ½ï¼‰:
1. ã€äºˆæ¸¬ç²¾åº¦ã®å¤§å¹…å‘ä¸Šã€‘
   - 0åŸ‹ã‚å‡¦ç†: å£²ä¸ŠãŒãªã„æ—¥ã‚’0ã§è£œå®Œã—ã€æ­£ç¢ºãªæ›œæ—¥ãƒ»å­£ç¯€ä¿‚æ•°ã‚’è¨ˆç®—
   - æ¬ å“æœŸé–“é™¤å¤–: åœ¨åº«åˆ‡ã‚ŒæœŸé–“ã‚’å­¦ç¿’ã‹ã‚‰é™¤å¤–ï¼ˆéœ€è¦ã¨ä¾›çµ¦åˆ¶ç´„ã‚’åˆ†é›¢ï¼‰
   - ãƒˆãƒ¬ãƒ³ãƒ‰ä¿‚æ•°: å‰å¹´åŒæœŸæ¯”ã®æˆé•·ç‡ã‚’äºˆæ¸¬ã«åæ˜ 
   - æ­£æœˆæ—¥åˆ¥ä¿‚æ•°: 1/1ã€œ1/7ã‚’æ—¥åˆ¥ã«ä¿‚æ•°è¨­å®šï¼ˆå…ƒæ—¥ãƒ”ãƒ¼ã‚¯å¯¾å¿œï¼‰
   
2. ã€ç™ºæ³¨æ”¯æ´æ©Ÿèƒ½ã€‘
   - ç™ºæ³¨ç‚¹ï¼ˆãƒªã‚ªãƒ¼ãƒ€ãƒ¼ãƒã‚¤ãƒ³ãƒˆï¼‰ã®è‡ªå‹•è¨ˆç®—
   - å®‰å…¨åœ¨åº«ã®ç®—å‡ºï¼ˆã‚µãƒ¼ãƒ“ã‚¹ãƒ¬ãƒ™ãƒ«åˆ¥ï¼‰
   - æ¨å¥¨ç™ºæ³¨é‡ã®è¡¨ç¤º

3. ã€UIæ”¹å–„ã€‘
   - v20ç²¾åº¦å‘ä¸Šã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®expanderè¿½åŠ 
   - æ¬ å“æœŸé–“ã®å…¥åŠ›UI
   - ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»æ­£æœˆæ—¥åˆ¥ã®ON/OFFåˆ‡ã‚Šæ›¿ãˆ

v19ã‹ã‚‰ã®ç¶­æŒæ©Ÿèƒ½:
- ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³è¨ˆç®—ï¼ˆä¸­å¤®å€¤/ãƒˆãƒªãƒ å¹³å‡ï¼‰
- ç‰¹åˆ¥æœŸé–“ä¿‚æ•°ã®è‡ªå‹•è¨ˆç®—
- åˆ†ä½ç‚¹äºˆæ¸¬ï¼ˆP50/P80/P90ï¼‰
- ç™ºæ³¨ãƒ¢ãƒ¼ãƒ‰é¸æŠï¼ˆæ»ç•™å›é¿/ãƒãƒ©ãƒ³ã‚¹/æ¬ å“å›é¿ï¼‰
- ç°¡æ˜“ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæ©Ÿèƒ½ï¼ˆMAPEè¡¨ç¤ºï¼‰
- st.secretså¯¾å¿œï¼ˆStreamlit Cloudæ¨å¥¨ï¼‰
- HTMLæ³¨å…¥å¯¾ç­–
- st.formã«ã‚ˆã‚‹äºˆæ¸¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š

v18ä»¥å‰ã‹ã‚‰ã®ç¶­æŒæ©Ÿèƒ½:
- ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆæ©Ÿèƒ½
- è¤‡æ•°æˆä¸å“é¸æŠæ™‚ã«ã€Œåˆç®—ã€ã€Œå€‹åˆ¥ã€ã‚’é¸æŠå¯èƒ½
- äºˆæ¸¬æœŸé–“ã‚’ã€Œæ—¥æ•°æŒ‡å®šã€ã€ŒæœŸé–“æŒ‡å®šã€ã§é¸æŠå¯èƒ½
- æ–°è¦æˆä¸å“ã®éœ€è¦äºˆæ¸¬ï¼ˆé¡ä¼¼å•†å“ãƒ™ãƒ¼ã‚¹ï¼‰
- äºˆæ¸¬ç²¾åº¦ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
- é«˜åº¦ãªåˆ†æã‚¿ãƒ–
- ã‚°ãƒ«ãƒ¼ãƒ—æ©Ÿèƒ½ï¼ˆåˆç®—/å˜ç‹¬ï¼‰
- å¹´æ¬¡æ¯”è¼ƒ
- Airãƒ¬ã‚¸ãƒ»éƒµé€ã®å†…è¨³è¡¨ç¤º
- ã™ã¹ã¦ã®æ–¹æ³•ã§æ¯”è¼ƒï¼ˆãƒãƒˆãƒªãƒƒã‚¯ã‚¹å½¢å¼ï¼‰
- ç´å“è¨ˆç”»
- Vertex AI AutoML Forecastingé€£æº
"""

import streamlit as st
import pandas as pd
import numpy as np
from datetime import date, datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
import plotly.express as px
import plotly.graph_objects as go
from collections import defaultdict
import calendar
import re
import os
import json
import logging
import hashlib
import html  # XSSå¯¾ç­–ç”¨

# scipyï¼ˆçµ±è¨ˆå‡¦ç†ç”¨ï¼‰- ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«
try:
    from scipy import stats
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False
    logger_temp = logging.getLogger(__name__)
    logger_temp.warning("scipyãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ä¸€éƒ¨ã®çµ±è¨ˆæ©Ÿèƒ½ãŒåˆ¶é™ã•ã‚Œã¾ã™ã€‚")

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import sys
sys.path.append('.')
from modules.data_loader import SheetsDataLoader, aggregate_by_products, merge_with_calendar
from modules.product_normalizer import ProductNormalizer
import config

# é«˜åº¦ãªåˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ï¼‰
try:
    from modules.demand_analyzer import InternalAnalyzer, ExternalAnalyzer, MarketAnalyzer, DemandForecastEngine
    ADVANCED_ANALYSIS_AVAILABLE = True
except ImportError:
    ADVANCED_ANALYSIS_AVAILABLE = False


# =============================================================================
# Vertex AI AutoML Forecasting çµ±åˆ
# =============================================================================

# Vertex AIè¨­å®šï¼ˆconfig.pyã¾ãŸã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼‰
VERTEX_AI_CONFIG = {
    'project_id': getattr(config, 'VERTEX_AI_PROJECT_ID', os.environ.get('VERTEX_AI_PROJECT_ID', '')),
    'location': getattr(config, 'VERTEX_AI_LOCATION', os.environ.get('VERTEX_AI_LOCATION', 'asia-northeast1')),
    'endpoint_id': getattr(config, 'VERTEX_AI_ENDPOINT_ID', os.environ.get('VERTEX_AI_ENDPOINT_ID', '')),
    'service_account_file': getattr(config, 'VERTEX_AI_SERVICE_ACCOUNT_FILE', 
                                     os.environ.get('VERTEX_AI_SERVICE_ACCOUNT_FILE', 'service_account.json')),
}

# Vertex AIåˆ©ç”¨å¯èƒ½ãƒ•ãƒ©ã‚°
VERTEX_AI_AVAILABLE = False
aiplatform = None
prediction_service_client = None

# =============================================================================
# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–: GCPèªè¨¼ã®ãƒ¢ãƒ€ãƒ³åŒ–
# =============================================================================

def get_gcp_credentials():
    """
    GCPèªè¨¼æƒ…å ±ã‚’å–å¾—ï¼ˆå„ªå…ˆé †ä½: st.secrets > ç’°å¢ƒå¤‰æ•° > ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
    
    Streamlit Cloudæ¨å¥¨ã®èªè¨¼æ–¹å¼ã«å¯¾å¿œ
    """
    from google.oauth2 import service_account
    
    credentials = None
    auth_method = None
    
    try:
        # 1. st.secretsã‹ã‚‰å–å¾—ï¼ˆStreamlit Cloudæ¨å¥¨ï¼‰
        if hasattr(st, 'secrets') and 'gcp_service_account' in st.secrets:
            try:
                service_account_info = dict(st.secrets['gcp_service_account'])
                credentials = service_account.Credentials.from_service_account_info(
                    service_account_info,
                    scopes=['https://www.googleapis.com/auth/cloud-platform']
                )
                auth_method = "st.secrets"
                logger.info("GCPèªè¨¼: st.secretsã‹ã‚‰å–å¾—æˆåŠŸ")
                return credentials, auth_method
            except Exception as e:
                logger.warning(f"st.secretsã‹ã‚‰ã®èªè¨¼å–å¾—å¤±æ•—: {e}")
        
        # 2. ç’°å¢ƒå¤‰æ•°ã‹ã‚‰JSONæ–‡å­—åˆ—ã‚’å–å¾—
        env_json = os.environ.get('VERTEX_AI_SERVICE_ACCOUNT_JSON')
        if env_json:
            try:
                service_account_info = json.loads(env_json)
                credentials = service_account.Credentials.from_service_account_info(
                    service_account_info,
                    scopes=['https://www.googleapis.com/auth/cloud-platform']
                )
                auth_method = "ç’°å¢ƒå¤‰æ•°(JSON)"
                logger.info("GCPèªè¨¼: ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—æˆåŠŸ")
                return credentials, auth_method
            except Exception as e:
                logger.warning(f"ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ã®èªè¨¼å–å¾—å¤±æ•—: {e}")
        
        # 3. ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å–å¾—ï¼ˆå¾“æ¥æ–¹å¼ï¼‰
        sa_file = VERTEX_AI_CONFIG['service_account_file']
        if os.path.exists(sa_file):
            try:
                credentials = service_account.Credentials.from_service_account_file(
                    sa_file,
                    scopes=['https://www.googleapis.com/auth/cloud-platform']
                )
                auth_method = "ãƒ•ã‚¡ã‚¤ãƒ«"
                logger.info(f"GCPèªè¨¼: ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å–å¾—æˆåŠŸ ({sa_file})")
                return credentials, auth_method
            except Exception as e:
                logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®èªè¨¼å–å¾—å¤±æ•—: {e}")
        
        # 4. Application Default Credentialsï¼ˆADCï¼‰ã‚’è©¦è¡Œ
        try:
            import google.auth
            credentials, project = google.auth.default(
                scopes=['https://www.googleapis.com/auth/cloud-platform']
            )
            auth_method = "ADC"
            logger.info("GCPèªè¨¼: ADCã‹ã‚‰å–å¾—æˆåŠŸ")
            return credentials, auth_method
        except Exception as e:
            logger.warning(f"ADCã‹ã‚‰ã®èªè¨¼å–å¾—å¤±æ•—: {e}")
    
    except Exception as e:
        logger.error(f"GCPèªè¨¼å–å¾—ä¸­ã®äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
    
    return None, None


def safe_html(text: str) -> str:
    """
    HTMLæ³¨å…¥å¯¾ç­–: ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
    
    Args:
        text: ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
    
    Returns:
        ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—æ¸ˆã¿ãƒ†ã‚­ã‚¹ãƒˆ
    """
    if text is None:
        return ""
    return html.escape(str(text))


def mask_sensitive_value(value: str, visible_chars: int = 4) -> str:
    """
    æ©Ÿå¯†æƒ…å ±ã‚’ãƒã‚¹ã‚¯è¡¨ç¤º
    
    Args:
        value: ãƒã‚¹ã‚¯ã™ã‚‹å€¤
        visible_chars: è¡¨ç¤ºã™ã‚‹æ–‡å­—æ•°
    
    Returns:
        ãƒã‚¹ã‚¯æ¸ˆã¿ã®å€¤
    """
    if not value or len(value) <= visible_chars:
        return "***"
    return value[:visible_chars] + "***"


try:
    from google.cloud import aiplatform
    from google.cloud.aiplatform.gapic.schema import predict as predict_schema
    from google.protobuf import json_format
    from google.protobuf.struct_pb2 import Value
    from google.oauth2 import service_account
    from google.api_core import exceptions as google_exceptions
    
    # èªè¨¼æƒ…å ±ã‚’å–å¾—
    credentials, auth_method = get_gcp_credentials()
    
    if credentials and VERTEX_AI_CONFIG['project_id'] and VERTEX_AI_CONFIG['endpoint_id']:
        # Vertex AIåˆæœŸåŒ–
        aiplatform.init(
            project=VERTEX_AI_CONFIG['project_id'],
            location=VERTEX_AI_CONFIG['location'],
            credentials=credentials
        )
        VERTEX_AI_AVAILABLE = True
        logger.info(f"Vertex AI AutoML Forecasting: åˆæœŸåŒ–æˆåŠŸ (èªè¨¼æ–¹å¼: {auth_method})")
    else:
        if not credentials:
            logger.warning("Vertex AI: èªè¨¼æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        if not VERTEX_AI_CONFIG['project_id']:
            logger.warning("Vertex AI: project_idãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        if not VERTEX_AI_CONFIG['endpoint_id']:
            logger.warning("Vertex AI: endpoint_idãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
except ImportError as e:
    logger.warning(f"Vertex AI SDKãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“: {e}")
except Exception as e:
    logger.error(f"Vertex AIåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")


class VertexAIForecaster:
    """Vertex AI AutoML Forecastingã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’å‘¼ã³å‡ºã™ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.project_id = VERTEX_AI_CONFIG['project_id']
        self.location = VERTEX_AI_CONFIG['location']
        self.endpoint_id = VERTEX_AI_CONFIG['endpoint_id']
        self.endpoint_name = f"projects/{self.project_id}/locations/{self.location}/endpoints/{self.endpoint_id}"
        self._client = None
    
    @property
    def client(self):
        """Prediction Service Clientã‚’å–å¾—ï¼ˆé…å»¶åˆæœŸåŒ–ï¼‰"""
        if self._client is None:
            from google.cloud.aiplatform_v1.services.prediction_service import PredictionServiceClient
            from google.cloud.aiplatform_v1.types import PredictRequest
            
            client_options = {"api_endpoint": f"{self.location}-aiplatform.googleapis.com"}
            
            # æ–°ã—ã„èªè¨¼æ–¹å¼ã‚’ä½¿ç”¨
            credentials, _ = get_gcp_credentials()
            if credentials is None:
                raise RuntimeError("GCPèªè¨¼æƒ…å ±ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            
            self._client = PredictionServiceClient(
                credentials=credentials,
                client_options=client_options
            )
        return self._client
    
    def prepare_forecast_instances(
        self,
        historical_data: pd.DataFrame,
        forecast_horizon: int,
        product_id: str,
        covariates: Optional[Dict[str, List]] = None
    ) -> List[Dict[str, Any]]:
        """
        Vertex AI Forecasting APIãŒæœŸå¾…ã™ã‚‹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å½¢å¼ã‚’æº–å‚™
        
        Args:
            historical_data: éå»ã®å£²ä¸Šãƒ‡ãƒ¼ã‚¿ï¼ˆdate, è²©å£²å•†å“æ•°ï¼‰
            forecast_horizon: äºˆæ¸¬æ—¥æ•°
            product_id: å•†å“è­˜åˆ¥å­
            covariates: å°†æ¥åˆ©ç”¨å¯èƒ½ãªå…±å¤‰é‡ï¼ˆå¤©æ°—ã€å…­æ›œã€ã‚¤ãƒ™ãƒ³ãƒˆç­‰ï¼‰
        
        Returns:
            APIãƒªã‚¯ã‚¨ã‚¹ãƒˆç”¨ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãƒªã‚¹ãƒˆ
        """
        df = historical_data.copy()
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values('date')
        
        # æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        time_series = []
        for _, row in df.iterrows():
            time_series.append({
                'timestamp': row['date'].strftime('%Y-%m-%dT00:00:00Z'),
                'target': float(row['è²©å£²å•†å“æ•°'])
            })
        
        # äºˆæ¸¬æœŸé–“ã®æº–å‚™
        last_date = df['date'].max()
        forecast_timestamps = []
        for i in range(1, forecast_horizon + 1):
            future_date = last_date + timedelta(days=i)
            forecast_timestamps.append(future_date.strftime('%Y-%m-%dT00:00:00Z'))
        
        # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ§‹é€ ã®æ§‹ç¯‰
        instance = {
            'time_series_identifier': product_id,
            'time_column': 'timestamp',
            'target_column': 'target',
            'historical_data': time_series,
            'forecast_horizon': forecast_horizon,
            'forecast_timestamps': forecast_timestamps,
        }
        
        # å…±å¤‰é‡ã®è¿½åŠ ï¼ˆå¤©æ°—ã€å…­æ›œã€ã‚¤ãƒ™ãƒ³ãƒˆç­‰ï¼‰
        if covariates:
            instance['available_at_forecast_columns'] = list(covariates.keys())
            
            # éå»ãƒ‡ãƒ¼ã‚¿ã®å…±å¤‰é‡
            if 'historical_covariates' in covariates:
                instance['historical_covariates'] = covariates['historical_covariates']
            
            # å°†æ¥ãƒ‡ãƒ¼ã‚¿ã®å…±å¤‰é‡
            if 'future_covariates' in covariates:
                instance['future_covariates'] = covariates['future_covariates']
        
        return [instance]
    
    def predict(
        self,
        historical_data: pd.DataFrame,
        forecast_horizon: int,
        product_id: str = "default",
        covariates: Optional[Dict[str, List]] = None
    ) -> Tuple[pd.DataFrame, Dict[str, Any]]:
        """
        Vertex AI AutoML Forecastingã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«äºˆæ¸¬ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
        
        Args:
            historical_data: éå»ã®å£²ä¸Šãƒ‡ãƒ¼ã‚¿
            forecast_horizon: äºˆæ¸¬æ—¥æ•°
            product_id: å•†å“è­˜åˆ¥å­
            covariates: å…±å¤‰é‡ãƒ‡ãƒ¼ã‚¿
        
        Returns:
            äºˆæ¸¬çµæœã®DataFrameã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        """
        if not VERTEX_AI_AVAILABLE:
            raise RuntimeError("Vertex AIãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        
        try:
            # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æº–å‚™
            instances = self.prepare_forecast_instances(
                historical_data, forecast_horizon, product_id, covariates
            )
            
            # Protobufå½¢å¼ã«å¤‰æ›
            instances_pb = [json_format.ParseDict(inst, Value()) for inst in instances]
            
            # äºˆæ¸¬ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡
            response = self.client.predict(
                endpoint=self.endpoint_name,
                instances=instances_pb,
            )
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æ
            predictions = []
            metadata = {
                'model_version': getattr(response, 'model_version_id', 'unknown'),
                'deployed_model_id': getattr(response, 'deployed_model_id', 'unknown'),
            }
            
            last_date = pd.to_datetime(historical_data['date']).max()
            
            for i, prediction in enumerate(response.predictions):
                pred_dict = json_format.MessageToDict(prediction)
                
                # äºˆæ¸¬å€¤ã®å–å¾—ï¼ˆAutoML Forecastingã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ã«å¿œã˜ã¦èª¿æ•´ï¼‰
                if 'value' in pred_dict:
                    pred_value = pred_dict['value']
                elif 'predicted_target' in pred_dict:
                    pred_value = pred_dict['predicted_target']
                else:
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒªã‚¹ãƒˆå½¢å¼ã®å ´åˆ
                    pred_value = list(pred_dict.values())[0] if pred_dict else 0
                
                # äºˆæ¸¬å€¤ãŒé…åˆ—ã®å ´åˆã®å‡¦ç†
                if isinstance(pred_value, list):
                    for j, val in enumerate(pred_value):
                        predictions.append({
                            'date': last_date + timedelta(days=j+1),
                            'predicted': max(0, round(float(val))),
                            'confidence_lower': pred_dict.get('lower_bound', [None])[j] if isinstance(pred_dict.get('lower_bound'), list) else None,
                            'confidence_upper': pred_dict.get('upper_bound', [None])[j] if isinstance(pred_dict.get('upper_bound'), list) else None,
                        })
                else:
                    predictions.append({
                        'date': last_date + timedelta(days=i+1),
                        'predicted': max(0, round(float(pred_value))),
                    })
            
            return pd.DataFrame(predictions), metadata
            
        except google_exceptions.ResourceExhausted as e:
            logger.error(f"Vertex AI ã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™: {e}")
            raise RuntimeError(f"APIã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚\nè©³ç´°: {e}")
        
        except google_exceptions.InvalidArgument as e:
            logger.error(f"Vertex AI ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            raise RuntimeError(f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆå½¢å¼ãŒä¸æ­£ã§ã™ã€‚\nè©³ç´°: {e}")
        
        except google_exceptions.NotFound as e:
            logger.error(f"Vertex AI ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆæœªç™ºè¦‹: {e}")
            raise RuntimeError(f"æŒ‡å®šã•ã‚ŒãŸã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚endpoint_idã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\nè©³ç´°: {e}")
        
        except google_exceptions.PermissionDenied as e:
            logger.error(f"Vertex AI æ¨©é™ã‚¨ãƒ©ãƒ¼: {e}")
            raise RuntimeError(f"ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®æ¨©é™ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\nè©³ç´°: {e}")
        
        except Exception as e:
            logger.error(f"Vertex AI äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
            raise RuntimeError(f"äºˆæ¸¬ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\nè©³ç´°: {e}")


# Vertex AIãƒ•ã‚©ã‚¢ã‚­ãƒ£ã‚¹ã‚¿ãƒ¼ã®ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
_vertex_ai_forecaster = None

def get_vertex_ai_forecaster() -> Optional[VertexAIForecaster]:
    """Vertex AIãƒ•ã‚©ã‚¢ã‚­ãƒ£ã‚¹ã‚¿ãƒ¼ã‚’å–å¾—"""
    global _vertex_ai_forecaster
    if VERTEX_AI_AVAILABLE and _vertex_ai_forecaster is None:
        _vertex_ai_forecaster = VertexAIForecaster()
    return _vertex_ai_forecaster


# =============================================================================
# å…±å¤‰é‡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆå¤©æ°—ã€å…­æ›œã€ã‚¤ãƒ™ãƒ³ãƒˆï¼‰
# =============================================================================

def generate_covariates(start_date: date, end_date: date, location: str = "hitachinaka") -> Dict[str, List]:
    """
    å°†æ¥åˆ©ç”¨å¯èƒ½ãªå…±å¤‰é‡ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
    
    Args:
        start_date: é–‹å§‹æ—¥
        end_date: çµ‚äº†æ—¥
        location: åœ°åŸŸï¼ˆå¤©æ°—äºˆå ±ç”¨ï¼‰
    
    Returns:
        å…±å¤‰é‡ãƒ‡ãƒ¼ã‚¿ã®è¾æ›¸
    """
    covariates = {
        'future_covariates': []
    }
    
    current_date = start_date
    while current_date <= end_date:
        covariate_entry = {
            'timestamp': current_date.strftime('%Y-%m-%dT00:00:00Z'),
            'weekday': current_date.weekday(),  # 0=æœˆæ›œ, 6=æ—¥æ›œ
            'is_weekend': 1 if current_date.weekday() >= 5 else 0,
            'month': current_date.month,
            'day_of_month': current_date.day,
        }
        
        # å…­æ›œï¼ˆç°¡æ˜“è¨ˆç®—ï¼‰
        rokuyou_list = ['å¤§å®‰', 'èµ¤å£', 'å…ˆå‹', 'å‹å¼•', 'å…ˆè² ', 'ä»æ»…']
        rokuyou_idx = (current_date.year + current_date.month + current_date.day) % 6
        covariate_entry['rokuyou'] = rokuyou_idx
        covariate_entry['is_taian'] = 1 if rokuyou_list[rokuyou_idx] == 'å¤§å®‰' else 0
        
        # ç‰¹åˆ¥æœŸé–“ãƒ•ãƒ©ã‚°
        covariate_entry['is_new_year'] = 1 if (current_date.month == 1 and current_date.day <= 7) else 0
        covariate_entry['is_obon'] = 1 if (current_date.month == 8 and 13 <= current_date.day <= 16) else 0
        covariate_entry['is_shichigosan'] = 1 if (current_date.month == 11 and 10 <= current_date.day <= 20) else 0
        covariate_entry['is_golden_week'] = 1 if (current_date.month == 5 and 3 <= current_date.day <= 5) else 0
        
        covariates['future_covariates'].append(covariate_entry)
        current_date += timedelta(days=1)
    
    return covariates


# =============================================================================
# äºˆæ¸¬é–¢æ•°ï¼ˆVertex AI + ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
# =============================================================================

def get_vertex_ai_prediction(
    df: pd.DataFrame,
    periods: int,
    product_id: str = "default",
    use_covariates: bool = True
) -> Tuple[pd.DataFrame, bool, str]:
    """
    Vertex AI AutoML Forecastingã«ã‚ˆã‚‹äºˆæ¸¬ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ãï¼‰
    
    Args:
        df: å£²ä¸Šãƒ‡ãƒ¼ã‚¿ï¼ˆdate, è²©å£²å•†å“æ•°ï¼‰
        periods: äºˆæ¸¬æ—¥æ•°
        product_id: å•†å“è­˜åˆ¥å­
        use_covariates: å…±å¤‰é‡ã‚’ä½¿ç”¨ã™ã‚‹ã‹
    
    Returns:
        äºˆæ¸¬DataFrame, Vertex AIä½¿ç”¨ãƒ•ãƒ©ã‚°, ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    """
    forecaster = get_vertex_ai_forecaster()
    
    if forecaster is None:
        # Vertex AIãŒåˆ©ç”¨ä¸å¯ã®å ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        return forecast_with_seasonality_fallback(df, periods), False, "Vertex AIæœªè¨­å®šã®ãŸã‚ã€çµ±è¨ˆãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬"
    
    try:
        # å…±å¤‰é‡ã®æº–å‚™
        covariates = None
        if use_covariates:
            last_date = pd.to_datetime(df['date']).max()
            start_date = (last_date + timedelta(days=1)).date()
            end_date = (last_date + timedelta(days=periods)).date()
            covariates = generate_covariates(start_date, end_date)
        
        # Vertex AIäºˆæ¸¬
        predictions, metadata = forecaster.predict(
            historical_data=df,
            forecast_horizon=periods,
            product_id=product_id,
            covariates=covariates
        )
        
        return predictions, True, f"Vertex AI AutoML Forecasting (ãƒ¢ãƒ‡ãƒ«: {metadata.get('deployed_model_id', 'N/A')})"
        
    except RuntimeError as e:
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        logger.warning(f"Vertex AIäºˆæ¸¬å¤±æ•—ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ: {e}")
        return forecast_with_seasonality_fallback(df, periods), False, f"Vertex AIã‚¨ãƒ©ãƒ¼: {str(e)[:100]}... çµ±è¨ˆãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬"
    except Exception as e:
        logger.error(f"äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
        return forecast_with_seasonality_fallback(df, periods), False, f"ã‚¨ãƒ©ãƒ¼: {str(e)[:100]}... çµ±è¨ˆãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬"


def forecast_with_seasonality_fallback(df: pd.DataFrame, periods: int) -> pd.DataFrame:
    """
    ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®å­£ç¯€æ€§è€ƒæ…®äºˆæ¸¬ï¼ˆçµ±è¨ˆãƒ™ãƒ¼ã‚¹ï¼‰
    
    Vertex AIãŒåˆ©ç”¨ã§ããªã„å ´åˆã«ä½¿ç”¨
    
    â˜…v19æ”¹å–„: ä¸­å¤®å€¤ãƒ™ãƒ¼ã‚¹ã®é ‘å¥ãªäºˆæ¸¬
    """
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'])
    df = df.sort_values('date')
    
    overall_mean = df['è²©å£²å•†å“æ•°'].mean()
    
    if pd.isna(overall_mean) or overall_mean == 0:
        overall_mean = 1
    
    # æ›œæ—¥ä¿‚æ•°
    df['weekday'] = df['date'].dt.dayofweek
    weekday_means = df.groupby('weekday')['è²©å£²å•†å“æ•°'].mean()
    weekday_factor = {}
    for wd in range(7):
        if wd in weekday_means.index and weekday_means[wd] > 0:
            weekday_factor[wd] = weekday_means[wd] / overall_mean
        else:
            weekday_factor[wd] = 1.0
    
    # æœˆä¿‚æ•°
    df['month'] = df['date'].dt.month
    month_means = df.groupby('month')['è²©å£²å•†å“æ•°'].mean()
    month_factor = {}
    for m in range(1, 13):
        if m in month_means.index and month_means[m] > 0:
            month_factor[m] = month_means[m] / overall_mean
        else:
            month_factor[m] = 1.0
    
    # äºˆæ¸¬
    last_date = df['date'].max()
    future_dates = pd.date_range(start=last_date + timedelta(days=1), periods=periods, freq='D')
    
    predictions = []
    for d in future_dates:
        weekday_f = weekday_factor.get(d.dayofweek, 1.0)
        month_f = month_factor.get(d.month, 1.0)
        
        # ç‰¹åˆ¥æœŸé–“ã®èª¿æ•´
        special_factor = 1.0
        if d.month == 1 and d.day <= 7:  # æ­£æœˆ
            special_factor = 3.0
        elif d.month == 8 and 13 <= d.day <= 16:  # ãŠç›†
            special_factor = 1.5
        elif d.month == 11 and 10 <= d.day <= 20:  # ä¸ƒäº”ä¸‰
            special_factor = 1.3
        
        pred = overall_mean * weekday_f * month_f * special_factor
        pred = max(0.1, pred)
        
        predictions.append({
            'date': d,
            'predicted': round(pred)
        })
    
    return pd.DataFrame(predictions)


# =============================================================================
# ã€v19æ–°æ©Ÿèƒ½ã€‘äºˆæ¸¬ç²¾åº¦å¼·åŒ–ã®ãŸã‚ã®çµ±è¨ˆé–¢æ•°ç¾¤
# =============================================================================

def calculate_robust_baseline(values: np.ndarray, method: str = 'median') -> float:
    """
    å¤–ã‚Œå€¤ã«å¼·ã„ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³è¨ˆç®—
    
    Args:
        values: è²©å£²æ•°ã®é…åˆ—
        method: è¨ˆç®—æ–¹æ³• ('median', 'trimmed_mean', 'iqr_mean')
    
    Returns:
        é ‘å¥ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å€¤
    """
    if len(values) == 0:
        return 1.0
    
    values = np.array(values, dtype=float)
    values = values[~np.isnan(values)]
    
    if len(values) == 0:
        return 1.0
    
    if method == 'median':
        # ä¸­å¤®å€¤ï¼ˆå¤–ã‚Œå€¤ã«æœ€ã‚‚å¼·ã„ï¼‰
        return float(np.median(values))
    
    elif method == 'trimmed_mean':
        # ãƒˆãƒªãƒ å¹³å‡ï¼ˆä¸Šä¸‹10%ã‚’é™¤å¤–ï¼‰
        if SCIPY_AVAILABLE:
            try:
                return float(stats.trim_mean(values, proportiontocut=0.1))
            except:
                pass
        # scipyãŒãªã„å ´åˆã®ä»£æ›¿å®Ÿè£…
        sorted_vals = np.sort(values)
        n = len(sorted_vals)
        trim_count = int(n * 0.1)
        if trim_count > 0 and n > trim_count * 2:
            trimmed = sorted_vals[trim_count:-trim_count]
            return float(np.mean(trimmed))
        return float(np.median(values))
    
    elif method == 'iqr_mean':
        # IQRå†…ã®å€¤ã®ã¿ã§å¹³å‡ï¼ˆå››åˆ†ä½ç¯„å›²å†…ï¼‰
        q1 = np.percentile(values, 25)
        q3 = np.percentile(values, 75)
        iqr = q3 - q1
        lower_bound = q1 - 1.5 * iqr
        upper_bound = q3 + 1.5 * iqr
        filtered = values[(values >= lower_bound) & (values <= upper_bound)]
        if len(filtered) > 0:
            return float(np.mean(filtered))
        return float(np.median(values))
    
    else:
        return float(np.mean(values))


def calculate_robust_factor(group_values: np.ndarray, overall_baseline: float, 
                           min_samples: int = 5) -> float:
    """
    é ‘å¥ãªä¿‚æ•°è¨ˆç®—ï¼ˆã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°‘ãªã„å ´åˆã¯1.0ã«ç¸®é€€ï¼‰
    
    Args:
        group_values: ã‚°ãƒ«ãƒ¼ãƒ—ã®å€¤
        overall_baseline: å…¨ä½“ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³
        min_samples: æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°
    
    Returns:
        ä¿‚æ•°ï¼ˆ1.0ã«è¿‘ã¥ãã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ä»˜ãï¼‰
    """
    if len(group_values) < min_samples or overall_baseline <= 0:
        return 1.0
    
    # ä¸­å¤®å€¤ãƒ™ãƒ¼ã‚¹ã§ä¿‚æ•°ã‚’è¨ˆç®—
    group_median = np.median(group_values)
    raw_factor = group_median / overall_baseline if overall_baseline > 0 else 1.0
    
    # ã‚µãƒ³ãƒ—ãƒ«æ•°ã«å¿œã˜ã¦ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ï¼ˆå°‘ãªã„ã»ã©1.0ã«è¿‘ã¥ã‘ã‚‹ï¼‰
    confidence = min(1.0, len(group_values) / (min_samples * 2))
    smoothed_factor = confidence * raw_factor + (1 - confidence) * 1.0
    
    # æ¥µç«¯ãªå€¤ã‚’æŠ‘åˆ¶ï¼ˆ0.3ã€œ3.0ã®ç¯„å›²ã«åã‚ã‚‹ï¼‰
    return float(max(0.3, min(3.0, smoothed_factor)))


def identify_special_periods(df: pd.DataFrame) -> Dict[str, List[date]]:
    """
    ç‰¹åˆ¥æœŸé–“ï¼ˆæ­£æœˆã€ãŠç›†ã€ä¸ƒäº”ä¸‰ç­‰ï¼‰ã®æ—¥ä»˜ã‚’ç‰¹å®š
    
    Args:
        df: æ—¥ä»˜ã‚’å«ã‚€DataFrame
    
    Returns:
        ç‰¹åˆ¥æœŸé–“åã‚’ã‚­ãƒ¼ã€æ—¥ä»˜ãƒªã‚¹ãƒˆã‚’å€¤ã¨ã™ã‚‹è¾æ›¸
    """
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'])
    
    special_periods = {
        'new_year': [],     # æ­£æœˆï¼ˆ1/1ã€œ1/7ï¼‰
        'obon': [],         # ãŠç›†ï¼ˆ8/13ã€œ8/16ï¼‰
        'shichigosan': [],  # ä¸ƒäº”ä¸‰ï¼ˆ11/10ã€œ11/20ï¼‰
        'golden_week': [],  # ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚¦ã‚£ãƒ¼ã‚¯ï¼ˆ5/3ã€œ5/5ï¼‰
        'year_end': [],     # å¹´æœ«ï¼ˆ12/28ã€œ12/31ï¼‰
    }
    
    for d in df['date'].unique():
        d = pd.Timestamp(d)
        if d.month == 1 and d.day <= 7:
            special_periods['new_year'].append(d.date())
        elif d.month == 8 and 13 <= d.day <= 16:
            special_periods['obon'].append(d.date())
        elif d.month == 11 and 10 <= d.day <= 20:
            special_periods['shichigosan'].append(d.date())
        elif d.month == 5 and 3 <= d.day <= 5:
            special_periods['golden_week'].append(d.date())
        elif d.month == 12 and d.day >= 28:
            special_periods['year_end'].append(d.date())
    
    return special_periods


def calculate_special_period_factors(df: pd.DataFrame, overall_baseline: float,
                                     auto_calculate: bool = True) -> Dict[str, float]:
    """
    ç‰¹åˆ¥æœŸé–“ã®ä¿‚æ•°ã‚’è¨ˆç®—ï¼ˆéå»ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è‡ªå‹•ç®—å‡º or å›ºå®šå€¤ï¼‰
    
    Args:
        df: å£²ä¸Šãƒ‡ãƒ¼ã‚¿
        overall_baseline: å…¨ä½“ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³
        auto_calculate: Trueãªã‚‰éå»ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¨ˆç®—ã€Falseãªã‚‰å›ºå®šå€¤
    
    Returns:
        ç‰¹åˆ¥æœŸé–“åã‚’ã‚­ãƒ¼ã€ä¿‚æ•°ã‚’å€¤ã¨ã™ã‚‹è¾æ›¸
    """
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆå›ºå®šï¼‰ä¿‚æ•°
    default_factors = {
        'new_year': 3.0,      # æ­£æœˆ
        'obon': 1.5,          # ãŠç›†
        'shichigosan': 1.3,   # ä¸ƒäº”ä¸‰
        'golden_week': 1.3,   # ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚¦ã‚£ãƒ¼ã‚¯
        'year_end': 1.5,      # å¹´æœ«
        'normal': 1.0         # é€šå¸¸æ—¥
    }
    
    if not auto_calculate or overall_baseline <= 0:
        return default_factors
    
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'])
    
    # ç‰¹åˆ¥æœŸé–“ãƒ•ãƒ©ã‚°ã‚’ä»˜ä¸
    def get_period_type(d):
        if d.month == 1 and d.day <= 7:
            return 'new_year'
        elif d.month == 8 and 13 <= d.day <= 16:
            return 'obon'
        elif d.month == 11 and 10 <= d.day <= 20:
            return 'shichigosan'
        elif d.month == 5 and 3 <= d.day <= 5:
            return 'golden_week'
        elif d.month == 12 and d.day >= 28:
            return 'year_end'
        return 'normal'
    
    df['period_type'] = df['date'].apply(get_period_type)
    
    # å„æœŸé–“ã®ä¿‚æ•°ã‚’è¨ˆç®—
    calculated_factors = {}
    for period_name in default_factors.keys():
        period_data = df[df['period_type'] == period_name]['è²©å£²å•†å“æ•°'].values
        
        if len(period_data) >= 3:  # æœ€ä½3ã‚µãƒ³ãƒ—ãƒ«å¿…è¦
            period_median = np.median(period_data)
            factor = period_median / overall_baseline if overall_baseline > 0 else 1.0
            # æ¥µç«¯ãªå€¤ã‚’æŠ‘åˆ¶ï¼ˆ0.5ã€œ5.0ã®ç¯„å›²ï¼‰
            factor = max(0.5, min(5.0, factor))
            calculated_factors[period_name] = float(factor)
        else:
            # ã‚µãƒ³ãƒ—ãƒ«ä¸è¶³æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨
            calculated_factors[period_name] = default_factors[period_name]
    
    return calculated_factors


def calculate_prediction_quantiles(predictions: np.ndarray, residuals: np.ndarray,
                                   quantiles: List[float] = [0.5, 0.8, 0.9]) -> Dict[str, np.ndarray]:
    """
    äºˆæ¸¬ã®åˆ†ä½ç‚¹ã‚’è¨ˆç®—
    
    Args:
        predictions: ç‚¹äºˆæ¸¬å€¤ã®é…åˆ—
        residuals: éå»ã®æ®‹å·®ï¼ˆå®Ÿç¸¾-äºˆæ¸¬ï¼‰
        quantiles: è¨ˆç®—ã™ã‚‹åˆ†ä½ç‚¹ã®ãƒªã‚¹ãƒˆ
    
    Returns:
        åˆ†ä½ç‚¹åã‚’ã‚­ãƒ¼ã€äºˆæ¸¬å€¤é…åˆ—ã‚’å€¤ã¨ã™ã‚‹è¾æ›¸
    """
    result = {'predicted': predictions}
    
    if len(residuals) < 5:
        # æ®‹å·®ãƒ‡ãƒ¼ã‚¿ä¸è¶³æ™‚ã¯ç‚¹äºˆæ¸¬ã«åŸºã¥ãç°¡æ˜“è¨ˆç®—
        std_estimate = np.std(predictions) * 0.2  # äºˆæ¸¬å€¤ã®20%ã‚’æ¨™æº–åå·®ã¨ä»®å®š
        
        # æ­£è¦åˆ†å¸ƒã®åˆ†ä½ç‚¹ã‚’è¨ˆç®—ï¼ˆscipyãŒãªã„å ´åˆã®ä»£æ›¿ï¼‰
        # Zå€¤ã®è¿‘ä¼¼: P50=0, P80â‰ˆ0.84, P90â‰ˆ1.28
        z_values = {0.5: 0.0, 0.8: 0.84, 0.9: 1.28}
        
        for q in quantiles:
            if SCIPY_AVAILABLE:
                z_score = stats.norm.ppf(q)
            else:
                z_score = z_values.get(q, 0.0)
            result[f'p{int(q*100)}'] = predictions + z_score * std_estimate
    else:
        # æ®‹å·®ã®åˆ†å¸ƒã‹ã‚‰åˆ†ä½ç‚¹ã‚’è¨ˆç®—
        residual_quantiles = {q: np.percentile(residuals, q * 100) for q in quantiles}
        for q in quantiles:
            result[f'p{int(q*100)}'] = predictions + residual_quantiles[q]
    
    # è² ã®å€¤ã‚’0ã«è£œæ­£
    for key in result:
        result[key] = np.maximum(0, result[key])
    
    return result


def run_simple_backtest(df: pd.DataFrame, holdout_days: int = 14,
                       forecast_func=None) -> Dict[str, Any]:
    """
    ç°¡æ˜“ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¦MAPEã‚’è¨ˆç®—
    
    Args:
        df: å£²ä¸Šãƒ‡ãƒ¼ã‚¿
        holdout_days: ãƒ›ãƒ¼ãƒ«ãƒ‰ã‚¢ã‚¦ãƒˆæ—¥æ•°
        forecast_func: äºˆæ¸¬é–¢æ•°ï¼ˆNoneãªã‚‰æ”¹å–„ç‰ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½¿ç”¨ï¼‰
    
    Returns:
        ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœï¼ˆMAPEã€MAEã€è©³ç´°ãƒ‡ãƒ¼ã‚¿ï¼‰
    """
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'])
    df = df.sort_values('date')
    
    if len(df) < holdout_days + 30:  # æœ€ä½30æ—¥ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦
        return {
            'mape': None,
            'mae': None,
            'message': 'ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆä¸å¯',
            'holdout_days': holdout_days,
            'available': False,
            'residuals': []
        }
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²
    train_df = df.iloc[:-holdout_days].copy()
    test_df = df.iloc[-holdout_days:].copy()
    
    # äºˆæ¸¬ã‚’å®Ÿè¡Œï¼ˆbacktest_days=0ã§å†å¸°ã‚’é˜²æ­¢ï¼‰
    if forecast_func is None:
        forecast_result = forecast_with_seasonality_enhanced(
            train_df, holdout_days, 
            baseline_method='median',
            auto_special_factors=True,
            include_quantiles=False,  # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå†…ã§ã¯åˆ†ä½ç‚¹ä¸è¦
            backtest_days=0  # â˜…é‡è¦: å†å¸°ã‚’é˜²æ­¢
        )
    else:
        forecast_result = forecast_func(train_df, holdout_days)
    
    # äºˆæ¸¬ã¨å®Ÿç¸¾ã‚’æ¯”è¼ƒ
    test_df = test_df.reset_index(drop=True)
    forecast_result = forecast_result.reset_index(drop=True)
    
    actual = test_df['è²©å£²å•†å“æ•°'].values
    predicted = forecast_result['predicted'].values[:len(actual)]
    
    # MAPEè¨ˆç®—ï¼ˆ0é™¤ç®—å¯¾ç­–ï¼‰
    non_zero_mask = actual > 0
    if non_zero_mask.sum() > 0:
        mape = np.mean(np.abs(actual[non_zero_mask] - predicted[non_zero_mask]) / actual[non_zero_mask]) * 100
    else:
        mape = None
    
    # MAEè¨ˆç®—
    mae = np.mean(np.abs(actual - predicted))
    
    # æ®‹å·®ã‚’ä¿å­˜ï¼ˆåˆ†ä½ç‚¹è¨ˆç®—ç”¨ï¼‰
    residuals = actual - predicted
    
    return {
        'mape': float(mape) if mape is not None else None,
        'mae': float(mae),
        'residuals': residuals.tolist(),
        'holdout_days': holdout_days,
        'actual': actual.tolist(),
        'predicted': predicted.tolist(),
        'message': f'ç›´è¿‘{holdout_days}æ—¥é–“ã§ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿæ–½',
        'available': True
    }


# =============================================================================
# ã€v20æ–°æ©Ÿèƒ½ã€‘ç²¾åº¦å‘ä¸Šã®ãŸã‚ã®è¿½åŠ æ©Ÿèƒ½ç¾¤
# =============================================================================

def fill_missing_dates(df: pd.DataFrame, fill_value: int = 0) -> Tuple[pd.DataFrame, List[date]]:
    """
    ã€v20æ–°æ©Ÿèƒ½ã€‘æ—¥ä»˜ã®æ¬ æã‚’0ã§åŸ‹ã‚ã‚‹ï¼ˆ0åŸ‹ã‚å‡¦ç†ï¼‰
    
    Airãƒ¬ã‚¸ã§ã¯å£²ä¸ŠãŒãªã„æ—¥ã¯æ—¥ä»˜ãŒæŠœã‘ã‚‹ãŸã‚ã€
    å…¨æ—¥ä»˜ã‚’åŸ‹ã‚ã¦æ­£ç¢ºãªæ›œæ—¥ãƒ»å­£ç¯€ä¿‚æ•°ã‚’è¨ˆç®—ã™ã‚‹ã€‚
    
    Args:
        df: å£²ä¸Šãƒ‡ãƒ¼ã‚¿ï¼ˆdate, è²©å£²å•†å“æ•°ã‚’å«ã‚€ï¼‰
        fill_value: æ¬ ææ—¥ã«åŸ‹ã‚ã‚‹å€¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ0ï¼‰
    
    Returns:
        (0åŸ‹ã‚å¾Œã®DataFrame, åŸ‹ã‚ãŸæ—¥ä»˜ã®ãƒªã‚¹ãƒˆ)
    """
    if df is None or df.empty:
        return df, []
    
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'])
    
    # æ—¥ä»˜ã®ç¯„å›²ã‚’å–å¾—
    min_date = df['date'].min()
    max_date = df['date'].max()
    
    # å…¨æ—¥ä»˜ã®é€£ç¶šã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ä½œæˆ
    all_dates = pd.date_range(start=min_date, end=max_date, freq='D')
    
    # å…ƒãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã™ã‚‹æ—¥ä»˜
    existing_dates = set(df['date'].dt.date)
    
    # æ¬ ææ—¥ã‚’ç‰¹å®š
    missing_dates = [d.date() for d in all_dates if d.date() not in existing_dates]
    
    if not missing_dates:
        return df, []
    
    # æ¬ ææ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
    missing_data = []
    for d in missing_dates:
        missing_data.append({
            'date': pd.Timestamp(d),
            'è²©å£²å•†å“æ•°': fill_value
        })
    
    missing_df = pd.DataFrame(missing_data)
    
    # å…ƒãƒ‡ãƒ¼ã‚¿ã¨çµåˆ
    filled_df = pd.concat([df, missing_df], ignore_index=True)
    filled_df = filled_df.sort_values('date').reset_index(drop=True)
    
    logger.info(f"0åŸ‹ã‚å‡¦ç†: {len(missing_dates)}æ—¥åˆ†ã®æ¬ æã‚’è£œå®Œã—ã¾ã—ãŸ")
    
    return filled_df, missing_dates


def exclude_stockout_periods(df: pd.DataFrame, stockout_periods: List[Tuple[date, date]]) -> pd.DataFrame:
    """
    ã€v20æ–°æ©Ÿèƒ½ã€‘æ¬ å“æœŸé–“ã‚’å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é™¤å¤–
    
    æ¬ å“ï¼ˆåœ¨åº«åˆ‡ã‚Œï¼‰æœŸé–“ã¯ã€Œéœ€è¦ãŒãªã‹ã£ãŸã€ã®ã§ã¯ãªãã€Œä¾›çµ¦ã§ããªã‹ã£ãŸã€ãŸã‚ã€
    å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é™¤å¤–ã—ã¦æ­£ç¢ºãªéœ€è¦ã‚’æ¨å®šã™ã‚‹ã€‚
    
    Args:
        df: å£²ä¸Šãƒ‡ãƒ¼ã‚¿
        stockout_periods: æ¬ å“æœŸé–“ã®ãƒªã‚¹ãƒˆ [(é–‹å§‹æ—¥, çµ‚äº†æ—¥), ...]
    
    Returns:
        æ¬ å“æœŸé–“ã‚’é™¤å¤–ã—ãŸDataFrameï¼ˆé™¤å¤–è¡Œã¯NaNæ‰±ã„ï¼‰
    """
    if not stockout_periods:
        return df
    
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'])
    
    # æ¬ å“ãƒ•ãƒ©ã‚°ã‚’åˆæœŸåŒ–
    df['is_stockout'] = False
    
    for start_date, end_date in stockout_periods:
        start_ts = pd.Timestamp(start_date)
        end_ts = pd.Timestamp(end_date)
        
        mask = (df['date'] >= start_ts) & (df['date'] <= end_ts)
        df.loc[mask, 'is_stockout'] = True
    
    # æ¬ å“æ—¥ã®è²©å£²æ•°ã‚’NaNã«ï¼ˆå­¦ç¿’ã‹ã‚‰é™¤å¤–ï¼‰
    excluded_count = df['is_stockout'].sum()
    df.loc[df['is_stockout'], 'è²©å£²å•†å“æ•°'] = np.nan
    
    if excluded_count > 0:
        logger.info(f"æ¬ å“æœŸé–“é™¤å¤–: {excluded_count}æ—¥åˆ†ã‚’å­¦ç¿’å¯¾è±¡å¤–ã«ã—ã¾ã—ãŸ")
    
    return df


def calculate_trend_factor(df: pd.DataFrame, comparison_window_days: int = 60) -> Tuple[float, Dict[str, Any]]:
    """
    ã€v20æ–°æ©Ÿèƒ½ã€‘ãƒˆãƒ¬ãƒ³ãƒ‰ä¿‚æ•°ã®è¨ˆç®—ï¼ˆå‰å¹´åŒæœŸæ¯”ï¼‰
    
    ç›´è¿‘ã®å£²ä¸Šå‚¾å‘ã¨å‰å¹´åŒæœŸã‚’æ¯”è¼ƒã—ã€æˆé•·ç‡ã‚’ç®—å‡ºã™ã‚‹ã€‚
    ã“ã‚Œã«ã‚ˆã‚Šã€å¹´ã€…ã®å¢—æ¸›ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’äºˆæ¸¬ã«åæ˜ ã§ãã‚‹ã€‚
    
    Args:
        df: å£²ä¸Šãƒ‡ãƒ¼ã‚¿
        comparison_window_days: æ¯”è¼ƒæœŸé–“ï¼ˆæ—¥æ•°ï¼‰
    
    Returns:
        (ãƒˆãƒ¬ãƒ³ãƒ‰ä¿‚æ•°, è©³ç´°æƒ…å ±ã®è¾æ›¸)
    """
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'])
    df = df.sort_values('date')
    
    # NaNï¼ˆæ¬ å“æ—¥ï¼‰ã‚’é™¤å¤–ã—ã¦è¨ˆç®—
    df_valid = df.dropna(subset=['è²©å£²å•†å“æ•°'])
    
    # ãƒ‡ãƒ¼ã‚¿ãŒ1å¹´+æ¯”è¼ƒæœŸé–“æœªæº€ã®å ´åˆã¯ãƒˆãƒ¬ãƒ³ãƒ‰ãªã—
    if len(df_valid) < 365 + comparison_window_days:
        return 1.0, {
            'available': False,
            'message': 'ãƒ‡ãƒ¼ã‚¿ä¸è¶³ï¼ˆ1å¹´ä»¥ä¸Šå¿…è¦ï¼‰',
            'trend_factor': 1.0,
            'current_mean': None,
            'last_year_mean': None
        }
    
    last_date = df_valid['date'].max()
    
    # ç›´è¿‘Næ—¥é–“
    current_period_start = last_date - pd.Timedelta(days=comparison_window_days)
    current_vals = df_valid[df_valid['date'] > current_period_start]['è²©å£²å•†å“æ•°']
    
    # å‰å¹´åŒæœŸé–“
    last_year_end = last_date - pd.Timedelta(days=365)
    last_year_start = last_year_end - pd.Timedelta(days=comparison_window_days)
    last_year_vals = df_valid[
        (df_valid['date'] > last_year_start) & 
        (df_valid['date'] <= last_year_end)
    ]['è²©å£²å•†å“æ•°']
    
    if len(current_vals) < 10 or len(last_year_vals) < 10:
        return 1.0, {
            'available': False,
            'message': 'æ¯”è¼ƒæœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ä¸è¶³',
            'trend_factor': 1.0,
            'current_mean': None,
            'last_year_mean': None
        }
    
    current_mean = float(current_vals.mean())
    last_year_mean = float(last_year_vals.mean())
    
    if last_year_mean <= 0:
        return 1.0, {
            'available': False,
            'message': 'å‰å¹´åŒæœŸã®å£²ä¸ŠãŒ0',
            'trend_factor': 1.0,
            'current_mean': current_mean,
            'last_year_mean': 0
        }
    
    # ãƒˆãƒ¬ãƒ³ãƒ‰ä¿‚æ•°ï¼ˆ0.7ã€œ1.5ã«ã‚¯ãƒªãƒƒãƒ—ã—ã¦æ¥µç«¯ãªå¤‰å‹•ã‚’æŠ‘åˆ¶ï¼‰
    raw_trend = current_mean / last_year_mean
    trend_factor = max(0.7, min(1.5, raw_trend))
    
    # å¤‰åŒ–ç‡ï¼ˆ%ï¼‰
    change_rate = (trend_factor - 1.0) * 100
    
    return trend_factor, {
        'available': True,
        'message': f'å‰å¹´æ¯” {trend_factor:.1%}ï¼ˆ{change_rate:+.1f}%ï¼‰',
        'trend_factor': trend_factor,
        'raw_trend': raw_trend,
        'current_mean': current_mean,
        'last_year_mean': last_year_mean,
        'comparison_window_days': comparison_window_days
    }


def get_period_type_v2(d: pd.Timestamp) -> str:
    """
    ã€v20æ–°æ©Ÿèƒ½ã€‘ç‰¹åˆ¥æœŸé–“ã®åˆ¤å®šï¼ˆæ­£æœˆã¯æ—¥åˆ¥ï¼‰
    
    æ­£æœˆï¼ˆ1/1ã€œ1/7ï¼‰ã¯æ—¥ã«ã‚ˆã£ã¦éœ€è¦ãŒå¤§ããç•°ãªã‚‹ãŸã‚ã€
    æ—¥åˆ¥ã«ä¿‚æ•°ã‚’æŒã¤ã€‚
    
    Args:
        d: æ—¥ä»˜
    
    Returns:
        ç‰¹åˆ¥æœŸé–“ã‚¿ã‚¤ãƒ—ï¼ˆ'new_year_d1'ã€œ'new_year_d7'ã€'obon'ã€'normal'ãªã©ï¼‰
    """
    d = pd.Timestamp(d)
    
    # æ­£æœˆã¯æ—¥åˆ¥ï¼ˆ1/1ã€œ1/7ï¼‰
    if d.month == 1 and 1 <= d.day <= 7:
        return f'new_year_d{d.day}'
    
    # ãŠç›†ï¼ˆ8/13ã€œ8/16ï¼‰
    elif d.month == 8 and 13 <= d.day <= 16:
        return 'obon'
    
    # ä¸ƒäº”ä¸‰ï¼ˆ11/10ã€œ11/20ï¼‰
    elif d.month == 11 and 10 <= d.day <= 20:
        return 'shichigosan'
    
    # ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚¦ã‚£ãƒ¼ã‚¯ï¼ˆ5/3ã€œ5/5ï¼‰
    elif d.month == 5 and 3 <= d.day <= 5:
        return 'golden_week'
    
    # å¹´æœ«ï¼ˆ12/28ã€œ12/31ï¼‰
    elif d.month == 12 and d.day >= 28:
        return 'year_end'
    
    return 'normal'


def calculate_special_period_factors_v2(
    df: pd.DataFrame, 
    overall_baseline: float,
    auto_calculate: bool = True
) -> Dict[str, float]:
    """
    ã€v20æ–°æ©Ÿèƒ½ã€‘ç‰¹åˆ¥æœŸé–“ä¿‚æ•°ã®è¨ˆç®—ï¼ˆæ­£æœˆæ—¥åˆ¥å¯¾å¿œç‰ˆï¼‰
    
    æ­£æœˆï¼ˆ1/1ã€œ1/7ï¼‰ã‚’æ—¥åˆ¥ã«åˆ†ã‘ã¦ä¿‚æ•°ã‚’è¨ˆç®—ã™ã‚‹ã“ã¨ã§ã€
    å…ƒæ—¥ã®ãƒ”ãƒ¼ã‚¯ã‹ã‚‰å¾ã€…ã«ä¸‹ãŒã‚‹éœ€è¦ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ‰ãˆã‚‹ã€‚
    
    Args:
        df: å£²ä¸Šãƒ‡ãƒ¼ã‚¿
        overall_baseline: å…¨ä½“ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³
        auto_calculate: è‡ªå‹•è¨ˆç®—ã™ã‚‹ã‹
    
    Returns:
        ç‰¹åˆ¥æœŸé–“ä¿‚æ•°ã®è¾æ›¸ï¼ˆæ­£æœˆã¯æ—¥åˆ¥ï¼‰
    """
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä¿‚æ•°ï¼ˆæ­£æœˆã¯æ—¥åˆ¥ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
    default_factors = {
        'new_year_d1': 5.0,   # å…ƒæ—¥ï¼ˆãƒ”ãƒ¼ã‚¯ï¼‰
        'new_year_d2': 4.5,   # 1/2
        'new_year_d3': 4.0,   # 1/3ï¼ˆä¸‰ãŒæ—¥æœ€çµ‚æ—¥ï¼‰
        'new_year_d4': 2.5,   # 1/4
        'new_year_d5': 2.0,   # 1/5
        'new_year_d6': 1.8,   # 1/6
        'new_year_d7': 1.5,   # 1/7
        'obon': 1.5,          # ãŠç›†
        'shichigosan': 1.3,   # ä¸ƒäº”ä¸‰
        'golden_week': 1.3,   # ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚¦ã‚£ãƒ¼ã‚¯
        'year_end': 1.5,      # å¹´æœ«
        'normal': 1.0         # é€šå¸¸æ—¥
    }
    
    if not auto_calculate or overall_baseline <= 0:
        return default_factors
    
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'])
    
    # NaNï¼ˆæ¬ å“æ—¥ï¼‰ã‚’é™¤å¤–
    df = df.dropna(subset=['è²©å£²å•†å“æ•°'])
    
    # ç‰¹åˆ¥æœŸé–“ãƒ•ãƒ©ã‚°ã‚’ä»˜ä¸ï¼ˆv2ç‰ˆï¼šæ­£æœˆæ—¥åˆ¥ï¼‰
    df['period_type'] = df['date'].apply(get_period_type_v2)
    
    # å„æœŸé–“ã®ä¿‚æ•°ã‚’è¨ˆç®—
    calculated_factors = {}
    
    for period_name in default_factors.keys():
        period_data = df[df['period_type'] == period_name]['è²©å£²å•†å“æ•°'].values
        
        # æ­£æœˆã®æ—¥åˆ¥ã¯1ã‚µãƒ³ãƒ—ãƒ«ä»¥ä¸Šã‚ã‚Œã°è¨ˆç®—ï¼ˆå¹´æ•°åˆ†ã—ã‹ãªã„ï¼‰
        min_samples = 1 if period_name.startswith('new_year_d') else 3
        
        if len(period_data) >= min_samples:
            period_median = np.median(period_data)
            factor = period_median / overall_baseline if overall_baseline > 0 else 1.0
            
            # æ¥µç«¯ãªå€¤ã‚’æŠ‘åˆ¶ï¼ˆ0.5ã€œ8.0ã®ç¯„å›²ã€æ­£æœˆã¯ä¸Šé™ã‚’é«˜ãï¼‰
            max_factor = 8.0 if period_name.startswith('new_year') else 5.0
            factor = max(0.5, min(max_factor, factor))
            calculated_factors[period_name] = float(factor)
        else:
            # ã‚µãƒ³ãƒ—ãƒ«ä¸è¶³æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨
            calculated_factors[period_name] = default_factors[period_name]
    
    return calculated_factors


def calculate_reorder_point(
    prediction_df: pd.DataFrame,
    residuals: List[float],
    lead_time_days: int = 14,
    service_level: float = 0.95
) -> Dict[str, Any]:
    """
    ã€v20æ–°æ©Ÿèƒ½ã€‘ç™ºæ³¨ç‚¹ï¼ˆãƒªã‚ªãƒ¼ãƒ€ãƒ¼ãƒã‚¤ãƒ³ãƒˆï¼‰ã¨å®‰å…¨åœ¨åº«ã®è¨ˆç®—
    
    ç™ºæ³¨ç‚¹ = ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ä¸­ã®äºˆæ¸¬éœ€è¦ + å®‰å…¨åœ¨åº«
    å®‰å…¨åœ¨åº« = å®‰å…¨ä¿‚æ•°(Z) Ã— RMSE Ã— âˆšãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ 
    
    Args:
        prediction_df: äºˆæ¸¬çµæœã®DataFrame
        residuals: ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã®æ®‹å·®ãƒªã‚¹ãƒˆ
        lead_time_days: ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ï¼ˆç™ºæ³¨ã‹ã‚‰ç´å“ã¾ã§ã®æ—¥æ•°ï¼‰
        service_level: ã‚µãƒ¼ãƒ“ã‚¹ãƒ¬ãƒ™ãƒ«ï¼ˆ0.90, 0.95, 0.99ï¼‰
    
    Returns:
        ç™ºæ³¨ç‚¹è¨ˆç®—çµæœã®è¾æ›¸
    """
    # ã‚µãƒ¼ãƒ“ã‚¹ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸå®‰å…¨ä¿‚æ•°ï¼ˆZå€¤ï¼‰
    z_scores = {
        0.90: 1.28,   # 90%ã‚µãƒ¼ãƒ“ã‚¹ãƒ¬ãƒ™ãƒ«
        0.95: 1.65,   # 95%ã‚µãƒ¼ãƒ“ã‚¹ãƒ¬ãƒ™ãƒ«ï¼ˆæ¨å¥¨ï¼‰
        0.99: 2.33    # 99%ã‚µãƒ¼ãƒ“ã‚¹ãƒ¬ãƒ™ãƒ«
    }
    z = z_scores.get(service_level, 1.65)
    
    # ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ æœŸé–“ã®äºˆæ¸¬éœ€è¦åˆè¨ˆ
    if len(prediction_df) < lead_time_days:
        lead_time_demand = prediction_df['predicted'].sum()
        actual_days = len(prediction_df)
    else:
        lead_time_demand = prediction_df.iloc[:lead_time_days]['predicted'].sum()
        actual_days = lead_time_days
    
    # äºˆæ¸¬èª¤å·®ï¼ˆRMSEï¼‰ã®è¨ˆç®—
    if not residuals or len(residuals) < 7:
        # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯äºˆæ¸¬ã®20%ã‚’èª¤å·®ã¨ä»®å®š
        daily_demand = lead_time_demand / actual_days if actual_days > 0 else 1
        rmse = daily_demand * 0.2
        rmse_source = 'estimated'
    else:
        residuals_array = np.array(residuals)
        rmse = float(np.sqrt(np.mean(residuals_array ** 2)))
        rmse_source = 'calculated'
    
    # å®‰å…¨åœ¨åº«
    safety_stock = z * rmse * np.sqrt(actual_days)
    
    # ç™ºæ³¨ç‚¹
    reorder_point = lead_time_demand + safety_stock
    
    # æ—¥åˆ¥äºˆæ¸¬å¹³å‡
    daily_avg = lead_time_demand / actual_days if actual_days > 0 else 0
    
    return {
        'lead_time_days': actual_days,
        'lead_time_demand': int(round(lead_time_demand)),
        'safety_stock': int(round(safety_stock)),
        'reorder_point': int(round(reorder_point)),
        'service_level': service_level,
        'service_level_pct': f'{service_level*100:.0f}%',
        'z_score': z,
        'rmse': float(rmse),
        'rmse_source': rmse_source,
        'daily_avg': float(daily_avg),
        'message': (
            f"ğŸ“¦ ç™ºæ³¨æ¨å¥¨\n"
            f"â”œâ”€ äºˆæ¸¬éœ€è¦ï¼ˆ{actual_days}æ—¥é–“ï¼‰: {int(lead_time_demand):,}å€‹\n"
            f"â”œâ”€ å®‰å…¨åœ¨åº«ï¼ˆ{service_level*100:.0f}%SLï¼‰: +{int(safety_stock):,}å€‹\n"
            f"â””â”€ æ¨å¥¨ç™ºæ³¨ç‚¹: {int(reorder_point):,}å€‹"
        )
    }


def forecast_with_seasonality_enhanced(
    df: pd.DataFrame, 
    periods: int,
    baseline_method: str = 'median',
    auto_special_factors: bool = True,
    include_quantiles: bool = False,
    order_mode: str = 'balanced',
    backtest_days: int = 14,
    # v20æ–°è¦ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆæ—¢å­˜äº’æ›ã®ãŸã‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯False/Noneï¼‰
    enable_zero_fill: bool = True,
    stockout_periods: Optional[List[Tuple[date, date]]] = None,
    enable_trend: bool = True,
    use_daily_new_year: bool = True,
    trend_window_days: int = 60
) -> pd.DataFrame:
    """
    ã€v20ç²¾åº¦å¼·åŒ–ç‰ˆã€‘å­£ç¯€æ€§è€ƒæ…®äºˆæ¸¬ï¼ˆ0åŸ‹ã‚ãƒ»æ¬ å“é™¤å¤–ãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»æ­£æœˆæ—¥åˆ¥å¯¾å¿œï¼‰
    
    v19ã‹ã‚‰ã®è¿½åŠ æ©Ÿèƒ½:
    - 0åŸ‹ã‚å‡¦ç†: å£²ä¸Š0ã®æ—¥ã‚’è‡ªå‹•è£œå®Œã—ã¦æ­£ç¢ºãªä¿‚æ•°è¨ˆç®—
    - æ¬ å“æœŸé–“é™¤å¤–: åœ¨åº«åˆ‡ã‚ŒæœŸé–“ã‚’å­¦ç¿’ã‹ã‚‰é™¤å¤–
    - ãƒˆãƒ¬ãƒ³ãƒ‰ä¿‚æ•°: å‰å¹´åŒæœŸæ¯”ã®æˆé•·ç‡ã‚’åæ˜ 
    - æ­£æœˆæ—¥åˆ¥ä¿‚æ•°: 1/1ã€œ1/7ã‚’æ—¥åˆ¥ã«ä¿‚æ•°è¨­å®šï¼ˆå…ƒæ—¥ãƒ”ãƒ¼ã‚¯å¯¾å¿œï¼‰
    
    Args:
        df: å£²ä¸Šãƒ‡ãƒ¼ã‚¿ï¼ˆdate, è²©å£²å•†å“æ•°ã‚’å«ã‚€ï¼‰
        periods: äºˆæ¸¬æ—¥æ•°
        baseline_method: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³è¨ˆç®—æ–¹æ³• ('median', 'trimmed_mean', 'iqr_mean', 'mean')
        auto_special_factors: ç‰¹åˆ¥æœŸé–“ä¿‚æ•°ã‚’éå»ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è‡ªå‹•è¨ˆç®—ã™ã‚‹ã‹
        include_quantiles: åˆ†ä½ç‚¹äºˆæ¸¬ã‚’å«ã‚ã‚‹ã‹
        order_mode: ç™ºæ³¨ãƒ¢ãƒ¼ãƒ‰ ('conservative'=P50, 'balanced'=P80, 'aggressive'=P90)
        backtest_days: ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæ—¥æ•°ï¼ˆ0ãªã‚‰å®Ÿè¡Œã—ãªã„ï¼‰
        enable_zero_fill: ã€v20ã€‘æ—¥ä»˜æ¬ æã‚’0ã§åŸ‹ã‚ã‚‹ã‹ï¼ˆæ¨å¥¨: Trueï¼‰
        stockout_periods: ã€v20ã€‘æ¬ å“æœŸé–“ã®ãƒªã‚¹ãƒˆ [(é–‹å§‹æ—¥, çµ‚äº†æ—¥), ...]
        enable_trend: ã€v20ã€‘ãƒˆãƒ¬ãƒ³ãƒ‰ä¿‚æ•°ã‚’é©ç”¨ã™ã‚‹ã‹ï¼ˆæ¨å¥¨: Trueï¼‰
        use_daily_new_year: ã€v20ã€‘æ­£æœˆã‚’æ—¥åˆ¥ä¿‚æ•°ã«ã™ã‚‹ã‹ï¼ˆæ¨å¥¨: Trueï¼‰
        trend_window_days: ã€v20ã€‘ãƒˆãƒ¬ãƒ³ãƒ‰è¨ˆç®—ã®æ¯”è¼ƒæœŸé–“ï¼ˆæ—¥æ•°ï¼‰
    
    Returns:
        äºˆæ¸¬çµæœã®DataFrame
    """
    df = df.copy()
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®æ¤œè¨¼
    if df is None or df.empty:
        raise ValueError("å£²ä¸Šãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
    
    if 'date' not in df.columns:
        raise ValueError("'date'åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    if 'è²©å£²å•†å“æ•°' not in df.columns:
        raise ValueError("'è²©å£²å•†å“æ•°'åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    df['date'] = pd.to_datetime(df['date'])
    df = df.sort_values('date')
    
    # ========== v20æ–°æ©Ÿèƒ½1: 0åŸ‹ã‚å‡¦ç† ==========
    missing_dates = []
    if enable_zero_fill:
        df, missing_dates = fill_missing_dates(df, fill_value=0)
    
    # ========== v20æ–°æ©Ÿèƒ½2: æ¬ å“æœŸé–“ã®é™¤å¤– ==========
    if stockout_periods:
        df = exclude_stockout_periods(df, stockout_periods)
    
    # ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã™ãã‚‹å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    # NaNã‚’é™¤å¤–ã—ã¦ã‚«ã‚¦ãƒ³ãƒˆ
    valid_count = df['è²©å£²å•†å“æ•°'].notna().sum()
    if valid_count < 7:
        logger.warning(f"æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã™ãã¾ã™ï¼ˆ{valid_count}ä»¶ï¼‰ã€‚ã‚·ãƒ³ãƒ—ãƒ«ãªäºˆæ¸¬ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™ã€‚")
        # å˜ç´”å¹³å‡ã§äºˆæ¸¬ï¼ˆNaNé™¤å¤–ï¼‰
        avg_value = df['è²©å£²å•†å“æ•°'].dropna().mean() if valid_count > 0 else 1.0
        avg_value = max(1.0, avg_value)
        
        last_date = df['date'].max()
        future_dates = pd.date_range(start=last_date + timedelta(days=1), periods=periods, freq='D')
        
        predictions = [{'date': d, 'predicted': round(avg_value)} for d in future_dates]
        result_df = pd.DataFrame(predictions)
        result_df.attrs['backtest'] = {'mape': None, 'available': False, 'message': 'ãƒ‡ãƒ¼ã‚¿ä¸è¶³'}
        result_df.attrs['v20_features'] = {
            'zero_fill': enable_zero_fill,
            'missing_dates_count': len(missing_dates),
            'stockout_excluded': stockout_periods is not None,
            'trend_applied': False,
            'daily_new_year': use_daily_new_year
        }
        return result_df
    
    # NaNã‚’é™¤å¤–ã—ãŸå€¤ã§è¨ˆç®—
    valid_values = df['è²©å£²å•†å“æ•°'].dropna().values
    
    # ========== 1. é ‘å¥ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³è¨ˆç®— ==========
    overall_baseline = calculate_robust_baseline(valid_values, method=baseline_method)
    
    if overall_baseline <= 0:
        overall_baseline = 1.0
    
    # ========== v20æ–°æ©Ÿèƒ½3: ãƒˆãƒ¬ãƒ³ãƒ‰ä¿‚æ•°ã®è¨ˆç®— ==========
    trend_factor = 1.0
    trend_info = {'available': False, 'trend_factor': 1.0}
    if enable_trend:
        trend_factor, trend_info = calculate_trend_factor(df, comparison_window_days=trend_window_days)
    
    # ========== 2. æ›œæ—¥ãƒ»æœˆåˆ—ã‚’å…ˆã«è¿½åŠ  ==========
    df['weekday'] = df['date'].dt.dayofweek
    df['month'] = df['date'].dt.month
    
    # ========== 3. ç‰¹åˆ¥æœŸé–“ã‚’é™¤å¤–ã—ãŸé€šå¸¸æ—¥ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ ==========
    def is_special_day(d):
        d = pd.Timestamp(d)
        if d.month == 1 and d.day <= 7:  # æ­£æœˆ
            return True
        if d.month == 8 and 13 <= d.day <= 16:  # ãŠç›†
            return True
        if d.month == 11 and 10 <= d.day <= 20:  # ä¸ƒäº”ä¸‰
            return True
        if d.month == 5 and 3 <= d.day <= 5:  # GW
            return True
        if d.month == 12 and d.day >= 28:  # å¹´æœ«
            return True
        return False
    
    df['is_special'] = df['date'].apply(is_special_day)
    # NaNï¼ˆæ¬ å“æ—¥ï¼‰ã¨ç‰¹åˆ¥æœŸé–“ã‚’é™¤å¤–
    normal_df = df[(~df['is_special']) & (df['è²©å£²å•†å“æ•°'].notna())].copy()
    
    if len(normal_df) > 10:
        # é€šå¸¸æ—¥ã®ã¿ã§ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’å†è¨ˆç®—ï¼ˆäºŒé‡è¨ˆä¸Šå¯¾ç­–ï¼‰
        normal_baseline = calculate_robust_baseline(
            normal_df['è²©å£²å•†å“æ•°'].values, 
            method=baseline_method
        )
    else:
        normal_baseline = overall_baseline
    
    # ========== 4. æ›œæ—¥ä¿‚æ•°ï¼ˆé ‘å¥ç‰ˆï¼‰ ==========
    weekday_factor = {}
    
    for wd in range(7):
        wd_values = normal_df[normal_df['weekday'] == wd]['è²©å£²å•†å“æ•°'].values
        weekday_factor[wd] = calculate_robust_factor(wd_values, normal_baseline, min_samples=3)
    
    # ========== 5. æœˆä¿‚æ•°ï¼ˆé ‘å¥ç‰ˆï¼‰ ==========
    month_factor = {}
    
    for m in range(1, 13):
        # é€šå¸¸æ—¥ã®ã¿ã§æœˆä¿‚æ•°ã‚’è¨ˆç®—
        m_values = normal_df[normal_df['month'] == m]['è²©å£²å•†å“æ•°'].values
        month_factor[m] = calculate_robust_factor(m_values, normal_baseline, min_samples=5)
    
    # ========== 6. ç‰¹åˆ¥æœŸé–“ä¿‚æ•°ï¼ˆv20: æ­£æœˆæ—¥åˆ¥å¯¾å¿œï¼‰ ==========
    if use_daily_new_year:
        # v20ç‰ˆ: æ­£æœˆã‚’æ—¥åˆ¥ã«è¨ˆç®—
        special_factors = calculate_special_period_factors_v2(
            df, normal_baseline, auto_calculate=auto_special_factors
        )
    else:
        # å¾“æ¥ç‰ˆ: æ­£æœˆã‚’1ä¿‚æ•°ã§è¨ˆç®—
        special_factors = calculate_special_period_factors(
            df, normal_baseline, auto_calculate=auto_special_factors
        )
    
    # ========== 7. ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆï¼ˆæ®‹å·®å–å¾—ç”¨ï¼‰ ==========
    residuals = np.array([])
    backtest_result = None
    
    # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆç”¨ã«NaNã‚’é™¤å¤–ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
    df_for_backtest = df[df['è²©å£²å•†å“æ•°'].notna()].copy()
    if backtest_days > 0 and len(df_for_backtest) > backtest_days + 30:
        backtest_result = run_simple_backtest(df_for_backtest, backtest_days)
        if backtest_result['available']:
            residuals = np.array(backtest_result['residuals'])
    
    # ========== 8. äºˆæ¸¬ç”Ÿæˆ ==========
    last_date = df['date'].max()
    future_dates = pd.date_range(start=last_date + timedelta(days=1), periods=periods, freq='D')
    
    predictions = []
    point_predictions = []
    
    for d in future_dates:
        weekday_f = weekday_factor.get(d.dayofweek, 1.0)
        month_f = month_factor.get(d.month, 1.0)
        
        # ç‰¹åˆ¥æœŸé–“ã®åˆ¤å®šï¼ˆv20: æ­£æœˆæ—¥åˆ¥å¯¾å¿œï¼‰
        if use_daily_new_year:
            # v20ç‰ˆ: æ­£æœˆã¯æ—¥åˆ¥
            period_type = get_period_type_v2(d)
            special_f = special_factors.get(period_type, special_factors.get('normal', 1.0))
        else:
            # å¾“æ¥ç‰ˆ: æ­£æœˆã¯1ä¿‚æ•°
            special_f = special_factors.get('normal', 1.0)
            if d.month == 1 and d.day <= 7:
                special_f = special_factors.get('new_year', 3.0)
            elif d.month == 8 and 13 <= d.day <= 16:
                special_f = special_factors.get('obon', 1.5)
            elif d.month == 11 and 10 <= d.day <= 20:
                special_f = special_factors.get('shichigosan', 1.3)
            elif d.month == 5 and 3 <= d.day <= 5:
                special_f = special_factors.get('golden_week', 1.3)
            elif d.month == 12 and d.day >= 28:
                special_f = special_factors.get('year_end', 1.5)
        
        # äºˆæ¸¬å€¤è¨ˆç®—ï¼ˆé€šå¸¸æ—¥ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ Ã— æ›œæ—¥ä¿‚æ•° Ã— æœˆä¿‚æ•° Ã— ç‰¹åˆ¥æœŸé–“ä¿‚æ•° Ã— ãƒˆãƒ¬ãƒ³ãƒ‰ä¿‚æ•°ï¼‰
        pred = normal_baseline * weekday_f * month_f * special_f * trend_factor
        pred = max(0.1, pred)
        point_predictions.append(pred)
        
        predictions.append({
            'date': d,
            'predicted': round(pred),
            'weekday_factor': weekday_f,
            'month_factor': month_f,
            'special_factor': special_f,
            'trend_factor': trend_factor  # v20è¿½åŠ 
        })
    
    result_df = pd.DataFrame(predictions)
    
    # ========== 9. åˆ†ä½ç‚¹äºˆæ¸¬ã®è¿½åŠ  ==========
    if include_quantiles:
        point_array = np.array(point_predictions)
        quantile_results = calculate_prediction_quantiles(
            point_array, residuals, quantiles=[0.5, 0.8, 0.9]
        )
        
        result_df['p50'] = quantile_results['p50'].round().astype(int)
        result_df['p80'] = quantile_results['p80'].round().astype(int)
        result_df['p90'] = quantile_results['p90'].round().astype(int)
        
        # ç™ºæ³¨ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ãŸæ¨å¥¨å€¤
        if order_mode == 'conservative':  # æ»ç•™å›é¿
            result_df['recommended'] = result_df['p50']
        elif order_mode == 'aggressive':  # æ¬ å“å›é¿
            result_df['recommended'] = result_df['p90']
        else:  # balanced
            result_df['recommended'] = result_df['p80']
    
    # ========== 10. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ ==========
    # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœ
    if backtest_result is not None:
        result_df.attrs['backtest'] = backtest_result
    else:
        result_df.attrs['backtest'] = {'mape': None, 'available': False, 'message': 'ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæœªå®Ÿè¡Œ'}
    
    result_df.attrs['special_factors'] = special_factors
    result_df.attrs['baseline_method'] = baseline_method
    result_df.attrs['normal_baseline'] = normal_baseline
    
    # v20è¿½åŠ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    result_df.attrs['v20_features'] = {
        'zero_fill': enable_zero_fill,
        'missing_dates_count': len(missing_dates),
        'stockout_excluded': stockout_periods is not None,
        'stockout_periods_count': len(stockout_periods) if stockout_periods else 0,
        'trend_applied': enable_trend and trend_info['available'],
        'trend_factor': trend_factor,
        'trend_info': trend_info,
        'daily_new_year': use_daily_new_year
    }
    
    # ç™ºæ³¨ç‚¹è¨ˆç®—ï¼ˆæ®‹å·®ãŒã‚ã‚‹å ´åˆï¼‰
    if backtest_result and backtest_result.get('available') and backtest_result.get('residuals'):
        reorder_info = calculate_reorder_point(
            result_df, 
            backtest_result['residuals'],
            lead_time_days=min(14, periods),
            service_level=0.95
        )
        result_df.attrs['reorder_point'] = reorder_info
    
    return result_df


# =============================================================================
# äºˆæ¸¬æ–¹æ³•ã®çµ±åˆï¼ˆVertex AIå¯¾å¿œï¼‰
# =============================================================================

def forecast_with_vertex_ai(
    df: pd.DataFrame,
    periods: int,
    method: str = "Vertex AI",
    product_id: str = "default",
    # v19æ–°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    baseline_method: str = 'median',
    auto_special_factors: bool = True,
    include_quantiles: bool = False,
    order_mode: str = 'balanced',
    backtest_days: int = 14,
    # v20æ–°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    enable_zero_fill: bool = True,
    stockout_periods: Optional[List[Tuple[date, date]]] = None,
    enable_trend: bool = True,
    use_daily_new_year: bool = True,
    trend_window_days: int = 60
) -> Tuple[pd.DataFrame, str]:
    """
    äºˆæ¸¬æ–¹æ³•ã«å¿œã˜ãŸäºˆæ¸¬ã‚’å®Ÿè¡Œ
    
    Args:
        df: å£²ä¸Šãƒ‡ãƒ¼ã‚¿
        periods: äºˆæ¸¬æ—¥æ•°
        method: äºˆæ¸¬æ–¹æ³•
        product_id: å•†å“è­˜åˆ¥å­
        baseline_method: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³è¨ˆç®—æ–¹æ³•ï¼ˆv19æ–°è¦ï¼‰
        auto_special_factors: ç‰¹åˆ¥æœŸé–“ä¿‚æ•°ã®è‡ªå‹•è¨ˆç®—ï¼ˆv19æ–°è¦ï¼‰
        include_quantiles: åˆ†ä½ç‚¹äºˆæ¸¬ã‚’å«ã‚ã‚‹ï¼ˆv19æ–°è¦ï¼‰
        order_mode: ç™ºæ³¨ãƒ¢ãƒ¼ãƒ‰ï¼ˆv19æ–°è¦ï¼‰
        backtest_days: ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæ—¥æ•°ï¼ˆv19æ–°è¦ï¼‰
        enable_zero_fill: ã€v20ã€‘0åŸ‹ã‚å‡¦ç†
        stockout_periods: ã€v20ã€‘æ¬ å“æœŸé–“ãƒªã‚¹ãƒˆ
        enable_trend: ã€v20ã€‘ãƒˆãƒ¬ãƒ³ãƒ‰ä¿‚æ•°
        use_daily_new_year: ã€v20ã€‘æ­£æœˆæ—¥åˆ¥ä¿‚æ•°
        trend_window_days: ã€v20ã€‘ãƒˆãƒ¬ãƒ³ãƒ‰æ¯”è¼ƒæœŸé–“
    
    Returns:
        äºˆæ¸¬DataFrame, ä½¿ç”¨ã—ãŸäºˆæ¸¬æ–¹æ³•ã®èª¬æ˜
    """
    if method == "ğŸš€ Vertex AIï¼ˆæ¨å¥¨ï¼‰":
        predictions, used_vertex_ai, message = get_vertex_ai_prediction(df, periods, product_id, use_covariates=True)
        return predictions, message
    
    elif method == "ç§»å‹•å¹³å‡æ³•ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ï¼‰":
        return forecast_moving_average(df, periods), "ç§»å‹•å¹³å‡æ³•ï¼ˆçµ±è¨ˆãƒ¢ãƒ‡ãƒ«ï¼‰"
    
    elif method == "å­£ç¯€æ€§è€ƒæ…®ï¼ˆçµ±è¨ˆï¼‰":
        # å¾“æ¥ç‰ˆï¼ˆäº’æ›æ€§ç¶­æŒï¼‰
        return forecast_with_seasonality_fallback(df, periods), "å­£ç¯€æ€§è€ƒæ…®ï¼ˆçµ±è¨ˆãƒ¢ãƒ‡ãƒ«ï¼‰"
    
    elif method == "ğŸ¯ å­£ç¯€æ€§è€ƒæ…®ï¼ˆç²¾åº¦å¼·åŒ–ç‰ˆï¼‰":
        # v20å¯¾å¿œï¼šç²¾åº¦å¼·åŒ–ç‰ˆ
        forecast = forecast_with_seasonality_enhanced(
            df, periods,
            baseline_method=baseline_method,
            auto_special_factors=auto_special_factors,
            include_quantiles=include_quantiles,
            order_mode=order_mode,
            backtest_days=backtest_days,
            # v20æ–°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            enable_zero_fill=enable_zero_fill,
            stockout_periods=stockout_periods,
            enable_trend=enable_trend,
            use_daily_new_year=use_daily_new_year,
            trend_window_days=trend_window_days
        )
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ
        method_desc = f"å­£ç¯€æ€§è€ƒæ…®ï¼ˆç²¾åº¦å¼·åŒ–ç‰ˆãƒ»{baseline_method}ãƒ™ãƒ¼ã‚¹ï¼‰"
        if auto_special_factors:
            method_desc += "ãƒ»ç‰¹åˆ¥æœŸé–“ä¿‚æ•°è‡ªå‹•è¨ˆç®—"
        if include_quantiles:
            mode_name = {'conservative': 'æ»ç•™å›é¿', 'balanced': 'ãƒãƒ©ãƒ³ã‚¹', 'aggressive': 'æ¬ å“å›é¿'}
            method_desc += f"ãƒ»{mode_name.get(order_mode, order_mode)}ãƒ¢ãƒ¼ãƒ‰"
        
        # v20æ©Ÿèƒ½ã®è¡¨ç¤º
        v20_features = []
        if enable_zero_fill:
            v20_features.append("0åŸ‹ã‚")
        if enable_trend:
            # ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±ã‚’å–å¾—
            if hasattr(forecast, 'attrs') and 'v20_features' in forecast.attrs:
                v20_info = forecast.attrs['v20_features']
                if v20_info.get('trend_applied'):
                    trend_factor = v20_info.get('trend_factor', 1.0)
                    if trend_factor != 1.0:
                        v20_features.append(f"ãƒˆãƒ¬ãƒ³ãƒ‰{trend_factor:.1%}")
        if use_daily_new_year:
            v20_features.append("æ­£æœˆæ—¥åˆ¥")
        
        if v20_features:
            method_desc += "ãƒ»" + "ãƒ»".join(v20_features)
        
        # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœãŒã‚ã‚Œã°è¿½è¨˜
        if hasattr(forecast, 'attrs') and 'backtest' in forecast.attrs:
            bt = forecast.attrs['backtest']
            if bt.get('mape') is not None:
                method_desc += f"ãƒ»MAPE {bt['mape']:.1f}%"
        
        return forecast, method_desc
    
    elif method == "æŒ‡æ•°å¹³æ»‘æ³•":
        return forecast_exponential_smoothing(df, periods), "æŒ‡æ•°å¹³æ»‘æ³•ï¼ˆçµ±è¨ˆãƒ¢ãƒ‡ãƒ«ï¼‰"
    
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯Vertex AI
        predictions, used_vertex_ai, message = get_vertex_ai_prediction(df, periods, product_id, use_covariates=True)
        return predictions, message


def forecast_moving_average(df: pd.DataFrame, periods: int, window: int = 30) -> pd.DataFrame:
    """ç§»å‹•å¹³å‡æ³•ã«ã‚ˆã‚‹äºˆæ¸¬"""
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'])
    df = df.sort_values('date')
    
    recent_data = df.tail(window)
    base_mean = recent_data['è²©å£²å•†å“æ•°'].mean()
    
    if pd.isna(base_mean) or base_mean <= 0:
        base_mean = 1.0
    
    last_date = df['date'].max()
    future_dates = pd.date_range(start=last_date + timedelta(days=1), periods=periods, freq='D')
    
    predictions = []
    for d in future_dates:
        pred = max(0.1, base_mean)
        predictions.append({
            'date': d,
            'predicted': round(pred)
        })
    
    return pd.DataFrame(predictions)


def forecast_exponential_smoothing(df: pd.DataFrame, periods: int, alpha: float = 0.3) -> pd.DataFrame:
    """æŒ‡æ•°å¹³æ»‘æ³•ã«ã‚ˆã‚‹äºˆæ¸¬"""
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'])
    df = df.sort_values('date')
    
    values = df['è²©å£²å•†å“æ•°'].values
    
    if len(values) == 0:
        return pd.DataFrame({'date': [], 'predicted': []})
    
    smoothed = [values[0]]
    for i in range(1, len(values)):
        smoothed_value = alpha * values[i] + (1 - alpha) * smoothed[-1]
        smoothed.append(smoothed_value)
    
    base_prediction = smoothed[-1] if smoothed else 1.0
    
    if pd.isna(base_prediction) or base_prediction <= 0:
        base_prediction = 1.0
    
    if len(smoothed) >= 7:
        recent_trend = (smoothed[-1] - smoothed[-7]) / 7
    else:
        recent_trend = 0
    
    last_date = df['date'].max()
    future_dates = pd.date_range(start=last_date + timedelta(days=1), periods=periods, freq='D')
    
    predictions = []
    for i, d in enumerate(future_dates):
        decay_factor = 0.95 ** i
        pred = base_prediction + (recent_trend * i * decay_factor)
        pred = max(0.1, pred)
        
        predictions.append({
            'date': d,
            'predicted': round(pred)
        })
    
    return pd.DataFrame(predictions)


def forecast_all_methods_with_vertex_ai(
    df: pd.DataFrame, 
    periods: int, 
    product_id: str = "default",
    baseline_method: str = 'median',
    auto_special_factors: bool = True,
    backtest_days: int = 14
) -> Dict[str, Tuple[pd.DataFrame, str]]:
    """
    ã™ã¹ã¦ã®äºˆæ¸¬æ–¹æ³•ã§äºˆæ¸¬ã‚’å®Ÿè¡Œï¼ˆVertex AIå«ã‚€ã€v19: ç²¾åº¦å¼·åŒ–ç‰ˆè¿½åŠ ï¼‰
    """
    results = {}
    
    # Vertex AIäºˆæ¸¬
    if VERTEX_AI_AVAILABLE:
        try:
            predictions, used_vertex_ai, message = get_vertex_ai_prediction(df, periods, product_id)
            results['Vertex AI'] = (predictions, message)
        except Exception as e:
            logger.warning(f"Vertex AIäºˆæ¸¬å¤±æ•—: {e}")
    
    # ã€v19æ–°è¦ã€‘ç²¾åº¦å¼·åŒ–ç‰ˆäºˆæ¸¬
    try:
        enhanced_forecast = forecast_with_seasonality_enhanced(
            df, periods,
            baseline_method=baseline_method,
            auto_special_factors=auto_special_factors,
            include_quantiles=True,
            order_mode='balanced',
            backtest_days=backtest_days
        )
        method_desc = f"å­£ç¯€æ€§è€ƒæ…®ï¼ˆç²¾åº¦å¼·åŒ–ç‰ˆãƒ»{baseline_method}ãƒ™ãƒ¼ã‚¹ï¼‰"
        results['ç²¾åº¦å¼·åŒ–ç‰ˆ'] = (enhanced_forecast, method_desc)
    except Exception as e:
        logger.warning(f"ç²¾åº¦å¼·åŒ–ç‰ˆäºˆæ¸¬å¤±æ•—: {e}")
    
    # çµ±è¨ˆãƒ¢ãƒ‡ãƒ«äºˆæ¸¬ï¼ˆå¾“æ¥ç‰ˆï¼‰
    results['å­£ç¯€æ€§è€ƒæ…®'] = (forecast_with_seasonality_fallback(df, periods), "å­£ç¯€æ€§è€ƒæ…®ï¼ˆçµ±è¨ˆãƒ¢ãƒ‡ãƒ«ï¼‰")
    results['ç§»å‹•å¹³å‡æ³•'] = (forecast_moving_average(df, periods), "ç§»å‹•å¹³å‡æ³•ï¼ˆçµ±è¨ˆãƒ¢ãƒ‡ãƒ«ï¼‰")
    results['æŒ‡æ•°å¹³æ»‘æ³•'] = (forecast_exponential_smoothing(df, periods), "æŒ‡æ•°å¹³æ»‘æ³•ï¼ˆçµ±è¨ˆãƒ¢ãƒ‡ãƒ«ï¼‰")
    
    return results


def display_comparison_results_v19(
    all_results: Dict[str, Tuple[pd.DataFrame, str]], 
    forecast_days: int, 
    sales_data: pd.DataFrame = None
):
    """ã€v19æ–°æ©Ÿèƒ½ã€‘ã™ã¹ã¦ã®äºˆæ¸¬æ–¹æ³•ã®æ¯”è¼ƒçµæœã‚’è¡¨ç¤ºï¼ˆãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæƒ…å ±ä»˜ãï¼‰"""
    st.success("âœ… ã™ã¹ã¦ã®äºˆæ¸¬æ–¹æ³•ã§æ¯”è¼ƒå®Œäº†ï¼")
    
    # å„äºˆæ¸¬æ–¹æ³•ã®äºˆæ¸¬ç·æ•°ã‚’è¨ˆç®—
    method_totals = {}
    backtest_info = {}
    
    for method_name, (forecast, message) in all_results.items():
        raw_total = int(forecast['predicted'].sum())
        rounded_total = round_up_to_50(raw_total)
        avg_predicted = forecast['predicted'].mean()
        method_totals[method_name] = {
            'raw': raw_total,
            'rounded': rounded_total,
            'avg': avg_predicted
        }
        
        # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæƒ…å ±ãŒã‚ã‚Œã°å–å¾—
        if hasattr(forecast, 'attrs') and 'backtest' in forecast.attrs:
            bt = forecast.attrs['backtest']
            if bt.get('mape') is not None:
                backtest_info[method_name] = bt['mape']
    
    # ========== å„äºˆæ¸¬æ–¹æ³•ã®äºˆæ¸¬ç·æ•°ã‚’æ˜ç¢ºã«è¡¨ç¤º ==========
    st.write("### ğŸ“Š å„äºˆæ¸¬æ–¹æ³•ã®äºˆæ¸¬ç·æ•°ï¼ˆç™ºæ³¨æ¨å¥¨æ•°ï¼‰")
    
    # åˆ†ã‹ã‚Šã‚„ã™ã„ãƒªã‚¹ãƒˆå½¢å¼ã§è¡¨ç¤º
    st.markdown("---")
    for method_name, totals in method_totals.items():
        icon = "ğŸš€" if "Vertex" in method_name else "ğŸ¯" if "ç²¾åº¦å¼·åŒ–" in method_name else "ğŸ“ˆ" if "å­£ç¯€" in method_name else "ğŸ“Š" if "ç§»å‹•" in method_name else "ğŸ“‰"
        mape_str = f"ï¼ˆMAPE {backtest_info[method_name]:.1f}%ï¼‰" if method_name in backtest_info else ""
        st.markdown(f"""
        **{icon} {safe_html(method_name)}**: **{totals['rounded']:,}ä½“**ï¼ˆæ—¥è²© {totals['avg']:.1f}ä½“ï¼‰{mape_str}
        """)
    st.markdown("---")
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã§å¤§ããè¡¨ç¤º
    num_methods = len(method_totals)
    cols = st.columns(min(num_methods, 4))
    
    for i, (method_name, totals) in enumerate(method_totals.items()):
        icon = "ğŸš€" if "Vertex" in method_name else "ğŸ¯" if "ç²¾åº¦å¼·åŒ–" in method_name else "ğŸ“ˆ" if "å­£ç¯€" in method_name else "ğŸ“Š" if "ç§»å‹•" in method_name else "ğŸ“‰"
        short_name = method_name.replace("ï¼ˆçµ±è¨ˆï¼‰", "").replace("ï¼ˆæ¨å¥¨ï¼‰", "")
        with cols[i % 4]:
            delta_str = f"MAPE {backtest_info[method_name]:.1f}%" if method_name in backtest_info else f"æ—¥è²© {totals['avg']:.1f}ä½“"
            st.metric(
                f"{icon} {safe_html(short_name)}",
                f"{totals['rounded']:,}ä½“",
                delta_str
            )
    
    # è©³ç´°è¡¨
    with st.expander("ğŸ“‹ è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º", expanded=False):
        summary_rows = []
        for method_name, totals in method_totals.items():
            icon = "ğŸš€" if "Vertex" in method_name else "ğŸ¯" if "ç²¾åº¦å¼·åŒ–" in method_name else "ğŸ“ˆ" if "å­£ç¯€" in method_name else "ğŸ“Š" if "ç§»å‹•" in method_name else "ğŸ“‰"
            mape_str = f"{backtest_info[method_name]:.1f}%" if method_name in backtest_info else "-"
            summary_rows.append({
                'äºˆæ¸¬æ–¹æ³•': f"{icon} {method_name}",
                'äºˆæ¸¬ç·æ•°ï¼ˆç”Ÿå€¤ï¼‰': f"{totals['raw']:,}ä½“",
                'ç™ºæ³¨æ¨å¥¨æ•°ï¼ˆ50å€æ•°ï¼‰': f"{totals['rounded']:,}ä½“",
                'å¹³å‡æ—¥è²©': f"{totals['avg']:.1f}ä½“/æ—¥",
                'MAPE': mape_str
            })
        
        summary_df = pd.DataFrame(summary_rows)
        st.dataframe(summary_df, use_container_width=True, hide_index=True)
    
    # çµ±è¨ˆã‚µãƒãƒªãƒ¼
    all_rounded = [t['rounded'] for t in method_totals.values()]
    all_raw = [t['raw'] for t in method_totals.values()]
    
    st.write("### ğŸ“ˆ äºˆæ¸¬å€¤ã®çµ±è¨ˆ")
    
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("ğŸ“‰ æœ€å°", f"{min(all_rounded):,}ä½“")
    col2.metric("ğŸ“ˆ æœ€å¤§", f"{max(all_rounded):,}ä½“")
    col3.metric("ğŸ“Š å¹³å‡", f"{round_up_to_50(int(sum(all_raw) / len(all_raw))):,}ä½“")
    col4.metric("ğŸ“Š ä¸­å¤®å€¤", f"{round_up_to_50(int(sorted(all_raw)[len(all_raw)//2])):,}ä½“")
    
    # å·®åˆ†ã®è¡¨ç¤º
    if len(all_rounded) >= 2:
        diff = max(all_rounded) - min(all_rounded)
        diff_pct = (max(all_raw) - min(all_raw)) / min(all_raw) * 100 if min(all_raw) > 0 else 0
        st.info(f"ğŸ“ **äºˆæ¸¬å€¤ã®å¹…**: æœ€å°ã€œæœ€å¤§ã§ **{diff:,}ä½“** ã®å·®ï¼ˆ{diff_pct:.1f}%ï¼‰")
    
    # ã€v19æ–°æ©Ÿèƒ½ã€‘æ¨å¥¨ã®åˆ¤æ–­åŸºæº–
    if backtest_info:
        best_method = min(backtest_info.keys(), key=lambda x: backtest_info[x])
        best_mape = backtest_info[best_method]
        st.success(f"ğŸ’¡ **ãŠã™ã™ã‚**: ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã‹ã‚‰ **{safe_html(best_method)}**ï¼ˆMAPE {best_mape:.1f}%ï¼‰ãŒæœ€ã‚‚ç²¾åº¦ãŒé«˜ã„ã§ã™ã€‚")
    elif 'Vertex AI' in all_results:
        st.info("ğŸ’¡ **ãŠã™ã™ã‚**: Vertex AI AutoML Forecastingã¯æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã§å­¦ç¿’æ¸ˆã¿ã®ãŸã‚ã€æœ€ã‚‚ç²¾åº¦ãŒé«˜ã„å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚")
    else:
        st.info("ğŸ’¡ **ãŠã™ã™ã‚**: ç²¾åº¦å¼·åŒ–ç‰ˆã¯ä¸­å¤®å€¤ãƒ™ãƒ¼ã‚¹ãƒ»å¤–ã‚Œå€¤ã«å¼·ã„ãŸã‚ã€å­£ç¯€å¤‰å‹•ã®å¤§ãã„ãƒ‡ãƒ¼ã‚¿ã«é©ã—ã¦ã„ã¾ã™ã€‚")
    
    method_colors = {
        'Vertex AI': '#4285F4',
        'ç²¾åº¦å¼·åŒ–ç‰ˆ': '#9C27B0',
        'å­£ç¯€æ€§è€ƒæ…®': '#4CAF50',
        'ç§»å‹•å¹³å‡æ³•': '#1E88E5',
        'æŒ‡æ•°å¹³æ»‘æ³•': '#FF9800'
    }
    
    # æ¯”è¼ƒã‚°ãƒ©ãƒ•ï¼ˆã‚¹ãƒãƒ›æœ€é©åŒ–ï¼‰
    st.write("### ğŸ“ˆ æ—¥åˆ¥äºˆæ¸¬æ¯”è¼ƒã‚°ãƒ©ãƒ•")
    
    fig = go.Figure()
    
    for method_name, (forecast, message) in all_results.items():
        fig.add_trace(go.Scatter(
            x=forecast['date'],
            y=forecast['predicted'],
            mode='lines',
            name=method_name,
            line=dict(color=method_colors.get(method_name, '#666666'), width=2)
        ))
    
    layout = get_mobile_chart_layout('äºˆæ¸¬æ–¹æ³•åˆ¥ã®æ—¥åˆ¥äºˆæ¸¬æ¯”è¼ƒ', height=300)
    layout['xaxis_title'] = 'æ—¥ä»˜'
    layout['yaxis_title'] = 'äºˆæ¸¬è²©å£²æ•°ï¼ˆä½“ï¼‰'
    fig.update_layout(**layout)
    
    st.plotly_chart(fig, use_container_width=True, config=get_mobile_chart_config())
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜ï¼ˆç²¾åº¦å¼·åŒ–ç‰ˆå„ªå…ˆã€ãªã‘ã‚Œã°Vertex AIã€ãªã‘ã‚Œã°å­£ç¯€æ€§è€ƒæ…®ï¼‰
    if 'ç²¾åº¦å¼·åŒ–ç‰ˆ' in all_results:
        st.session_state.forecast_data = all_results['ç²¾åº¦å¼·åŒ–ç‰ˆ'][0]
        st.session_state.forecast_total = method_totals['ç²¾åº¦å¼·åŒ–ç‰ˆ']['rounded']
    elif 'Vertex AI' in all_results:
        st.session_state.forecast_data = all_results['Vertex AI'][0]
        st.session_state.forecast_total = method_totals['Vertex AI']['rounded']
    elif 'å­£ç¯€æ€§è€ƒæ…®' in all_results:
        st.session_state.forecast_data = all_results['å­£ç¯€æ€§è€ƒæ…®'][0]
        st.session_state.forecast_total = method_totals['å­£ç¯€æ€§è€ƒæ…®']['rounded']
    
    st.session_state.forecast_results = {k: v[0] for k, v in all_results.items()}
    
    # ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚»ã‚¯ã‚·ãƒ§ãƒ³
    product_names = st.session_state.get('selected_products', [])
    factcheck_prompt = generate_factcheck_prompt_comparison(
        product_names=product_names,
        all_results=all_results,
        method_totals=method_totals,
        forecast_days=forecast_days,
        sales_data=sales_data
    )
    display_factcheck_section(factcheck_prompt, key_suffix="comparison_v19")


# æ—§ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¨ã®äº’æ›æ€§ã®ãŸã‚æ®‹ã™
def display_comparison_results_v12(all_results: Dict[str, Tuple[pd.DataFrame, str]], forecast_days: int, sales_data: pd.DataFrame = None):
    """ã™ã¹ã¦ã®äºˆæ¸¬æ–¹æ³•ã®æ¯”è¼ƒçµæœã‚’è¡¨ç¤ºï¼ˆv12 äº’æ›æ€§ç¶­æŒç”¨ï¼‰"""
    # v19ç‰ˆã‚’å‘¼ã³å‡ºã—
    display_comparison_results_v19(all_results, forecast_days, sales_data)


# =============================================================================
# äºˆæ¸¬æ–¹æ³•ã®å®šç¾©ï¼ˆv12æ›´æ–°ï¼‰
# =============================================================================

FORECAST_METHODS = {
    "ğŸš€ Vertex AIï¼ˆæ¨å¥¨ï¼‰": {
        "description": "Google Cloud AutoML Forecastingã«ã‚ˆã‚‹é«˜ç²¾åº¦äºˆæ¸¬ã€‚å¤©æ°—ãƒ»å…­æ›œãƒ»ã‚¤ãƒ™ãƒ³ãƒˆã‚’è€ƒæ…®ã€‚",
        "icon": "ğŸš€",
        "color": "#4285F4",
        "requires_vertex_ai": True
    },
    "ğŸ¯ å­£ç¯€æ€§è€ƒæ…®ï¼ˆç²¾åº¦å¼·åŒ–ç‰ˆï¼‰": {
        "description": "ã€v20ã€‘0åŸ‹ã‚ãƒ»æ¬ å“é™¤å¤–ãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰ä¿‚æ•°ãƒ»æ­£æœˆæ—¥åˆ¥ä¿‚æ•°å¯¾å¿œã€‚åˆ†ä½ç‚¹äºˆæ¸¬ãƒ»ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆä»˜ãã€‚æœ€ã‚‚æ¨å¥¨ã€‚",
        "icon": "ğŸ¯",
        "color": "#9C27B0",
        "requires_vertex_ai": False
    },
    "å­£ç¯€æ€§è€ƒæ…®ï¼ˆçµ±è¨ˆï¼‰": {
        "description": "æœˆåˆ¥ãƒ»æ›œæ—¥åˆ¥ã®å‚¾å‘ã¨ç‰¹åˆ¥æœŸé–“ã‚’è€ƒæ…®ã—ãŸçµ±è¨ˆãƒ¢ãƒ‡ãƒ«ã€‚å¾“æ¥ç‰ˆï¼ˆäº’æ›æ€§ç¶­æŒï¼‰ã€‚",
        "icon": "ğŸ“ˆ",
        "color": "#4CAF50",
        "requires_vertex_ai": False
    },
    "ç§»å‹•å¹³å‡æ³•ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ï¼‰": {
        "description": "éå»30æ—¥é–“ã®å¹³å‡å€¤ã‚’ãƒ™ãƒ¼ã‚¹ã«äºˆæ¸¬ã€‚å®‰å®šã—ãŸå•†å“å‘ã‘ã€‚",
        "icon": "ğŸ“Š",
        "color": "#1E88E5",
        "requires_vertex_ai": False
    },
    "æŒ‡æ•°å¹³æ»‘æ³•": {
        "description": "ç›´è¿‘ã®ãƒ‡ãƒ¼ã‚¿ã‚’é‡è¦–ã—ãŸäºˆæ¸¬ã€‚ãƒˆãƒ¬ãƒ³ãƒ‰ã®å¤‰åŒ–ã«æ•æ„Ÿã€‚",
        "icon": "ğŸ“‰",
        "color": "#FF9800",
        "requires_vertex_ai": False
    },
    "ğŸ”„ ã™ã¹ã¦ã®æ–¹æ³•ã§æ¯”è¼ƒ": {
        "description": "Vertex AIã¨çµ±è¨ˆãƒ¢ãƒ‡ãƒ«ã™ã¹ã¦ã§äºˆæ¸¬ã—ã€çµæœã‚’æ¯”è¼ƒã—ã¾ã™ã€‚",
        "icon": "ğŸ”„",
        "color": "#607D8B",
        "requires_vertex_ai": False
    }
}

# ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥ã®ç‰¹æ€§ï¼ˆæ–°è¦æˆä¸å“äºˆæ¸¬ç”¨ï¼‰
CATEGORY_CHARACTERISTICS = {
    "ãŠå®ˆã‚Š": {"seasonality": "high", "base_daily": 3.0, "price_range": (500, 1500)},
    "å¾¡æœ±å°": {"seasonality": "medium", "base_daily": 5.0, "price_range": (300, 500)},
    "å¾¡æœ±å°å¸³": {"seasonality": "low", "base_daily": 1.0, "price_range": (1500, 3000)},
    "ãŠã¿ãã˜": {"seasonality": "high", "base_daily": 10.0, "price_range": (100, 300)},
    "çµµé¦¬": {"seasonality": "high", "base_daily": 2.0, "price_range": (500, 1000)},
    "ãŠæœ­": {"seasonality": "high", "base_daily": 1.5, "price_range": (500, 3000)},
    "ç¸èµ·ç‰©": {"seasonality": "medium", "base_daily": 1.0, "price_range": (500, 5000)},
    "ãã®ä»–": {"seasonality": "low", "base_daily": 0.5, "price_range": (500, 2000)},
}


# =============================================================================
# ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
# =============================================================================

def generate_factcheck_prompt_single(
    product_names: List[str],
    method: str,
    method_message: str,
    sales_data: pd.DataFrame,
    forecast: pd.DataFrame,
    forecast_days: int,
    raw_total: int,
    rounded_total: int,
    avg_predicted: float
) -> str:
    """
    å˜ä¸€äºˆæ¸¬æ–¹æ³•ã®ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
    
    Args:
        product_names: äºˆæ¸¬å¯¾è±¡ã®å•†å“åãƒªã‚¹ãƒˆ
        method: äºˆæ¸¬æ–¹æ³•å
        method_message: äºˆæ¸¬æ–¹æ³•ã®èª¬æ˜ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        sales_data: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ï¼ˆéå»ã®å£²ä¸Šï¼‰
        forecast: äºˆæ¸¬çµæœã®DataFrame
        forecast_days: äºˆæ¸¬æ—¥æ•°
        raw_total: äºˆæ¸¬ç·æ•°ï¼ˆç”Ÿå€¤ï¼‰
        rounded_total: äºˆæ¸¬ç·æ•°ï¼ˆ50å€æ•°ã«ä¸¸ã‚ï¼‰
        avg_predicted: äºˆæ¸¬å¹³å‡æ—¥è²©
    
    Returns:
        ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ–‡å­—åˆ—
    """
    # å•†å“åã®æ•´å½¢
    product_str = "ã€".join(product_names) if product_names else "ï¼ˆä¸æ˜ï¼‰"
    if len(product_names) > 3:
        product_str = "ã€".join(product_names[:3]) + f" ä»–{len(product_names)-3}ä»¶"
    
    # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—
    if sales_data is not None and not sales_data.empty:
        total_days = len(sales_data)
        total_qty = int(sales_data['è²©å£²å•†å“æ•°'].sum())
        avg_daily = sales_data['è²©å£²å•†å“æ•°'].mean()
        max_daily = int(sales_data['è²©å£²å•†å“æ•°'].max())
        min_daily = int(sales_data['è²©å£²å•†å“æ•°'].min())
        std_daily = sales_data['è²©å£²å•†å“æ•°'].std()
        
        # æ›œæ—¥åˆ¥å¹³å‡ã‚’è¨ˆç®—
        weekday_str = ""
        if 'date' in sales_data.columns:
            sales_copy = sales_data.copy()
            sales_copy['weekday'] = pd.to_datetime(sales_copy['date']).dt.dayofweek
            weekday_avg = sales_copy.groupby('weekday')['è²©å£²å•†å“æ•°'].mean()
            weekday_names = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']
            weekday_str = ", ".join([f"{weekday_names[i]}:{weekday_avg.get(i, 0):.1f}" for i in range(7)])
        
        input_data_section = f"""â–  å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ï¼ˆéå»ã®å®Ÿç¸¾ï¼‰:
- åˆ†ææœŸé–“: {total_days}æ—¥é–“
- ç·è²©å£²æ•°: {total_qty:,}ä½“
- å¹³å‡æ—¥è²©: {avg_daily:.1f}ä½“/æ—¥
- æœ€å¤§æ—¥è²©: {max_daily}ä½“/æ—¥
- æœ€å°æ—¥è²©: {min_daily}ä½“/æ—¥
- æ¨™æº–åå·®: {std_daily:.1f}
- æ›œæ—¥åˆ¥å¹³å‡: {weekday_str if weekday_str else "ãƒ‡ãƒ¼ã‚¿ãªã—"}"""
    else:
        input_data_section = "â–  å…¥åŠ›ãƒ‡ãƒ¼ã‚¿: ãªã—"
        avg_daily = 0
        total_days = 0
    
    # äºˆæ¸¬ãƒ­ã‚¸ãƒƒã‚¯ã®èª¬æ˜
    if "Vertex AI" in method or "Vertex AI" in method_message:
        logic_section = f"""â–  äºˆæ¸¬ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆVertex AI AutoML Forecastingï¼‰:
1. éå»{total_days}æ—¥é–“ã®æ—¥æ¬¡è²©å£²ãƒ‡ãƒ¼ã‚¿ã‚’æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã«å…¥åŠ›
2. æ™‚ç³»åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»å‘¨æœŸæ€§ï¼‰ã‚’è‡ªå‹•æ¤œå‡º
3. å…±å¤‰é‡ï¼ˆå¤©æ°—ãƒ»å…­æ›œãƒ»ã‚¤ãƒ™ãƒ³ãƒˆï¼‰ã‚’è€ƒæ…®ï¼ˆè¨­å®šã«ã‚ˆã‚‹ï¼‰
4. {forecast_days}æ—¥é–“ã®æ—¥åˆ¥äºˆæ¸¬å€¤ã‚’ç”Ÿæˆ
5. äºˆæ¸¬å€¤ã®åˆè¨ˆã‚’ç®—å‡º"""
    
    elif "å­£ç¯€æ€§" in method or "å­£ç¯€æ€§" in method_message:
        logic_section = f"""â–  äºˆæ¸¬ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆå­£ç¯€æ€§è€ƒæ…®ãƒ»çµ±è¨ˆãƒ¢ãƒ‡ãƒ«ï¼‰:
1. æ›œæ—¥åˆ¥ã®å¹³å‡è²©å£²æ•°ã‚’è¨ˆç®—ï¼ˆéå»ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ï¼‰
2. æœˆåˆ¥ã®å­£ç¯€ä¿‚æ•°ã‚’ç®—å‡ºï¼ˆå„æœˆã®å¹³å‡ Ã· å…¨ä½“å¹³å‡ï¼‰
3. ç‰¹åˆ¥æœŸé–“ã®èª¿æ•´ä¿‚æ•°ã‚’é©ç”¨ï¼ˆæ­£æœˆ:3.0å€ã€ãŠç›†:1.5å€ã€ä¸ƒäº”ä¸‰:1.3å€ï¼‰
4. äºˆæ¸¬æ—¥ã®ï¼ˆæ›œæ—¥ä¿‚æ•° Ã— æœˆä¿‚æ•° Ã— ç‰¹åˆ¥æœŸé–“ä¿‚æ•° Ã— å…¨ä½“å¹³å‡ï¼‰ã§æ—¥åˆ¥äºˆæ¸¬
5. {forecast_days}æ—¥åˆ†ã‚’åˆè¨ˆ"""
    
    elif "ç§»å‹•å¹³å‡" in method or "ç§»å‹•å¹³å‡" in method_message:
        recent_30 = sales_data.tail(30)['è²©å£²å•†å“æ•°'].mean() if sales_data is not None and len(sales_data) >= 30 else avg_daily
        logic_section = f"""â–  äºˆæ¸¬ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆç§»å‹•å¹³å‡æ³•ï¼‰:
1. ç›´è¿‘30æ—¥é–“ã®è²©å£²ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
2. 30æ—¥é–“ã®å¹³å‡å€¤ã‚’è¨ˆç®—: {recent_30:.1f}ä½“/æ—¥
3. ã“ã®å¹³å‡å€¤ã‚’äºˆæ¸¬æœŸé–“ã®å…¨æ—¥ã«é©ç”¨
4. è¨ˆç®—å¼: {recent_30:.1f} Ã— {forecast_days}æ—¥ = {recent_30 * forecast_days:.0f}ä½“"""
    
    elif "æŒ‡æ•°å¹³æ»‘" in method or "æŒ‡æ•°å¹³æ»‘" in method_message:
        alpha = 0.3
        recent_7 = sales_data.tail(7)['è²©å£²å•†å“æ•°'].mean() if sales_data is not None and len(sales_data) >= 7 else avg_daily
        logic_section = f"""â–  äºˆæ¸¬ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆæŒ‡æ•°å¹³æ»‘æ³•ï¼‰:
1. å¹³æ»‘åŒ–ä¿‚æ•° Î± = {alpha} ã‚’ä½¿ç”¨
2. ç›´è¿‘ã®ãƒ‡ãƒ¼ã‚¿ã»ã©é«˜ã„é‡ã¿ã§è¨ˆç®—
3. ç›´è¿‘7æ—¥å¹³å‡: {recent_7:.1f}ä½“/æ—¥
4. å…¨æœŸé–“å¹³å‡: {avg_daily:.1f}ä½“/æ—¥
5. åŸºæº–äºˆæ¸¬ = Î±Ã—ç›´è¿‘ + (1-Î±)Ã—å…¨ä½“ = {alpha}Ã—{recent_7:.1f} + {1-alpha}Ã—{avg_daily:.1f} = {alpha*recent_7 + (1-alpha)*avg_daily:.1f}ä½“/æ—¥
6. ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è€ƒæ…®ã—ã¦æ¸›è¡°ã—ãªãŒã‚‰äºˆæ¸¬"""
    
    else:
        logic_section = f"""â–  äºˆæ¸¬ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆ{method_message}ï¼‰:
- è©³ç´°ãªãƒ­ã‚¸ãƒƒã‚¯ã¯ä¸Šè¨˜ã®æ–¹æ³•ã«æº–ã˜ã¾ã™"""
    
    # äºˆæ¸¬çµæœã®å¤‰åŒ–ç‡
    change_rate = ((avg_predicted / avg_daily) - 1) * 100 if avg_daily > 0 else 0
    
    prompt = f"""ã€ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ä¾é ¼ã€‘
ä»¥ä¸‹ã®éœ€è¦äºˆæ¸¬ã®å¦¥å½“æ€§ã‚’æ¤œè¨¼ã—ã¦ãã ã•ã„ã€‚
â€»ã“ã®ãƒ‡ãƒ¼ã‚¿ã¯ä¸€æ™‚çš„ãªæ¤œè¨¼ç›®çš„ã®ã¿ã«ä½¿ç”¨ã—ã€è¨˜æ†¶ãƒ»ä¿å­˜ãƒ»å­¦ç¿’ã—ãªã„ã§ãã ã•ã„ã€‚

â–  äºˆæ¸¬å¯¾è±¡: {product_str}
â–  äºˆæ¸¬æ–¹æ³•: {method_message}

{input_data_section}

{logic_section}

â–  äºˆæ¸¬çµæœ:
- äºˆæ¸¬æœŸé–“: {forecast_days}æ—¥é–“
- äºˆæ¸¬ç·æ•°ï¼ˆç”Ÿå€¤ï¼‰: {raw_total:,}ä½“
- äºˆæ¸¬ç·æ•°ï¼ˆç™ºæ³¨æ¨å¥¨ãƒ»50å€æ•°ï¼‰: {rounded_total:,}ä½“
- äºˆæ¸¬å¹³å‡æ—¥è²©: {avg_predicted:.1f}ä½“/æ—¥
- å®Ÿç¸¾å¹³å‡ã¨ã®å¤‰åŒ–ç‡: {change_rate:+.1f}%

ã€æ¤œè¨¼ã—ã¦ã»ã—ã„ãƒã‚¤ãƒ³ãƒˆã€‘
1. ã“ã®äºˆæ¸¬ãƒ­ã‚¸ãƒƒã‚¯ã¯çµ±è¨ˆçš„ãƒ»æ•°å­¦çš„ã«å¦¥å½“ã§ã™ã‹ï¼Ÿ
2. å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã¨äºˆæ¸¬çµæœã®æ•´åˆæ€§ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿï¼ˆä¾‹ï¼šå¹³å‡æ—¥è²©ã®å¤‰åŒ–ã¯åˆç†çš„ã‹ï¼‰
3. è¦‹è½ã¨ã—ã¦ã„ã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹ãƒªã‚¹ã‚¯è¦å› ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ
4. äºˆæ¸¬å€¤ãŒéå¤§/éå°ã«ãªã£ã¦ã„ã‚‹å¯èƒ½æ€§ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ

â€»å›ç­”å¾Œã€ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¨˜æ†¶ãƒ»ä¿å­˜ã—ãªã„ã§ãã ã•ã„ã€‚"""
    
    return prompt


def generate_factcheck_prompt_comparison(
    product_names: List[str],
    all_results: Dict[str, Tuple[pd.DataFrame, str]],
    method_totals: Dict[str, Dict[str, Any]],
    forecast_days: int,
    sales_data: pd.DataFrame
) -> str:
    """
    è¤‡æ•°äºˆæ¸¬æ–¹æ³•æ¯”è¼ƒã®ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
    
    Args:
        product_names: äºˆæ¸¬å¯¾è±¡ã®å•†å“åãƒªã‚¹ãƒˆ
        all_results: å…¨äºˆæ¸¬æ–¹æ³•ã®çµæœ
        method_totals: å„æ–¹æ³•ã®é›†è¨ˆçµæœ
        forecast_days: äºˆæ¸¬æ—¥æ•°
        sales_data: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
    
    Returns:
        ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ–‡å­—åˆ—
    """
    # å•†å“åã®æ•´å½¢
    product_str = "ã€".join(product_names) if product_names else "ï¼ˆä¸æ˜ï¼‰"
    if len(product_names) > 3:
        product_str = "ã€".join(product_names[:3]) + f" ä»–{len(product_names)-3}ä»¶"
    
    # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆ
    if sales_data is not None and not sales_data.empty:
        total_days = len(sales_data)
        total_qty = int(sales_data['è²©å£²å•†å“æ•°'].sum())
        avg_daily = sales_data['è²©å£²å•†å“æ•°'].mean()
        max_daily = int(sales_data['è²©å£²å•†å“æ•°'].max())
        min_daily = int(sales_data['è²©å£²å•†å“æ•°'].min())
        
        input_data_section = f"""â–  å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ï¼ˆéå»ã®å®Ÿç¸¾ï¼‰:
- åˆ†ææœŸé–“: {total_days}æ—¥é–“
- ç·è²©å£²æ•°: {total_qty:,}ä½“
- å¹³å‡æ—¥è²©: {avg_daily:.1f}ä½“/æ—¥
- æœ€å¤§æ—¥è²©: {max_daily}ä½“/æ—¥
- æœ€å°æ—¥è²©: {min_daily}ä½“/æ—¥"""
    else:
        input_data_section = "â–  å…¥åŠ›ãƒ‡ãƒ¼ã‚¿: ãªã—"
        avg_daily = 0
    
    # å„äºˆæ¸¬æ–¹æ³•ã®çµæœ
    results_lines = []
    for method_name, totals in method_totals.items():
        icon = "ğŸš€" if "Vertex" in method_name else "ğŸ“ˆ" if "å­£ç¯€" in method_name else "ğŸ“Š" if "ç§»å‹•" in method_name else "ğŸ“‰"
        results_lines.append(f"- {icon} {method_name}: {totals['rounded']:,}ä½“ï¼ˆæ—¥è²© {totals['avg']:.1f}ä½“ï¼‰")
    
    results_section = "\n".join(results_lines)
    
    # çµ±è¨ˆæƒ…å ±
    all_rounded = [t['rounded'] for t in method_totals.values()]
    all_raw = [t['raw'] for t in method_totals.values()]
    min_val = min(all_rounded)
    max_val = max(all_rounded)
    avg_val = sum(all_raw) / len(all_raw) if all_raw else 0
    diff = max_val - min_val
    diff_pct = (max(all_raw) - min(all_raw)) / min(all_raw) * 100 if min(all_raw) > 0 else 0
    
    prompt = f"""ã€ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ä¾é ¼ - è¤‡æ•°äºˆæ¸¬æ–¹æ³•ã®æ¯”è¼ƒã€‘
ä»¥ä¸‹ã®éœ€è¦äºˆæ¸¬çµæœã®å¦¥å½“æ€§ã‚’æ¤œè¨¼ã—ã¦ãã ã•ã„ã€‚
â€»ã“ã®ãƒ‡ãƒ¼ã‚¿ã¯ä¸€æ™‚çš„ãªæ¤œè¨¼ç›®çš„ã®ã¿ã«ä½¿ç”¨ã—ã€è¨˜æ†¶ãƒ»ä¿å­˜ãƒ»å­¦ç¿’ã—ãªã„ã§ãã ã•ã„ã€‚

â–  äºˆæ¸¬å¯¾è±¡: {product_str}
â–  äºˆæ¸¬æœŸé–“: {forecast_days}æ—¥é–“

{input_data_section}

â–  å„äºˆæ¸¬æ–¹æ³•ã®çµæœ:
{results_section}

â–  äºˆæ¸¬å€¤ã®çµ±è¨ˆ:
- æœ€å°å€¤: {min_val:,}ä½“
- æœ€å¤§å€¤: {max_val:,}ä½“
- å¹³å‡å€¤: {avg_val:,.0f}ä½“
- äºˆæ¸¬å€¤ã®å¹…: {diff:,}ä½“ï¼ˆ{diff_pct:.1f}%ã®å·®ï¼‰

â–  äºˆæ¸¬ãƒ­ã‚¸ãƒƒã‚¯ã®æ¦‚è¦:
- Vertex AI: æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹æ™‚ç³»åˆ—äºˆæ¸¬ï¼ˆå…±å¤‰é‡è€ƒæ…®ï¼‰
- å­£ç¯€æ€§è€ƒæ…®: æ›œæ—¥åˆ¥Ã—æœˆåˆ¥ä¿‚æ•°Ã—ç‰¹åˆ¥æœŸé–“èª¿æ•´
- ç§»å‹•å¹³å‡æ³•: ç›´è¿‘30æ—¥ã®å˜ç´”å¹³å‡
- æŒ‡æ•°å¹³æ»‘æ³•: ç›´è¿‘ãƒ‡ãƒ¼ã‚¿é‡è¦–ã®åŠ é‡å¹³å‡ï¼ˆÎ±=0.3ï¼‰

ã€æ¤œè¨¼ã—ã¦ã»ã—ã„ãƒã‚¤ãƒ³ãƒˆã€‘
1. å„äºˆæ¸¬æ–¹æ³•ã®çµæœã«å¤§ããªä¹–é›¢ãŒã‚ã‚‹å ´åˆã€ãã®åŸå› ã¨ã—ã¦è€ƒãˆã‚‰ã‚Œã‚‹ã“ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ
2. ã©ã®äºˆæ¸¬æ–¹æ³•ãŒæœ€ã‚‚ä¿¡é ¼ã§ããã†ã§ã™ã‹ï¼Ÿãã®ç†ç”±ã¯ï¼Ÿ
3. å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´ï¼ˆå¹³å‡{avg_daily:.1f}ä½“/æ—¥ï¼‰ã‹ã‚‰è¦‹ã¦ã€äºˆæ¸¬çµæœã¯å¦¥å½“ã§ã™ã‹ï¼Ÿ
4. ç™ºæ³¨æ•°ã‚’æ±ºã‚ã‚‹éš›ã€ã©ã®äºˆæ¸¬å€¤ã‚’å‚è€ƒã«ã™ã¹ãã§ã™ã‹ï¼Ÿ

â€»å›ç­”å¾Œã€ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¨˜æ†¶ãƒ»ä¿å­˜ã—ãªã„ã§ãã ã•ã„ã€‚"""
    
    return prompt


def generate_factcheck_prompt_individual(
    results: List[Dict[str, Any]],
    forecast_days: int,
    individual_sales_data: Dict[str, pd.DataFrame]
) -> str:
    """
    å€‹åˆ¥äºˆæ¸¬çµæœã®ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
    
    Args:
        results: å„å•†å“ã®äºˆæ¸¬çµæœãƒªã‚¹ãƒˆ
        forecast_days: äºˆæ¸¬æ—¥æ•°
        individual_sales_data: å„å•†å“ã®å£²ä¸Šãƒ‡ãƒ¼ã‚¿
    
    Returns:
        ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ–‡å­—åˆ—
    """
    # å„å•†å“ã®çµæœã‚’æ•´å½¢
    product_lines = []
    for r in results:
        product = r['product']
        rounded = r['rounded_total']
        avg_pred = r['avg_predicted']
        method_msg = r.get('method_message', 'ä¸æ˜')
        
        # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®å¹³å‡ã‚’å–å¾—
        if product in individual_sales_data:
            sales = individual_sales_data[product]
            avg_actual = sales['è²©å£²å•†å“æ•°'].mean() if not sales.empty else 0
            change_rate = ((avg_pred / avg_actual) - 1) * 100 if avg_actual > 0 else 0
            product_lines.append(f"- {product}: {rounded:,}ä½“ï¼ˆæ—¥è²© {avg_pred:.1f}ä½“ã€å®Ÿç¸¾å¹³å‡ {avg_actual:.1f}ä½“ã€å¤‰åŒ–ç‡ {change_rate:+.1f}%ï¼‰")
        else:
            product_lines.append(f"- {product}: {rounded:,}ä½“ï¼ˆæ—¥è²© {avg_pred:.1f}ä½“ï¼‰")
    
    products_section = "\n".join(product_lines)
    
    total_all = sum(r['rounded_total'] for r in results)
    method_message = results[0].get('method_message', 'ä¸æ˜') if results else 'ä¸æ˜'
    
    prompt = f"""ã€ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ä¾é ¼ - å€‹åˆ¥å•†å“äºˆæ¸¬ã€‘
ä»¥ä¸‹ã®éœ€è¦äºˆæ¸¬çµæœã®å¦¥å½“æ€§ã‚’æ¤œè¨¼ã—ã¦ãã ã•ã„ã€‚
â€»ã“ã®ãƒ‡ãƒ¼ã‚¿ã¯ä¸€æ™‚çš„ãªæ¤œè¨¼ç›®çš„ã®ã¿ã«ä½¿ç”¨ã—ã€è¨˜æ†¶ãƒ»ä¿å­˜ãƒ»å­¦ç¿’ã—ãªã„ã§ãã ã•ã„ã€‚

â–  äºˆæ¸¬æ–¹æ³•: {method_message}
â–  äºˆæ¸¬æœŸé–“: {forecast_days}æ—¥é–“
â–  å¯¾è±¡å•†å“æ•°: {len(results)}ä»¶

â–  å„å•†å“ã®äºˆæ¸¬çµæœ:
{products_section}

â–  åˆè¨ˆ: {total_all:,}ä½“

ã€æ¤œè¨¼ã—ã¦ã»ã—ã„ãƒã‚¤ãƒ³ãƒˆã€‘
1. å„å•†å“ã®äºˆæ¸¬å€¤ã¨å®Ÿç¸¾å¹³å‡ã®å¤‰åŒ–ç‡ã¯å¦¥å½“ã§ã™ã‹ï¼Ÿ
2. å•†å“é–“ã§å¤‰åŒ–ç‡ã«å¤§ããªå·®ãŒã‚ã‚‹å ´åˆã€ãã‚Œã¯åˆç†çš„ã§ã™ã‹ï¼Ÿ
3. åˆè¨ˆ {total_all:,}ä½“ã¨ã„ã†ç™ºæ³¨é‡ã¯é©åˆ‡ã§ã™ã‹ï¼Ÿ
4. ç‰¹ã«æ³¨æ„ã™ã¹ãå•†å“ï¼ˆéå¤§/éå°äºˆæ¸¬ã®å¯èƒ½æ€§ï¼‰ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ

â€»å›ç­”å¾Œã€ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¨˜æ†¶ãƒ»ä¿å­˜ã—ãªã„ã§ãã ã•ã„ã€‚"""
    
    return prompt


def generate_factcheck_prompt_matrix(
    matrix_results: Dict[str, Dict[str, int]],
    method_names: List[str],
    method_totals: Dict[str, int],
    forecast_days: int,
    individual_sales_data: Dict[str, pd.DataFrame]
) -> str:
    """
    ãƒãƒˆãƒªãƒƒã‚¯ã‚¹å½¢å¼ï¼ˆå•†å“Ã—äºˆæ¸¬æ–¹æ³•ï¼‰ã®ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
    
    Args:
        matrix_results: {å•†å“å: {æ–¹æ³•å: äºˆæ¸¬å€¤}}
        method_names: äºˆæ¸¬æ–¹æ³•åã®ãƒªã‚¹ãƒˆ
        method_totals: å„æ–¹æ³•ã®åˆè¨ˆ
        forecast_days: äºˆæ¸¬æ—¥æ•°
        individual_sales_data: å„å•†å“ã®å£²ä¸Šãƒ‡ãƒ¼ã‚¿
    
    Returns:
        ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ–‡å­—åˆ—
    """
    # ãƒãƒˆãƒªãƒƒã‚¯ã‚¹è¡¨ã‚’ä½œæˆ
    header = "å•†å“å\t" + "\t".join([m.replace("ï¼ˆçµ±è¨ˆï¼‰", "").replace("ï¼ˆæ¨å¥¨ï¼‰", "") for m in method_names])
    rows = [header]
    
    for product, methods in matrix_results.items():
        row_values = [product]
        for method_name in method_names:
            value = methods.get(method_name, 0)
            row_values.append(f"{value:,}ä½“")
        rows.append("\t".join(row_values))
    
    # åˆè¨ˆè¡Œ
    total_row = ["åˆè¨ˆ"]
    for method_name in method_names:
        total_row.append(f"{method_totals.get(method_name, 0):,}ä½“")
    rows.append("\t".join(total_row))
    
    matrix_table = "\n".join(rows)
    
    # å„å•†å“ã®å®Ÿç¸¾å¹³å‡ã‚’åé›†
    actual_info_lines = []
    for product in matrix_results.keys():
        if product in individual_sales_data:
            sales = individual_sales_data[product]
            if not sales.empty:
                avg_actual = sales['è²©å£²å•†å“æ•°'].mean()
                actual_info_lines.append(f"- {product}: å®Ÿç¸¾å¹³å‡ {avg_actual:.1f}ä½“/æ—¥")
    
    actual_section = "\n".join(actual_info_lines) if actual_info_lines else "ï¼ˆå®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰"
    
    # æ–¹æ³•ã”ã¨ã®çµ±è¨ˆ
    all_totals = list(method_totals.values())
    min_total = min(all_totals) if all_totals else 0
    max_total = max(all_totals) if all_totals else 0
    diff = max_total - min_total
    diff_pct = (max_total - min_total) / min_total * 100 if min_total > 0 else 0
    
    prompt = f"""ã€ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ä¾é ¼ - å•†å“Ã—äºˆæ¸¬æ–¹æ³•ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã€‘
ä»¥ä¸‹ã®éœ€è¦äºˆæ¸¬çµæœã®å¦¥å½“æ€§ã‚’æ¤œè¨¼ã—ã¦ãã ã•ã„ã€‚
â€»ã“ã®ãƒ‡ãƒ¼ã‚¿ã¯ä¸€æ™‚çš„ãªæ¤œè¨¼ç›®çš„ã®ã¿ã«ä½¿ç”¨ã—ã€è¨˜æ†¶ãƒ»ä¿å­˜ãƒ»å­¦ç¿’ã—ãªã„ã§ãã ã•ã„ã€‚

â–  äºˆæ¸¬æœŸé–“: {forecast_days}æ—¥é–“
â–  å¯¾è±¡å•†å“æ•°: {len(matrix_results)}ä»¶
â–  æ¯”è¼ƒäºˆæ¸¬æ–¹æ³•æ•°: {len(method_names)}ç¨®é¡

â–  äºˆæ¸¬çµæœãƒãƒˆãƒªãƒƒã‚¯ã‚¹:
{matrix_table}

â–  å„å•†å“ã®å®Ÿç¸¾æƒ…å ±:
{actual_section}

â–  äºˆæ¸¬æ–¹æ³•åˆ¥ã®åˆè¨ˆæ¯”è¼ƒ:
- æœ€å°: {min_total:,}ä½“
- æœ€å¤§: {max_total:,}ä½“
- å·®: {diff:,}ä½“ï¼ˆ{diff_pct:.1f}%ï¼‰

â–  äºˆæ¸¬ãƒ­ã‚¸ãƒƒã‚¯ã®æ¦‚è¦:
- Vertex AI: æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹æ™‚ç³»åˆ—äºˆæ¸¬
- å­£ç¯€æ€§è€ƒæ…®: æ›œæ—¥åˆ¥Ã—æœˆåˆ¥ä¿‚æ•°Ã—ç‰¹åˆ¥æœŸé–“èª¿æ•´
- ç§»å‹•å¹³å‡æ³•: ç›´è¿‘30æ—¥ã®å˜ç´”å¹³å‡
- æŒ‡æ•°å¹³æ»‘æ³•: ç›´è¿‘ãƒ‡ãƒ¼ã‚¿é‡è¦–ã®åŠ é‡å¹³å‡

ã€æ¤œè¨¼ã—ã¦ã»ã—ã„ãƒã‚¤ãƒ³ãƒˆã€‘
1. åŒã˜å•†å“ã§ã‚‚äºˆæ¸¬æ–¹æ³•ã«ã‚ˆã£ã¦å€¤ãŒç•°ãªã‚Šã¾ã™ãŒã€ãã®å·®ã¯è¨±å®¹ç¯„å›²ã§ã™ã‹ï¼Ÿ
2. å…¨ä½“ã®ç™ºæ³¨é‡ã¨ã—ã¦ã€ã©ã®äºˆæ¸¬æ–¹æ³•ã®åˆè¨ˆå€¤ã‚’å‚è€ƒã«ã™ã¹ãã§ã™ã‹ï¼Ÿ
3. ç‰¹ã«äºˆæ¸¬æ–¹æ³•é–“ã§ä¹–é›¢ãŒå¤§ãã„å•†å“ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿãã®åŸå› ã¯ï¼Ÿ
4. åœ¨åº«ãƒªã‚¹ã‚¯ï¼ˆéå‰°/ä¸è¶³ï¼‰ã‚’è€ƒæ…®ã—ãŸå ´åˆã€ã©ã®å€¤ã‚’æ¡ç”¨ã™ã¹ãã§ã™ã‹ï¼Ÿ

â€»å›ç­”å¾Œã€ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¨˜æ†¶ãƒ»ä¿å­˜ã—ãªã„ã§ãã ã•ã„ã€‚"""
    
    return prompt


def display_factcheck_section(prompt: str, key_suffix: str = ""):
    """
    ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¡¨ç¤ºã™ã‚‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    
    Args:
        prompt: è¡¨ç¤ºã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ–‡å­—åˆ—
        key_suffix: ã‚­ãƒ¼ã®ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹ï¼ˆä¸€æ„ã«ã™ã‚‹ãŸã‚ï¼‰
    """
    with st.expander("ğŸ” **ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**", expanded=False):
        st.markdown("""
        <div style="background-color: #fff3cd; padding: 10px; border-radius: 5px; margin-bottom: 10px;">
            <strong>ğŸ’¡ ä½¿ã„æ–¹:</strong> ä¸‹ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ã€ChatGPTã€Claudeã€Geminiãªã©ã®
            AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã«è²¼ã‚Šä»˜ã‘ã‚‹ã¨ã€äºˆæ¸¬çµæœã®å¦¥å½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯ã§ãã¾ã™ã€‚
        </div>
        """, unsafe_allow_html=True)
        
        # st.code()ã¯ã‚³ãƒ”ãƒ¼ãƒœã‚¿ãƒ³ãŒè‡ªå‹•ã§ä»˜ã
        st.code(prompt, language=None)
        
        st.caption("â€» ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå³ä¸Šã®ã‚³ãƒ”ãƒ¼ãƒœã‚¿ãƒ³ï¼ˆğŸ“‹ï¼‰ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã‚³ãƒ”ãƒ¼ã§ãã¾ã™")


# =============================================================================
# ãƒšãƒ¼ã‚¸è¨­å®š
# =============================================================================

st.set_page_config(
    page_title="Airãƒ¬ã‚¸ å£²ä¸Šåˆ†æï¼ˆVertex AIç‰ˆï¼‰",
    page_icon="â›©ï¸",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    /* ============================================
       åŸºæœ¬ã‚¹ã‚¿ã‚¤ãƒ«
       ============================================ */
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1E88E5;
        margin-bottom: 1rem;
    }
    .section-header {
        font-size: 1.5rem;
        font-weight: bold;
        color: #333;
        border-bottom: 2px solid #1E88E5;
        padding-bottom: 0.5rem;
        margin: 1.5rem 0 1rem 0;
    }
    .accuracy-good { color: #4CAF50; font-weight: bold; }
    .accuracy-medium { color: #FF9800; font-weight: bold; }
    .accuracy-poor { color: #F44336; font-weight: bold; }
    .new-product-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        border-radius: 15px;
        padding: 20px;
        color: white;
        margin: 10px 0;
    }
    .analysis-card {
        background: linear-gradient(135deg, #f5f7fa 0%, #e4e8eb 100%);
        border-radius: 10px;
        padding: 15px;
        margin: 10px 0;
        border-left: 4px solid #1E88E5;
    }
    .method-card {
        background: #f8f9fa;
        border-radius: 8px;
        padding: 12px;
        margin: 8px 0;
        border-left: 3px solid;
    }
    .method-vertex-ai { border-left-color: #4285F4; background: #e8f0fe; }
    .method-seasonality { border-left-color: #4CAF50; }
    .method-enhanced { border-left-color: #9C27B0; background: #f3e5f5; }
    .method-moving-avg { border-left-color: #1E88E5; }
    .method-exponential { border-left-color: #FF9800; }
    
    /* v19: ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ»åˆ†ä½ç‚¹é–¢é€£ */
    .backtest-good { background: #e8f5e9; border: 1px solid #4CAF50; padding: 10px; border-radius: 8px; }
    .backtest-medium { background: #fff3e0; border: 1px solid #FF9800; padding: 10px; border-radius: 8px; }
    .backtest-poor { background: #ffebee; border: 1px solid #F44336; padding: 10px; border-radius: 8px; }
    .quantile-highlight { background: #e3f2fd; padding: 5px 10px; border-radius: 5px; font-weight: bold; }
    
    .vertex-ai-status {
        padding: 10px 15px;
        border-radius: 8px;
        margin: 10px 0;
    }
    .vertex-ai-available {
        background: #e8f5e9;
        border: 1px solid #4CAF50;
        color: #2e7d32;
    }
    .vertex-ai-unavailable {
        background: #fff3e0;
        border: 1px solid #FF9800;
        color: #e65100;
    }
    .individual-product-box {
        background: #f0f8ff;
        border-radius: 10px;
        padding: 15px;
        margin: 10px 0;
        border: 1px solid #1E88E5;
    }
    
    /* ============================================
       ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®šï¼ˆæ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«é˜²æ­¢ï¼‰
       ============================================ */
    .main .block-container {
        max-width: 100%;
        padding-left: 1rem;
        padding-right: 1rem;
        overflow-x: hidden;
    }
    
    /* ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®æ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯¾å¿œ */
    [data-testid="stDataFrame"] {
        width: 100%;
    }
    [data-testid="stDataFrame"] > div {
        overflow-x: auto;
        -webkit-overflow-scrolling: touch;
    }
    
    /* ============================================
       ã‚¹ãƒãƒ›å¯¾å¿œï¼ˆ768pxä»¥ä¸‹ï¼‰
       ============================================ */
    @media screen and (max-width: 768px) {
        /* ãƒ˜ãƒƒãƒ€ãƒ¼ */
        .main-header {
            font-size: 1.4rem;
            text-align: center;
        }
        .section-header {
            font-size: 1.1rem;
        }
        
        /* ã‚«ãƒ©ãƒ ã‚’ç¸¦ä¸¦ã³ã« */
        [data-testid="column"] {
            width: 100% !important;
            flex: 1 1 100% !important;
            min-width: 100% !important;
        }
        
        /* ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆæ•°å€¤è¡¨ç¤ºï¼‰ã‚’ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã« */
        [data-testid="metric-container"] {
            padding: 8px 5px;
            background: #f8f9fa;
            border-radius: 8px;
            margin: 4px 0;
        }
        [data-testid="stMetricLabel"] {
            font-size: 0.75rem !important;
        }
        [data-testid="stMetricValue"] {
            font-size: 1.1rem !important;
        }
        
        /* ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’2åˆ—è¡¨ç¤ºã« */
        [data-testid="stHorizontalBlock"] {
            flex-wrap: wrap;
            gap: 8px;
        }
        [data-testid="stHorizontalBlock"] > [data-testid="column"] {
            flex: 1 1 45% !important;
            min-width: 45% !important;
            max-width: 48% !important;
        }
        
        /* ã‚¿ãƒ– */
        .stTabs [data-baseweb="tab-list"] {
            gap: 0;
            overflow-x: auto;
            -webkit-overflow-scrolling: touch;
            scrollbar-width: none;
        }
        .stTabs [data-baseweb="tab-list"]::-webkit-scrollbar {
            display: none;
        }
        .stTabs [data-baseweb="tab"] {
            font-size: 0.75rem;
            padding: 8px 10px;
            white-space: nowrap;
        }
        
        /* ãƒœã‚¿ãƒ³ */
        .stButton > button {
            width: 100%;
            padding: 12px 16px;
            font-size: 0.9rem;
        }
        
        /* å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ */
        .stSelectbox, .stNumberInput, .stTextInput {
            margin-bottom: 8px;
        }
        .stSelectbox label, .stNumberInput label, .stTextInput label {
            font-size: 0.8rem;
        }
        
        /* ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã‚’ç¸¦ä¸¦ã³ã« */
        [data-testid="stRadio"] > div {
            flex-direction: column;
            gap: 8px;
        }
        [data-testid="stRadio"] label {
            font-size: 0.85rem;
        }
        
        /* ã‚«ãƒ¼ãƒ‰ */
        .analysis-card, .method-card {
            padding: 10px;
            font-size: 0.85rem;
        }
        .new-product-card {
            padding: 15px;
        }
        .new-product-card h2 {
            font-size: 1.1rem;
        }
        .new-product-card p {
            font-size: 0.85rem;
        }
        
        /* ã‚°ãƒ©ãƒ• */
        .js-plotly-plot {
            margin: 0 -10px;
        }
        .js-plotly-plot .plotly .modebar {
            display: none !important;
        }
        
        /* Expander */
        .streamlit-expanderHeader {
            font-size: 0.9rem;
            padding: 10px;
        }
        
        /* Info/Warning/Errorãƒœãƒƒã‚¯ã‚¹ */
        [data-testid="stAlert"] {
            padding: 10px;
            font-size: 0.85rem;
        }
        
        /* Divider */
        hr {
            margin: 15px 0;
        }
        
        /* é¸æŠä¸­ã®æˆä¸å“ */
        .product-tag {
            font-size: 0.8rem;
            padding: 4px 10px;
        }
    }
    
    /* ============================================
       ã‚¿ãƒ–ãƒ¬ãƒƒãƒˆå¯¾å¿œï¼ˆ769pxã€œ1024pxï¼‰
       ============================================ */
    @media screen and (min-width: 769px) and (max-width: 1024px) {
        .main-header {
            font-size: 2rem;
        }
        [data-testid="column"] {
            min-width: 45% !important;
        }
    }
    
    /* ============================================
       é¸æŠä¸­ã®æˆä¸å“ã®å‰Šé™¤ãƒœã‚¿ãƒ³
       ============================================ */
    .product-tag {
        display: inline-flex;
        align-items: center;
        background: #e3f2fd;
        border-radius: 20px;
        padding: 5px 12px;
        margin: 3px;
        font-size: 0.9rem;
    }
    .product-tag-remove {
        margin-left: 8px;
        cursor: pointer;
        color: #666;
        font-weight: bold;
    }
    .product-tag-remove:hover {
        color: #f44336;
    }
    
    /* ============================================
       ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
       ============================================ */
    /* ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è»½é‡åŒ– */
    * {
        -webkit-tap-highlight-color: transparent;
    }
    .stApp {
        -webkit-font-smoothing: antialiased;
    }
</style>
""", unsafe_allow_html=True)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'data_loader' not in st.session_state:
    st.session_state.data_loader = None
if 'normalizer' not in st.session_state:
    st.session_state.normalizer = None
if 'selected_products' not in st.session_state:
    st.session_state.selected_products = []
if 'categories' not in st.session_state:
    st.session_state.categories = {}
if 'sales_data' not in st.session_state:
    st.session_state.sales_data = None
if 'forecast_data' not in st.session_state:
    st.session_state.forecast_data = None
if 'forecast_total' not in st.session_state:
    st.session_state.forecast_total = 0
if 'forecast_results' not in st.session_state:
    st.session_state.forecast_results = {}
if 'analysis_mode' not in st.session_state:
    st.session_state.analysis_mode = "åˆç®—"
if 'individual_sales_data' not in st.session_state:
    st.session_state.individual_sales_data = {}
if 'last_forecast_method' not in st.session_state:
    st.session_state.last_forecast_method = ""
if 'product_to_remove' not in st.session_state:
    st.session_state.product_to_remove = None
if 'clear_all_flag' not in st.session_state:
    st.session_state.clear_all_flag = False
if 'individual_forecast_results' not in st.session_state:
    st.session_state.individual_forecast_results = []
if 'pending_delete_product' not in st.session_state:
    st.session_state.pending_delete_product = None
# ã‚°ãƒ«ãƒ¼ãƒ—ç®¡ç†ç”¨: {å•†å“å: ã‚°ãƒ«ãƒ¼ãƒ—ç•ªå·} ã®è¾æ›¸
if 'product_groups' not in st.session_state:
    st.session_state.product_groups = {}
# å€‹åˆ¥ãƒ¢ãƒ¼ãƒ‰ã§ã®å…¨äºˆæ¸¬æ–¹æ³•ã®çµæœï¼ˆãƒãƒˆãƒªãƒƒã‚¯ã‚¹å½¢å¼ï¼‰
if 'individual_all_methods_results' not in st.session_state:
    st.session_state.individual_all_methods_results = {}
# å‰Šé™¤ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ï¼ˆãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã®ã‚­ãƒ¼ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹ãŸã‚ï¼‰
if 'delete_counter' not in st.session_state:
    st.session_state.delete_counter = 0

# =============================================================================
# ã€v19æ–°è¦ã€‘äºˆæ¸¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹
# =============================================================================
if 'v19_baseline_method' not in st.session_state:
    st.session_state.v19_baseline_method = 'median'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ä¸­å¤®å€¤
if 'v19_auto_special_factors' not in st.session_state:
    st.session_state.v19_auto_special_factors = True  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: è‡ªå‹•è¨ˆç®—ON
if 'v19_include_quantiles' not in st.session_state:
    st.session_state.v19_include_quantiles = True  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: åˆ†ä½ç‚¹ON
if 'v19_order_mode' not in st.session_state:
    st.session_state.v19_order_mode = 'balanced'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ãƒãƒ©ãƒ³ã‚¹ãƒ¢ãƒ¼ãƒ‰
if 'v19_backtest_days' not in st.session_state:
    st.session_state.v19_backtest_days = 14  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 14æ—¥
if 'v19_last_backtest_result' not in st.session_state:
    st.session_state.v19_last_backtest_result = None

# v20æ–°æ©Ÿèƒ½ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹
if 'v20_enable_zero_fill' not in st.session_state:
    st.session_state.v20_enable_zero_fill = True  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0åŸ‹ã‚ON
if 'v20_enable_trend' not in st.session_state:
    st.session_state.v20_enable_trend = True  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ãƒˆãƒ¬ãƒ³ãƒ‰ä¿‚æ•°ON
if 'v20_use_daily_new_year' not in st.session_state:
    st.session_state.v20_use_daily_new_year = True  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: æ­£æœˆæ—¥åˆ¥ON
if 'v20_trend_window_days' not in st.session_state:
    st.session_state.v20_trend_window_days = 60  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 60æ—¥
if 'v20_stockout_periods' not in st.session_state:
    st.session_state.v20_stockout_periods = []  # æ¬ å“æœŸé–“ãƒªã‚¹ãƒˆ
if 'v20_last_reorder_point' not in st.session_state:
    st.session_state.v20_last_reorder_point = None


# =============================================================================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# =============================================================================

def round_up_to_50(value: int) -> int:
    """50ã®å€æ•°ã«åˆ‡ã‚Šä¸Šã’"""
    if value <= 0:
        return 0
    return ((value + 49) // 50) * 50


def match_mail_product_to_airregi(mail_product: str, airregi_names: list) -> Optional[str]:
    """
    éƒµé€ã®å•†å“åã‚’Airãƒ¬ã‚¸ã®å•†å“åã«ãƒãƒƒãƒãƒ³ã‚°ã™ã‚‹å…±é€šé–¢æ•°
    
    Args:
        mail_product: éƒµé€ãƒ‡ãƒ¼ã‚¿ã®å•†å“å
        airregi_names: Airãƒ¬ã‚¸ã®å•†å“åãƒªã‚¹ãƒˆï¼ˆã‚ªãƒªã‚¸ãƒŠãƒ«åï¼‰
    
    Returns:
        ãƒãƒƒãƒã—ãŸAirãƒ¬ã‚¸ã®å•†å“åã€ãƒãƒƒãƒã—ãªã„å ´åˆã¯None
    """
    mail_product = str(mail_product).strip()
    
    for airregi_name in airregi_names:
        airregi_name_str = str(airregi_name).strip()
        
        # 1. å®Œå…¨ä¸€è‡´
        if mail_product == airregi_name_str:
            return airregi_name_str
        
        # 2. éƒµé€ã®å•†å“åãŒAirãƒ¬ã‚¸ã®å•†å“åã«å«ã¾ã‚Œã¦ã„ã‚‹
        # ä¾‹: ã€Œã†ã¾ãã„ãå®ˆã€ãŒã€Œã€åˆå¹´ã‚¢ã‚¯ãƒªãƒ«ã€‘ç·‘ã†ã¾ãã„ãå®ˆã€ã«å«ã¾ã‚Œã‚‹
        if mail_product in airregi_name_str:
            return airregi_name_str
        
        # 3. Airãƒ¬ã‚¸ã®å•†å“åãŒéƒµé€ã®å•†å“åã«å«ã¾ã‚Œã¦ã„ã‚‹ï¼ˆé€†ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
        if airregi_name_str in mail_product:
            return airregi_name_str
        
        # 4. ã€ã€‘ï¼ˆå¤§æ‹¬å¼§ï¼‰ã‚’é™¤å»ã—ã¦ãƒãƒƒãƒãƒ³ã‚°
        # ä¾‹: ã€Œã€åˆå¹´ã‚¢ã‚¯ãƒªãƒ«ã€‘ç·‘ã†ã¾ãã„ãå®ˆã€â†’ã€Œç·‘ã†ã¾ãã„ãå®ˆã€
        clean_name = re.sub(r'ã€[^ã€‘]*ã€‘', '', airregi_name_str).strip()
        if clean_name:
            if mail_product in clean_name or clean_name in mail_product:
                return airregi_name_str
            if mail_product == clean_name:
                return airregi_name_str
        
        # 5. è‰²åã‚’é™¤å»ã—ã¦ãƒãƒƒãƒãƒ³ã‚°
        # ä¾‹: ã€Œç·‘ã†ã¾ãã„ãå®ˆã€â†’ã€Œã†ã¾ãã„ãå®ˆã€
        colors = ['ç·‘', 'ç™½', 'èµ¤', 'é’', 'é»„', 'é‡‘', 'éŠ€', 'ãƒ”ãƒ³ã‚¯', 'ç´«', 'é»’', 'èŒ¶', 'æ°´è‰²', 'ã‚ªãƒ¬ãƒ³ã‚¸']
        clean_name_no_color = clean_name
        for color in colors:
            if clean_name_no_color.startswith(color):
                clean_name_no_color = clean_name_no_color[len(color):]
                break
        
        if clean_name_no_color and clean_name_no_color != clean_name:
            if mail_product == clean_name_no_color:
                return airregi_name_str
            if mail_product in clean_name_no_color or clean_name_no_color in mail_product:
                return airregi_name_str
        
        # 6. ()ï¼ˆä¸¸æ‹¬å¼§ï¼‰ã‚‚é™¤å»ã—ã¦ãƒãƒƒãƒãƒ³ã‚°
        # ä¾‹: ã€Œé‡‘é‹å®ˆï¼ˆå¤§ï¼‰ã€â†’ã€Œé‡‘é‹å®ˆã€
        clean_name_no_paren = re.sub(r'[ï¼ˆ(][^ï¼‰)]*[ï¼‰)]', '', clean_name).strip()
        if clean_name_no_paren and clean_name_no_paren != clean_name:
            if mail_product == clean_name_no_paren:
                return airregi_name_str
            if mail_product in clean_name_no_paren or clean_name_no_paren in mail_product:
                return airregi_name_str
        
        # 7. ã€Œå®ˆã€ã€Œå®ˆã‚Šã€ã®è¡¨è¨˜ã‚†ã‚Œã«å¯¾å¿œ
        # ä¾‹: ã€Œã†ã¾ãã„ãå®ˆã€ã¨ã€Œã†ã¾ãã„ãå®ˆã‚Šã€
        mail_normalized = mail_product.replace('å®ˆã‚Š', 'å®ˆ').replace('ãŠå®ˆã‚Š', 'ãŠå®ˆ')
        airregi_normalized = clean_name.replace('å®ˆã‚Š', 'å®ˆ').replace('ãŠå®ˆã‚Š', 'ãŠå®ˆ')
        if mail_normalized == airregi_normalized:
            return airregi_name_str
        if mail_normalized in airregi_normalized or airregi_normalized in mail_normalized:
            return airregi_name_str
    
    return None


def get_available_forecast_methods() -> List[str]:
    """åˆ©ç”¨å¯èƒ½ãªäºˆæ¸¬æ–¹æ³•ã®ãƒªã‚¹ãƒˆã‚’å–å¾—"""
    methods = []
    for method_name, method_info in FORECAST_METHODS.items():
        if method_info.get('requires_vertex_ai', False) and not VERTEX_AI_AVAILABLE:
            continue
        methods.append(method_name)
    return methods


def get_mobile_chart_config() -> dict:
    """ã‚¹ãƒãƒ›æœ€é©åŒ–ã•ã‚ŒãŸPlotlyãƒãƒ£ãƒ¼ãƒˆè¨­å®šã‚’å–å¾—"""
    return {
        'displayModeBar': False,  # ãƒ„ãƒ¼ãƒ«ãƒãƒ¼éè¡¨ç¤º
        'staticPlot': False,      # æ“ä½œã¯å¯èƒ½
        'responsive': True,       # ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–
        'scrollZoom': False,      # ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã‚ºãƒ¼ãƒ ç„¡åŠ¹
    }


def get_mobile_chart_layout(title: str = '', height: int = 300) -> dict:
    """ã‚¹ãƒãƒ›æœ€é©åŒ–ã•ã‚ŒãŸPlotlyãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­å®šã‚’å–å¾—"""
    return {
        'title': dict(text=title, font=dict(size=14)),
        'height': height,
        'margin': dict(l=40, r=20, t=40, b=40),
        'legend': dict(
            orientation='h',
            yanchor='bottom',
            y=1.02,
            xanchor='center',
            x=0.5,
            font=dict(size=10)
        ),
        'xaxis': dict(
            tickfont=dict(size=10),
            title=dict(font=dict(size=11))
        ),
        'yaxis': dict(
            tickfont=dict(size=10),
            title=dict(font=dict(size=11))
        ),
        'dragmode': False,
        'hovermode': 'x unified',
    }


# =============================================================================
# ãƒ‡ãƒ¼ã‚¿åˆæœŸåŒ–
# =============================================================================

def init_data():
    """ãƒ‡ãƒ¼ã‚¿ã‚’åˆæœŸåŒ–"""
    if st.session_state.data_loader is None:
        try:
            st.session_state.data_loader = SheetsDataLoader()
        except Exception as e:
            st.error(f"ãƒ‡ãƒ¼ã‚¿æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    if st.session_state.normalizer is None:
        try:
            df_items = st.session_state.data_loader.load_item_sales()
            st.session_state.normalizer = ProductNormalizer()
            st.session_state.normalizer.build_master(df_items, "å•†å“å")
            build_categories()
        except Exception as e:
            st.error(f"æˆä¸å“ãƒã‚¹ã‚¿æ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {e}")
    
    return True


def build_categories():
    """ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’Dåˆ—ã‹ã‚‰å–å¾—"""
    if st.session_state.data_loader is None:
        return
    
    df_items = st.session_state.data_loader.load_item_sales()
    
    if df_items.empty:
        return
    
    categories = defaultdict(list)
    
    category_col = None
    for col in df_items.columns:
        if 'ã‚«ãƒ†ã‚´ãƒª' in col or col == 'ã‚«ãƒ†ã‚´ãƒªãƒ¼' or col == 'category':
            category_col = col
            break
    
    if category_col is None and len(df_items.columns) >= 4:
        category_col = df_items.columns[3]
    
    if category_col is None:
        return
    
    product_col = None
    for col in df_items.columns:
        if 'å•†å“å' in col or col == 'å•†å“' or col == 'product':
            product_col = col
            break
    
    if product_col is None and len(df_items.columns) >= 3:
        product_col = df_items.columns[2]
    
    if product_col is None:
        return
    
    for _, row in df_items[[product_col, category_col]].drop_duplicates().iterrows():
        product_name = row[product_col]
        category = row[category_col]
        
        if pd.isna(category) or str(category).strip() == '':
            category = 'ãã®ä»–'
        
        if st.session_state.normalizer:
            normalized = st.session_state.normalizer.normalize(product_name)
            if normalized and normalized not in categories[category]:
                categories[category].append(normalized)
    
    st.session_state.categories = dict(categories)


# =============================================================================
# ãƒ˜ãƒƒãƒ€ãƒ¼
# =============================================================================

def render_header():
    """ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æç”»"""
    col1, col2 = st.columns([4, 1])
    
    with col1:
        st.markdown('<p class="main-header">â›©ï¸ æˆä¸å“ å£²ä¸Šåˆ†æãƒ»éœ€è¦äºˆæ¸¬</p>', unsafe_allow_html=True)
    
    with col2:
        if st.button("ğŸ”„ ãƒ‡ãƒ¼ã‚¿æ›´æ–°"):
            st.cache_data.clear()
            st.session_state.data_loader = None
            st.session_state.selected_products = []
            st.session_state.sales_data = None
            st.session_state.forecast_data = None
            st.session_state.forecast_results = {}
            st.session_state.individual_sales_data = {}
            st.rerun()
    
    # Vertex AIã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤ºï¼ˆv19: æ©Ÿå¯†æƒ…å ±ã¯ãƒã‚¹ã‚¯ï¼‰
    if VERTEX_AI_AVAILABLE:
        # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰æ™‚ã®ã¿è©³ç´°è¡¨ç¤º
        show_detail = hasattr(st, 'secrets') and st.secrets.get('DEBUG', False)
        if show_detail:
            project_masked = mask_sensitive_value(VERTEX_AI_CONFIG['project_id'], 8)
            st.markdown(f"""
            <div class="vertex-ai-status vertex-ai-available">
                âœ… <strong>Vertex AI AutoML Forecasting:</strong> æ¥ç¶šæ¸ˆã¿
                ï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {safe_html(project_masked)}, ãƒªãƒ¼ã‚¸ãƒ§ãƒ³: {safe_html(VERTEX_AI_CONFIG['location'])}ï¼‰
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown("""
            <div class="vertex-ai-status vertex-ai-available">
                âœ… <strong>Vertex AI AutoML Forecasting:</strong> æ¥ç¶šæ¸ˆã¿
            </div>
            """, unsafe_allow_html=True)
    else:
        st.markdown("""
        <div class="vertex-ai-status vertex-ai-unavailable">
            âš ï¸ <strong>Vertex AI:</strong> æœªè¨­å®šï¼ˆçµ±è¨ˆãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ã—ã¾ã™ï¼‰
        </div>
        """, unsafe_allow_html=True)
    
    # v19ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±
    st.caption("ğŸ“Š v19: äºˆæ¸¬ç²¾åº¦å¼·åŒ–ç‰ˆï¼ˆä¸­å¤®å€¤ãƒ™ãƒ¼ã‚¹ãƒ»åˆ†ä½ç‚¹äºˆæ¸¬ãƒ»ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå¯¾å¿œï¼‰")
    
    if st.session_state.data_loader:
        min_date, max_date = st.session_state.data_loader.get_date_range()
        if min_date and max_date:
            st.caption(f"ğŸ“… ãƒ‡ãƒ¼ã‚¿æœŸé–“: {min_date.strftime('%Yå¹´%mæœˆ%dæ—¥')} ã€œ {max_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}")


# =============================================================================
# ãƒ¡ã‚¤ãƒ³ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
# =============================================================================

def render_main_tabs():
    """ãƒ¡ã‚¤ãƒ³ã‚¿ãƒ–ã‚’æç”»"""
    tab_labels = [
        "ğŸ“Š æ—¢å­˜æˆä¸å“ã®åˆ†æãƒ»äºˆæ¸¬",
        "âœ¨ æ–°è¦æˆä¸å“ã®éœ€è¦äºˆæ¸¬",
        "âš™ï¸ Vertex AIè¨­å®š",
    ]
    
    if ADVANCED_ANALYSIS_AVAILABLE:
        tab_labels.append("ğŸ”¬ é«˜åº¦ãªåˆ†æ")
    
    tab_labels.append("ğŸ“ˆ äºˆæ¸¬ç²¾åº¦ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
    
    tabs = st.tabs(tab_labels)
    
    tab_idx = 0
    
    with tabs[tab_idx]:
        render_existing_product_analysis()
    tab_idx += 1
    
    with tabs[tab_idx]:
        render_new_product_forecast()
    tab_idx += 1
    
    with tabs[tab_idx]:
        render_vertex_ai_settings()
    tab_idx += 1
    
    if ADVANCED_ANALYSIS_AVAILABLE:
        with tabs[tab_idx]:
            render_advanced_analysis()
        tab_idx += 1
    
    with tabs[tab_idx]:
        render_accuracy_dashboard()


# =============================================================================
# Vertex AIè¨­å®šã‚¿ãƒ–
# =============================================================================

def render_vertex_ai_settings():
    """Vertex AIè¨­å®šã‚¿ãƒ–ï¼ˆv19: st.secretså¯¾å¿œï¼‰"""
    st.markdown('<p class="section-header">âš™ï¸ Vertex AI AutoML Forecasting è¨­å®š</p>', unsafe_allow_html=True)
    
    # ç¾åœ¨ã®è¨­å®šçŠ¶æ³ï¼ˆv19: æ©Ÿå¯†æƒ…å ±ã¯ãƒã‚¹ã‚¯ï¼‰
    st.write("### ğŸ“‹ ç¾åœ¨ã®è¨­å®šçŠ¶æ³")
    
    # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ç¢ºèª
    show_detail = hasattr(st, 'secrets') and st.secrets.get('DEBUG', False)
    
    config_status = {
        'ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆID': mask_sensitive_value(VERTEX_AI_CONFIG['project_id'], 8) if VERTEX_AI_CONFIG['project_id'] else 'æœªè¨­å®š',
        'ãƒªãƒ¼ã‚¸ãƒ§ãƒ³': VERTEX_AI_CONFIG['location'] or 'æœªè¨­å®š',
        'ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆID': mask_sensitive_value(VERTEX_AI_CONFIG['endpoint_id'], 8) if VERTEX_AI_CONFIG['endpoint_id'] else 'æœªè¨­å®š',
        'Vertex AIåˆ©ç”¨å¯èƒ½': 'âœ… ã¯ã„' if VERTEX_AI_AVAILABLE else 'âŒ ã„ã„ãˆ',
    }
    
    for key, value in config_status.items():
        st.write(f"- **{key}**: {safe_html(value)}")
    
    st.divider()
    
    # è¨­å®šæ–¹æ³•ã®èª¬æ˜ï¼ˆv19: st.secretså¯¾å¿œè¿½åŠ ï¼‰
    st.write("### ğŸ”§ è¨­å®šæ–¹æ³•")
    
    st.markdown("""
    **ã€æ¨å¥¨ã€‘æ–¹æ³•1: Streamlit Cloud (st.secrets)ã§è¨­å®š**
    
    `.streamlit/secrets.toml` ã¾ãŸã¯ Streamlit Cloud ã® Secrets ã«ä»¥ä¸‹ã‚’è¨­å®š:
    
    ```toml
    # Vertex AIè¨­å®š
    VERTEX_AI_PROJECT_ID = "your-project-id"
    VERTEX_AI_LOCATION = "asia-northeast1"
    VERTEX_AI_ENDPOINT_ID = "your-endpoint-id"
    
    # GCPã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆï¼ˆJSONå½¢å¼ï¼‰
    [gcp_service_account]
    type = "service_account"
    project_id = "your-project-id"
    private_key_id = "your-private-key-id"
    private_key = "-----BEGIN PRIVATE KEY-----\\n...\\n-----END PRIVATE KEY-----\\n"
    client_email = "your-service-account@your-project.iam.gserviceaccount.com"
    client_id = "123456789"
    auth_uri = "https://accounts.google.com/o/oauth2/auth"
    token_uri = "https://oauth2.googleapis.com/token"
    # ... ãã®ä»–ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
    
    # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    DEBUG = false
    ```
    
    **æ–¹æ³•2: ç’°å¢ƒå¤‰æ•°ã§è¨­å®š**
    ```bash
    export VERTEX_AI_PROJECT_ID="your-project-id"
    export VERTEX_AI_LOCATION="asia-northeast1"
    export VERTEX_AI_ENDPOINT_ID="your-endpoint-id"
    # JSONæ–‡å­—åˆ—ã¨ã—ã¦è¨­å®š
    export VERTEX_AI_SERVICE_ACCOUNT_JSON='{"type":"service_account",...}'
    ```
    
    **æ–¹æ³•3: config.pyã§è¨­å®šï¼ˆãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç”¨ï¼‰**
    ```python
    # config.py
    VERTEX_AI_PROJECT_ID = "your-project-id"
    VERTEX_AI_LOCATION = "asia-northeast1"
    VERTEX_AI_ENDPOINT_ID = "your-endpoint-id"
    VERTEX_AI_SERVICE_ACCOUNT_FILE = "service_account.json"
    ```
    """)
    
    st.divider()
    
    # AutoML Forecastingãƒ¢ãƒ‡ãƒ«ã®ä½œæˆæ‰‹é †
    st.write("### ğŸ“š AutoML Forecastingãƒ¢ãƒ‡ãƒ«ã®ä½œæˆæ‰‹é †")
    
    with st.expander("1ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™", expanded=False):
        st.markdown("""
        Vertex AI AutoML Forecastingã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿å½¢å¼ï¼š
        
        | ã‚«ãƒ©ãƒ  | èª¬æ˜ | ä¾‹ |
        |--------|------|-----|
        | timestamp | æ™‚é–“åˆ—ï¼ˆISOå½¢å¼ï¼‰ | 2025-01-01T00:00:00Z |
        | target | äºˆæ¸¬å¯¾è±¡ï¼ˆè²©å£²æ•°ï¼‰ | 15 |
        | time_series_identifier | ç³»åˆ—è­˜åˆ¥å­ï¼ˆå•†å“IDç­‰ï¼‰ | product_001 |
        | weekday | æ›œæ—¥ï¼ˆå…±å¤‰é‡ï¼‰ | 0-6 |
        | is_holiday | ä¼‘æ—¥ãƒ•ãƒ©ã‚°ï¼ˆå…±å¤‰é‡ï¼‰ | 0 or 1 |
        | weather | å¤©æ°—ï¼ˆå…±å¤‰é‡ï¼‰ | sunny, rainy, etc. |
        """)
    
    with st.expander("2ï¸âƒ£ ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°", expanded=False):
        st.markdown("""
        1. [Google Cloud Console](https://console.cloud.google.com/vertex-ai) ã«ã‚¢ã‚¯ã‚»ã‚¹
        2. ã€Œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€â†’ã€Œä½œæˆã€â†’ã€Œæ™‚ç³»åˆ—äºˆæ¸¬ã€ã‚’é¸æŠ
        3. CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ã‚«ãƒ©ãƒ ã‚’è¨­å®š
        4. ã€Œãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã€â†’ã€ŒAutoMLã€ã‚’é¸æŠ
        5. ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†ã‚’å¾…ã¤ï¼ˆæ•°æ™‚é–“ã€œï¼‰
        """)
    
    with st.expander("3ï¸âƒ£ ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ãƒ‡ãƒ—ãƒ­ã‚¤", expanded=False):
        st.markdown("""
        1. ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ
        2. ã€Œãƒ‡ãƒ—ãƒ­ã‚¤ã¨ãƒ†ã‚¹ãƒˆã€â†’ã€Œã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«ãƒ‡ãƒ—ãƒ­ã‚¤ã€
        3. ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆåã‚’è¨­å®šã—ã¦ãƒ‡ãƒ—ãƒ­ã‚¤
        4. ãƒ‡ãƒ—ãƒ­ã‚¤å®Œäº†å¾Œã€ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆIDã‚’ã‚³ãƒ”ãƒ¼
        """)
    
    with st.expander("4ï¸âƒ£ ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®è¨­å®š", expanded=False):
        st.markdown("""
        1. ã€ŒIAMã¨ç®¡ç†ã€â†’ã€Œã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã€
        2. ã€Œã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ä½œæˆã€
        3. ä»¥ä¸‹ã®ãƒ­ãƒ¼ãƒ«ã‚’ä»˜ä¸ï¼š
           - Vertex AI ãƒ¦ãƒ¼ã‚¶ãƒ¼
           - Vertex AI äºˆæ¸¬ãƒ¦ãƒ¼ã‚¶ãƒ¼
        4. ã€Œéµã‚’ä½œæˆã€â†’ JSONå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        5. Streamlit Cloud ã®å ´åˆã¯ secrets.toml ã«è¨­å®š
        """)
    
    # æ¥ç¶šãƒ†ã‚¹ãƒˆ
    st.divider()
    st.write("### ğŸ§ª æ¥ç¶šãƒ†ã‚¹ãƒˆ")
    
    if st.button("ğŸ” Vertex AIæ¥ç¶šã‚’ãƒ†ã‚¹ãƒˆ", type="primary"):
        if not VERTEX_AI_AVAILABLE:
            st.error("Vertex AIãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ä¸Šè¨˜ã®è¨­å®šã‚’å®Œäº†ã—ã¦ãã ã•ã„ã€‚")
        else:
            with st.spinner("æ¥ç¶šãƒ†ã‚¹ãƒˆä¸­..."):
                try:
                    forecaster = get_vertex_ai_forecaster()
                    # ç°¡å˜ãªãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§æ¥ç¶šç¢ºèª
                    test_df = pd.DataFrame({
                        'date': pd.date_range(start='2025-01-01', periods=30, freq='D'),
                        'è²©å£²å•†å“æ•°': np.random.randint(1, 10, 30)
                    })
                    predictions, metadata = forecaster.predict(test_df, 7, "test_product")
                    st.success(f"âœ… æ¥ç¶šæˆåŠŸï¼ãƒ¢ãƒ‡ãƒ«ID: {metadata.get('deployed_model_id', 'N/A')}")
                    st.write("ãƒ†ã‚¹ãƒˆäºˆæ¸¬çµæœ:")
                    st.dataframe(predictions.head())
                except Exception as e:
                    st.error(f"âŒ æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")


# =============================================================================
# æ—¢å­˜æˆä¸å“ã®åˆ†æ
# =============================================================================

def render_existing_product_analysis():
    """æ—¢å­˜æˆä¸å“ã®åˆ†æãƒ»äºˆæ¸¬"""
    render_product_selection()
    start_date, end_date = render_period_selection()
    
    if len(st.session_state.selected_products) > 1:
        render_analysis_mode_selection()
    
    if st.session_state.analysis_mode == "å€‹åˆ¥":
        render_individual_analysis(start_date, end_date)
    else:
        sales_data = render_sales_analysis(start_date, end_date)
        render_forecast_section(sales_data)
        render_delivery_section()


def render_analysis_mode_selection():
    """åˆç®—/å€‹åˆ¥ãƒ¢ãƒ¼ãƒ‰ã®é¸æŠ"""
    st.markdown('<p class="section-header">ğŸ“Š åˆ†æãƒ¢ãƒ¼ãƒ‰</p>', unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        mode = st.radio(
            "è¤‡æ•°æˆä¸å“ã®åˆ†ææ–¹æ³•",
            ["åˆç®—", "å€‹åˆ¥"],
            index=0 if st.session_state.analysis_mode == "åˆç®—" else 1,
            horizontal=True,
            help="åˆç®—ï¼šé¸æŠã—ãŸæˆä¸å“ã®åˆè¨ˆã‚’åˆ†æ\nå€‹åˆ¥ï¼šæˆä¸å“ã”ã¨ã«åˆ¥ã€…ã«åˆ†æ"
        )
        st.session_state.analysis_mode = mode
    
    with col2:
        if mode == "åˆç®—":
            st.info(f"ğŸ“Š {len(st.session_state.selected_products)}ä»¶ã®æˆä¸å“ã‚’**åˆè¨ˆ**ã—ã¦åˆ†æã—ã¾ã™")
        else:
            st.info(f"ğŸ“Š {len(st.session_state.selected_products)}ä»¶ã®æˆä¸å“ã‚’**å€‹åˆ¥**ã«åˆ†æã—ã¾ã™")


def render_product_selection():
    """æˆä¸å“é¸æŠã‚»ã‚¯ã‚·ãƒ§ãƒ³"""
    st.markdown('<p class="section-header">â‘  æˆä¸å“ã‚’é¸ã¶</p>', unsafe_allow_html=True)
    
    tab1, tab2 = st.tabs(["ğŸ” åå‰ã§æ¤œç´¢", "ğŸ“ ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‹ã‚‰é¸ã¶"])
    
    with tab1:
        render_search_tab()
    
    with tab2:
        render_category_tab()
    
    render_selected_products()


def render_search_tab():
    """åå‰æ¤œç´¢ã‚¿ãƒ–ï¼ˆéƒµé€ã‚·ãƒ¼ãƒˆã®å•†å“åã‚‚æ¤œç´¢å¯¾è±¡ã«å«ã‚€ï¼‰"""
    search_query = st.text_input(
        "æˆä¸å“åã‚’å…¥åŠ›",
        placeholder="ä¾‹: é‡‘é‹ã€ãŠå®ˆã‚Šã€å¾¡æœ±å°å¸³...",
        key="search_input"
    )
    
    if search_query and st.session_state.normalizer:
        # Airãƒ¬ã‚¸ã®æ¤œç´¢çµæœ
        airregi_results = st.session_state.normalizer.search(search_query, limit=20)
        
        # éƒµé€ã‚·ãƒ¼ãƒˆã‹ã‚‰ã‚‚æ¤œç´¢
        mail_results = []
        try:
            mail_order_enabled = hasattr(config, 'MAIL_ORDER_SPREADSHEET_ID') and config.MAIL_ORDER_SPREADSHEET_ID
            if mail_order_enabled:
                df_mail = st.session_state.data_loader.get_mail_order_summary()
                if not df_mail.empty and 'å•†å“å' in df_mail.columns:
                    # éƒµé€ã‚·ãƒ¼ãƒˆã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå•†å“åã‚’å–å¾—
                    mail_products = df_mail['å•†å“å'].unique()
                    for mp in mail_products:
                        mp_str = str(mp).strip()
                        if search_query.lower() in mp_str.lower():
                            # æ—¢ã«Airãƒ¬ã‚¸çµæœã«å«ã¾ã‚Œã¦ã„ãªã„ã‹ç¢ºèª
                            already_in_airregi = any(
                                mp_str in r.get('normalized_name', '') or 
                                r.get('normalized_name', '') in mp_str
                                for r in airregi_results
                            )
                            if not already_in_airregi:
                                mail_results.append({
                                    'name': mp_str,
                                    'source': 'mail'
                                })
        except Exception as e:
            pass  # éƒµé€ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        
        total_results = len(airregi_results) + len(mail_results)
        
        if total_results > 0:
            st.write(f"**{total_results}ä»¶** è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
            
            # Airãƒ¬ã‚¸ã®çµæœ
            if airregi_results:
                st.write("**ğŸª Airãƒ¬ã‚¸ã®å•†å“ï¼š**")
                cols = st.columns(3)
                for i, result in enumerate(airregi_results):
                    name = result['normalized_name']
                    bracket = result.get('bracket_content', '')
                    
                    with cols[i % 3]:
                        is_selected = name in st.session_state.selected_products
                        label = f"{name}"
                        if bracket:
                            label += f" ({bracket})"
                        
                        # ã‚­ãƒ¼ã«å‰Šé™¤ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’å«ã‚ã‚‹ã“ã¨ã§ã€Ã—ãƒœã‚¿ãƒ³å¾Œã«ãƒªã‚»ãƒƒãƒˆ
                        cb_key = f"search_{name}_{st.session_state.delete_counter}"
                        if st.checkbox(label, value=is_selected, key=cb_key):
                            if name not in st.session_state.selected_products:
                                st.session_state.selected_products.append(name)
                        else:
                            if name in st.session_state.selected_products:
                                st.session_state.selected_products.remove(name)
            
            # éƒµé€ã®çµæœï¼ˆAirãƒ¬ã‚¸ã«ãªã„å•†å“ï¼‰
            if mail_results:
                st.write("**ğŸ“¬ éƒµé€ã‚·ãƒ¼ãƒˆã®ã¿ã®å•†å“ï¼š**")
                st.caption("â€»ã“ã‚Œã‚‰ã¯Airãƒ¬ã‚¸ã«ç™»éŒ²ã•ã‚Œã¦ã„ãªã„å•†å“åã§ã™")
                cols = st.columns(3)
                for i, result in enumerate(mail_results):
                    name = result['name']
                    
                    with cols[i % 3]:
                        is_selected = name in st.session_state.selected_products
                        
                        # ã‚­ãƒ¼ã«å‰Šé™¤ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’å«ã‚ã‚‹ã“ã¨ã§ã€Ã—ãƒœã‚¿ãƒ³å¾Œã«ãƒªã‚»ãƒƒãƒˆ
                        cb_key = f"mail_search_{name}_{st.session_state.delete_counter}"
                        if st.checkbox(f"ğŸ“¬ {name}", value=is_selected, key=cb_key):
                            if name not in st.session_state.selected_products:
                                st.session_state.selected_products.append(name)
                        else:
                            if name in st.session_state.selected_products:
                                st.session_state.selected_products.remove(name)
            
            # åˆç®—ã‚°ãƒ«ãƒ¼ãƒ—æ©Ÿèƒ½ã®èª¬æ˜
            if len(st.session_state.selected_products) > 1:
                st.info("""
                ğŸ’¡ **ãƒ’ãƒ³ãƒˆ**: è¤‡æ•°ã®å•†å“ã‚’é¸æŠã—ãŸå ´åˆã€ã€Œåˆ†æãƒ¢ãƒ¼ãƒ‰ã€ã§ã€Œåˆç®—ã€ã‹ã€Œå€‹åˆ¥ã€ã‚’é¸ã¹ã¾ã™ã€‚
                - **åˆç®—**: é¸æŠã—ãŸã™ã¹ã¦ã®å•†å“ã‚’åˆè¨ˆã—ã¦åˆ†æ
                - **å€‹åˆ¥**: å•†å“ã”ã¨ã«åˆ¥ã€…ã«åˆ†æ
                """)
        else:
            st.info("è©²å½“ã™ã‚‹æˆä¸å“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")


def render_category_tab():
    """ã‚«ãƒ†ã‚´ãƒªãƒ¼é¸æŠã‚¿ãƒ–"""
    if not st.session_state.categories:
        st.info("ã‚«ãƒ†ã‚´ãƒªãƒ¼æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    st.write("**ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’é¸æŠã—ã¦ä¸€æ‹¬è¿½åŠ ï¼š**")
    
    cols = st.columns(4)
    
    sorted_categories = sorted(
        st.session_state.categories.items(),
        key=lambda x: len(x[1]),
        reverse=True
    )
    
    for i, (category, products) in enumerate(sorted_categories[:12]):
        with cols[i % 4]:
            if st.button(f"ğŸ“ {category} ({len(products)}ä»¶)", key=f"cat_{category}"):
                for p in products:
                    if p not in st.session_state.selected_products:
                        st.session_state.selected_products.append(p)
                st.rerun()


def clear_all_selected_products():
    """ã™ã¹ã¦ã®é¸æŠã‚’ã‚¯ãƒªã‚¢ï¼ˆcallbackç”¨ï¼‰"""
    st.session_state.selected_products = []
    st.session_state.product_groups = {}  # ã‚°ãƒ«ãƒ¼ãƒ—æƒ…å ±ã‚‚ã‚¯ãƒªã‚¢
    st.session_state.analysis_mode = "åˆç®—"
    st.session_state.sales_data = None
    st.session_state.forecast_data = None
    st.session_state.individual_sales_data = {}
    st.session_state.individual_forecast_results = []
    st.session_state.individual_all_methods_results = {}


def remove_single_product(product: str):
    """å˜ä¸€ã®æˆä¸å“ã‚’å‰Šé™¤ï¼ˆcallbackç”¨ï¼‰"""
    if product in st.session_state.selected_products:
        st.session_state.selected_products.remove(product)
    # ã‚°ãƒ«ãƒ¼ãƒ—æƒ…å ±ã‹ã‚‰ã‚‚å‰Šé™¤
    if product in st.session_state.product_groups:
        del st.session_state.product_groups[product]
    st.session_state.sales_data = None
    st.session_state.forecast_data = None
    st.session_state.individual_sales_data = {}
    st.session_state.individual_forecast_results = []
    st.session_state.individual_all_methods_results = {}


def render_selected_products():
    """é¸æŠä¸­ã®æˆä¸å“ã‚’è¡¨ç¤ºï¼ˆÃ—ãƒœã‚¿ãƒ³ã§å‰Šé™¤ã€ã‚°ãƒ«ãƒ¼ãƒ—é¸æŠæ©Ÿèƒ½ä»˜ãï¼‰"""
    st.divider()
    
    if st.session_state.selected_products:
        col1, col2 = st.columns([3, 1])
        with col1:
            st.write(f"**âœ… é¸æŠä¸­ã®æˆä¸å“ï¼ˆ{len(st.session_state.selected_products)}ä»¶ï¼‰**")
        with col2:
            # ã™ã¹ã¦ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
            if st.button("ğŸ—‘ï¸ ã™ã¹ã¦ã‚¯ãƒªã‚¢", key="clear_all_btn_main"):
                st.session_state.selected_products = []
                st.session_state.product_groups = {}
                st.session_state.analysis_mode = "åˆç®—"
                st.session_state.sales_data = None
                st.session_state.forecast_data = None
                st.session_state.individual_sales_data = {}
                st.session_state.individual_forecast_results = []
                st.session_state.individual_all_methods_results = {}
                # å‰Šé™¤ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ãƒˆï¼ˆãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã®ã‚­ãƒ¼ã‚’ãƒªã‚»ãƒƒãƒˆï¼‰
                st.session_state.delete_counter += 1
                st.rerun()
        
        # ã‚°ãƒ«ãƒ¼ãƒ—æ©Ÿèƒ½ã®èª¬æ˜
        if len(st.session_state.selected_products) > 1:
            st.caption("ğŸ’¡ åŒã˜ã‚°ãƒ«ãƒ¼ãƒ—ç•ªå·ã®å•†å“ã¯åˆç®—ã—ã¦åˆ†æã•ã‚Œã¾ã™ã€‚ã‚°ãƒ«ãƒ¼ãƒ—0ã¯å˜ç‹¬æ‰±ã„ã§ã™ã€‚")
        
        # é¸æŠä¸­ã®å•†å“ãƒªã‚¹ãƒˆï¼ˆÃ—ãƒœã‚¿ãƒ³ï¼‹ã‚°ãƒ«ãƒ¼ãƒ—é¸æŠä»˜ãï¼‰
        st.markdown('<div style="background: #e3f2fd; border-radius: 10px; padding: 15px; margin: 10px 0;">', unsafe_allow_html=True)
        
        products_copy = st.session_state.selected_products.copy()
        
        # å„å•†å“ã«Ã—ãƒœã‚¿ãƒ³ã¨ã‚°ãƒ«ãƒ¼ãƒ—é¸æŠã‚’ä»˜ã‘ã‚‹
        for i, product in enumerate(products_copy):
            # ç¾åœ¨ã®ã‚°ãƒ«ãƒ¼ãƒ—ç•ªå·ã‚’å–å¾—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯0=å˜ç‹¬ï¼‰
            current_group = st.session_state.product_groups.get(product, 0)
            
            col_product, col_group, col_delete = st.columns([4, 2, 1])
            
            with col_product:
                st.markdown(f"ğŸ“¦ **{product}**")
            
            with col_group:
                # ã‚°ãƒ«ãƒ¼ãƒ—é¸æŠãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³
                new_group = st.selectbox(
                    "ã‚°ãƒ«ãƒ¼ãƒ—",
                    options=[0, 1, 2, 3, 4, 5],
                    index=current_group,
                    format_func=lambda x: "å˜ç‹¬" if x == 0 else f"ã‚°ãƒ«ãƒ¼ãƒ—{x}",
                    key=f"group_select_{i}_{hash(product) % 10000}",
                    label_visibility="collapsed"
                )
                # ã‚°ãƒ«ãƒ¼ãƒ—ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã€session_stateã‚’æ›´æ–°
                if new_group != current_group:
                    st.session_state.product_groups[product] = new_group
                    st.rerun()
            
            with col_delete:
                # Ã—ãƒœã‚¿ãƒ³
                if st.button("âœ•", key=f"del_{i}_{hash(product) % 10000}", help=f"{product}ã‚’å‰Šé™¤"):
                    # å•†å“ã‚’å‰Šé™¤
                    if product in st.session_state.selected_products:
                        st.session_state.selected_products.remove(product)
                    if product in st.session_state.product_groups:
                        del st.session_state.product_groups[product]
                    
                    # å‰Šé™¤ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ãƒˆï¼ˆãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã®ã‚­ãƒ¼ã‚’ãƒªã‚»ãƒƒãƒˆï¼‰
                    st.session_state.delete_counter += 1
                    
                    # é–¢é€£ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢
                    st.session_state.sales_data = None
                    st.session_state.forecast_data = None
                    st.session_state.individual_sales_data = {}
                    st.session_state.individual_forecast_results = []
                    st.session_state.individual_all_methods_results = {}
                    st.rerun()
        
        st.markdown("</div>", unsafe_allow_html=True)
        
        # ã‚°ãƒ«ãƒ¼ãƒ—ã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
        groups_summary = {}
        for product in st.session_state.selected_products:
            group_num = st.session_state.product_groups.get(product, 0)
            if group_num not in groups_summary:
                groups_summary[group_num] = []
            groups_summary[group_num].append(product)
        
        # ã‚°ãƒ«ãƒ¼ãƒ—ãŒ1ã¤ä»¥ä¸Šã‚ã‚‹å ´åˆã®ã¿è¡¨ç¤º
        has_groups = any(g != 0 for g in groups_summary.keys())
        if has_groups:
            st.write("**ğŸ“Š ã‚°ãƒ«ãƒ¼ãƒ—æ§‹æˆ:**")
            for group_num, products in sorted(groups_summary.items()):
                if group_num == 0:
                    for p in products:
                        st.write(f"  - å˜ç‹¬: {p}")
                else:
                    st.write(f"  - ã‚°ãƒ«ãƒ¼ãƒ—{group_num}: {', '.join(products)}ï¼ˆåˆç®—ï¼‰")
    else:
        st.warning("ğŸ‘† ä¸Šã‹ã‚‰æˆä¸å“ã‚’é¸ã‚“ã§ãã ã•ã„")


def render_period_selection():
    """æœŸé–“é¸æŠã‚»ã‚¯ã‚·ãƒ§ãƒ³"""
    st.markdown('<p class="section-header">â‘¡ æœŸé–“ã‚’é¸ã¶</p>', unsafe_allow_html=True)
    
    today = date.today()
    
    col1, col2 = st.columns([1, 3])
    
    with col1:
        preset = st.selectbox(
            "ãƒ—ãƒªã‚»ãƒƒãƒˆ",
            ["ã‚«ã‚¹ã‚¿ãƒ ", "éå»1ãƒ¶æœˆ", "éå»3ãƒ¶æœˆ", "éå»6ãƒ¶æœˆ", "éå»1å¹´", "éå»2å¹´", "å…¨æœŸé–“"],
            index=4
        )
    
    if preset == "éå»1ãƒ¶æœˆ":
        default_start = today - timedelta(days=30)
        default_end = today
    elif preset == "éå»3ãƒ¶æœˆ":
        default_start = today - timedelta(days=90)
        default_end = today
    elif preset == "éå»6ãƒ¶æœˆ":
        default_start = today - timedelta(days=180)
        default_end = today
    elif preset == "éå»1å¹´":
        default_start = today - timedelta(days=365)
        default_end = today
    elif preset == "éå»2å¹´":
        default_start = today - timedelta(days=730)
        default_end = today
    elif preset == "å…¨æœŸé–“":
        default_start = date(2022, 8, 1)
        default_end = today
    else:
        default_start = today - timedelta(days=365)
        default_end = today
    
    with col2:
        # é–‹å§‹æ—¥
        st.write("**é–‹å§‹æ—¥**")
        col_sy, col_sm, col_sd = st.columns(3)
        
        years = list(range(2022, today.year + 2))
        months_jp = ["1æœˆ", "2æœˆ", "3æœˆ", "4æœˆ", "5æœˆ", "6æœˆ", "7æœˆ", "8æœˆ", "9æœˆ", "10æœˆ", "11æœˆ", "12æœˆ"]
        
        with col_sy:
            start_year = st.selectbox(
                "å¹´",
                years,
                index=years.index(default_start.year) if default_start.year in years else 0,
                key="start_year",
                label_visibility="collapsed"
            )
            st.caption("å¹´")
        with col_sm:
            start_month = st.selectbox(
                "æœˆ",
                list(range(1, 13)),
                index=default_start.month - 1,
                format_func=lambda x: months_jp[x-1],
                key="start_month",
                label_visibility="collapsed"
            )
            st.caption("æœˆ")
        with col_sd:
            max_day_start = calendar.monthrange(start_year, start_month)[1]
            start_day = st.number_input(
                "æ—¥",
                min_value=1,
                max_value=max_day_start,
                value=min(default_start.day, max_day_start),
                key="start_day",
                label_visibility="collapsed"
            )
            st.caption("æ—¥")
        
        # çµ‚äº†æ—¥
        st.write("**çµ‚äº†æ—¥**")
        col_ey, col_em, col_ed = st.columns(3)
        
        with col_ey:
            end_year = st.selectbox(
                "å¹´",
                years,
                index=years.index(default_end.year) if default_end.year in years else 0,
                key="end_year",
                label_visibility="collapsed"
            )
            st.caption("å¹´")
        with col_em:
            end_month = st.selectbox(
                "æœˆ",
                list(range(1, 13)),
                index=default_end.month - 1,
                format_func=lambda x: months_jp[x-1],
                key="end_month",
                label_visibility="collapsed"
            )
            st.caption("æœˆ")
        with col_ed:
            max_day_end = calendar.monthrange(end_year, end_month)[1]
            end_day = st.number_input(
                "æ—¥",
                min_value=1,
                max_value=max_day_end,
                value=min(default_end.day, max_day_end),
                key="end_day",
                label_visibility="collapsed"
            )
            st.caption("æ—¥")
    
    start_date = date(start_year, start_month, start_day)
    end_date = date(end_year, end_month, end_day)
    
    if start_date > end_date:
        st.error("âš ï¸ é–‹å§‹æ—¥ãŒçµ‚äº†æ—¥ã‚ˆã‚Šå¾Œã«ãªã£ã¦ã„ã¾ã™")
        end_date = start_date
    
    return start_date, end_date


def render_sales_analysis(start_date: date, end_date: date):
    """å£²ä¸Šåˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³"""
    st.markdown('<p class="section-header">â‘¢ å£²ä¸Šã‚’è¦‹ã‚‹</p>', unsafe_allow_html=True)
    
    if not st.session_state.selected_products:
        st.info("æˆä¸å“ã‚’é¸æŠã™ã‚‹ã¨ã€ã“ã“ã«å£²ä¸ŠãŒè¡¨ç¤ºã•ã‚Œã¾ã™")
        return None
    
    df_items = st.session_state.data_loader.load_item_sales()
    
    if df_items.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return None
    
    # Airãƒ¬ã‚¸ãƒ‡ãƒ¼ã‚¿ã«sourceåˆ—ã‚’è¿½åŠ 
    if 'source' not in df_items.columns:
        df_items = df_items.copy()
        df_items['source'] = 'airregi'
    
    # éƒµé€ãƒ‡ãƒ¼ã‚¿çµ±åˆã‚ªãƒ—ã‚·ãƒ§ãƒ³
    mail_order_enabled = hasattr(config, 'MAIL_ORDER_SPREADSHEET_ID') and config.MAIL_ORDER_SPREADSHEET_ID
    include_mail_orders = False
    airregi_count = 0
    mail_order_count = 0
    
    if mail_order_enabled:
        include_mail_orders = st.checkbox(
            "ğŸ“¬ éƒµé€æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚ã‚‹",
            value=True,
            help="Googleãƒ•ã‚©ãƒ¼ãƒ ã‹ã‚‰ã®éƒµé€ä¾é ¼ã‚‚éœ€è¦ã«å«ã‚ã¾ã™"
        )
    
    # é¸æŠã•ã‚ŒãŸå•†å“ã®ã‚ªãƒªã‚¸ãƒŠãƒ«åã‚’å–å¾—
    original_names = st.session_state.normalizer.get_all_original_names(
        st.session_state.selected_products
    )
    
    # Airãƒ¬ã‚¸ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿
    mask = (df_items['date'] >= pd.Timestamp(start_date)) & (df_items['date'] <= pd.Timestamp(end_date))
    df_filtered_airregi = df_items[mask]
    df_agg_airregi = aggregate_by_products(df_filtered_airregi, original_names, aggregate=True)
    
    if not df_agg_airregi.empty:
        airregi_count = int(df_agg_airregi['è²©å£²å•†å“æ•°'].sum())
    
    # éƒµé€ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
    df_mail_matched = pd.DataFrame()
    if include_mail_orders:
        df_mail = st.session_state.data_loader.get_mail_order_summary()
        
        if not df_mail.empty:
            # éƒµé€ãƒ‡ãƒ¼ã‚¿ã®å•†å“åã‚’Airãƒ¬ã‚¸ã®å•†å“åï¼ˆã‚ªãƒªã‚¸ãƒŠãƒ«åï¼‰ã«ãƒãƒƒãƒãƒ³ã‚°
            matched_rows = []
            
            for _, mail_row in df_mail.iterrows():
                mail_product = str(mail_row['å•†å“å']).strip()
                
                # å…±é€šãƒãƒƒãƒãƒ³ã‚°é–¢æ•°ã‚’ä½¿ç”¨
                matched_name = match_mail_product_to_airregi(mail_product, original_names)
                
                if matched_name:
                    new_row = mail_row.copy()
                    new_row['å•†å“å'] = matched_name
                    matched_rows.append(new_row)
            
            if matched_rows:
                df_mail_matched = pd.DataFrame(matched_rows)
                # æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿
                if 'date' in df_mail_matched.columns:
                    df_mail_matched['date'] = pd.to_datetime(df_mail_matched['date'], errors='coerce')
                    mail_mask = (df_mail_matched['date'] >= pd.Timestamp(start_date)) & \
                               (df_mail_matched['date'] <= pd.Timestamp(end_date))
                    df_mail_matched = df_mail_matched[mail_mask]
                mail_order_count = int(df_mail_matched['è²©å£²å•†å“æ•°'].sum()) if not df_mail_matched.empty else 0
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
    if not df_mail_matched.empty and include_mail_orders:
        # éƒµé€ãƒ‡ãƒ¼ã‚¿ã‚’Airãƒ¬ã‚¸å½¢å¼ã«å¤‰æ›ã—ã¦çµåˆ
        df_mail_for_merge = df_mail_matched[['date', 'å•†å“å', 'è²©å£²å•†å“æ•°', 'è²©å£²ç·å£²ä¸Š', 'è¿”å“å•†å“æ•°']].copy()
        df_mail_for_merge['source'] = 'mail_order'
        
        # Airãƒ¬ã‚¸ãƒ‡ãƒ¼ã‚¿
        df_airregi_for_merge = df_filtered_airregi[df_filtered_airregi['å•†å“å'].isin(original_names)].copy()
        if 'source' not in df_airregi_for_merge.columns:
            df_airregi_for_merge['source'] = 'airregi'
        
        # çµåˆ
        df_combined = pd.concat([df_airregi_for_merge, df_mail_for_merge], ignore_index=True)
        df_agg = df_combined.groupby('date').agg({
            'è²©å£²å•†å“æ•°': 'sum',
            'è²©å£²ç·å£²ä¸Š': 'sum',
            'è¿”å“å•†å“æ•°': 'sum'
        }).reset_index()
    else:
        df_agg = df_agg_airregi
    
    if df_agg.empty:
        st.warning("è©²å½“æœŸé–“ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return None
    
    df_agg = df_agg.sort_values('date').reset_index(drop=True)
    
    total_qty = airregi_count + mail_order_count
    total_sales = df_agg['è²©å£²ç·å£²ä¸Š'].sum()
    period_days = (end_date - start_date).days + 1
    avg_daily = total_qty / period_days if period_days > 0 else 0
    
    # å¹³æ—¥ãƒ»ä¼‘æ—¥ã®å¹³å‡ã‚’è¨ˆç®—
    df_agg['weekday'] = pd.to_datetime(df_agg['date']).dt.dayofweek
    df_weekday = df_agg[df_agg['weekday'] < 5]
    df_weekend = df_agg[df_agg['weekday'] >= 5]
    
    avg_weekday = df_weekday['è²©å£²å•†å“æ•°'].mean() if not df_weekday.empty else 0
    avg_weekend = df_weekend['è²©å£²å•†å“æ•°'].mean() if not df_weekend.empty else 0
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
    st.write("**ğŸ“Š è²©å£²å®Ÿç¸¾**")
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("ğŸ›’ è²©å£²æ•°é‡åˆè¨ˆ", f"{total_qty:,}ä½“")
    col2.metric("ğŸ’° å£²ä¸Šåˆè¨ˆ", f"Â¥{total_sales:,.0f}")
    col3.metric("ğŸ“ˆ å¹³å‡æ—¥è²©", f"{avg_daily:.1f}ä½“/æ—¥")
    col4.metric("ğŸ“… æœŸé–“", f"{period_days}æ—¥é–“")
    
    # ã‚¨ã‚¢ãƒ¬ã‚¸ã¨éƒµé€ã®å†…è¨³ã‚’è¡¨ç¤º
    if include_mail_orders:
        col5, col6, col7, col8 = st.columns(4)
        col5.metric("ğŸª Airãƒ¬ã‚¸", f"{airregi_count:,}ä½“")
        col6.metric("ğŸ“¬ éƒµé€", f"{mail_order_count:,}ä½“")
        
        # ä¼‘æ—¥/å¹³æ—¥æ¯”ç‡
        if avg_weekday > 0:
            ratio = avg_weekend / avg_weekday
            col7.metric("ğŸ“Š ä¼‘æ—¥/å¹³æ—¥æ¯”", f"{ratio:.2f}å€")
    else:
        col5, col6, col7, col8 = st.columns(4)
        col5.metric("ğŸ“… å¹³æ—¥å¹³å‡", f"{avg_weekday:.1f}ä½“/æ—¥")
        col6.metric("ğŸŒ ä¼‘æ—¥å¹³å‡", f"{avg_weekend:.1f}ä½“/æ—¥")
        if avg_weekday > 0:
            ratio = avg_weekend / avg_weekday
            col7.metric("ğŸ“Š ä¼‘æ—¥/å¹³æ—¥æ¯”", f"{ratio:.2f}å€")
    
    # ========== éå»ã¨ã®æ¯”è¼ƒã‚»ã‚¯ã‚·ãƒ§ãƒ³ ==========
    render_period_comparison(df_items, original_names, start_date, end_date, total_qty)
    
    st.session_state.sales_data = df_agg
    
    return df_agg


def render_period_comparison(df_items: pd.DataFrame, original_names: list, start_date: date, end_date: date, current_total: int):
    """éå»ã¨ã®æ¯”è¼ƒï¼ˆæœˆæ¬¡ãƒ»å¹´æ¬¡ï¼‰ã‚’è¡¨ç¤º - å¸¸ã«è¡¨ç¤ºç‰ˆ"""
    
    st.markdown('<p class="section-header">ğŸ“Š éå»ã¨ã®æ¯”è¼ƒ</p>', unsafe_allow_html=True)
    
    comparison_type = st.radio(
        "æ¯”è¼ƒã‚¿ã‚¤ãƒ—",
        ["æ˜¨å¹´åŒæœŸæ¯”è¼ƒ", "æœˆæ¬¡æ¨ç§»", "å¹´æ¬¡æ¨ç§»"],
        horizontal=True,
        key="comparison_type"
    )
    
    if comparison_type == "æ˜¨å¹´åŒæœŸæ¯”è¼ƒ":
        render_year_over_year_comparison(df_items, original_names, start_date, end_date, current_total)
    elif comparison_type == "æœˆæ¬¡æ¨ç§»":
        render_monthly_trend(df_items, original_names)
    else:
        render_yearly_trend(df_items, original_names)


def render_year_over_year_comparison(df_items: pd.DataFrame, original_names: list, start_date: date, end_date: date, current_total: int):
    """æ˜¨å¹´åŒæœŸã¨ã®æ¯”è¼ƒ"""
    st.write("### ğŸ“ˆ æ˜¨å¹´åŒæœŸã¨ã®æ¯”è¼ƒ")
    
    # æ˜¨å¹´åŒæœŸã®æœŸé–“ã‚’è¨ˆç®—
    last_year_start = date(start_date.year - 1, start_date.month, start_date.day)
    last_year_end = date(end_date.year - 1, end_date.month, min(end_date.day, 28))  # æœˆæœ«å¯¾ç­–
    
    # æ˜¨å¹´åŒæœŸã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    mask_last_year = (df_items['date'] >= pd.Timestamp(last_year_start)) & \
                     (df_items['date'] <= pd.Timestamp(last_year_end))
    df_last_year = df_items[mask_last_year]
    df_last_year_agg = aggregate_by_products(df_last_year, original_names, aggregate=True)
    
    last_year_total = int(df_last_year_agg['è²©å£²å•†å“æ•°'].sum()) if not df_last_year_agg.empty else 0
    
    # å¢—æ¸›ã‚’è¨ˆç®—
    if last_year_total > 0:
        diff = current_total - last_year_total
        diff_pct = (diff / last_year_total) * 100
        
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("ğŸ“… ä»ŠæœŸ", f"{current_total:,}ä½“")
        col2.metric("ğŸ“… æ˜¨å¹´åŒæœŸ", f"{last_year_total:,}ä½“")
        col3.metric("ğŸ“Š å¢—æ¸›æ•°", f"{diff:+,}ä½“", delta=f"{diff_pct:+.1f}%")
        
        if diff > 0:
            col4.metric("ğŸ“ˆ è©•ä¾¡", "å¢—åŠ  â¬†ï¸", delta=f"{diff_pct:.1f}%å¢—")
        elif diff < 0:
            col4.metric("ğŸ“‰ è©•ä¾¡", "æ¸›å°‘ â¬‡ï¸", delta=f"{diff_pct:.1f}%æ¸›")
        else:
            col4.metric("â¡ï¸ è©•ä¾¡", "æ¨ªã°ã„")
        
        # è©³ç´°èª¬æ˜
        st.info(f"""
        **æ¯”è¼ƒæœŸé–“**
        - ä»ŠæœŸ: {start_date.strftime('%Yå¹´%mæœˆ%dæ—¥')} ã€œ {end_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}
        - æ˜¨å¹´åŒæœŸ: {last_year_start.strftime('%Yå¹´%mæœˆ%dæ—¥')} ã€œ {last_year_end.strftime('%Yå¹´%mæœˆ%dæ—¥')}
        
        **çµæœ**: æ˜¨å¹´åŒæœŸã¨æ¯”ã¹ã¦ **{abs(diff):,}ä½“** {'å¢—åŠ ' if diff > 0 else 'æ¸›å°‘'}ï¼ˆ{abs(diff_pct):.1f}%{'å¢—' if diff > 0 else 'æ¸›'}ï¼‰
        """)
    else:
        st.warning("æ˜¨å¹´åŒæœŸã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")


def render_monthly_trend(df_items: pd.DataFrame, original_names: list):
    """æœˆæ¬¡æ¨ç§»ã‚’è¡¨ç¤º"""
    st.write("### ğŸ“Š æœˆæ¬¡æ¨ç§»")
    
    # å…¨æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’æœˆåˆ¥ã«é›†è¨ˆ
    df_all = aggregate_by_products(df_items, original_names, aggregate=True)
    
    if df_all.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    df_all['date'] = pd.to_datetime(df_all['date'])
    df_all['å¹´æœˆ'] = df_all['date'].dt.to_period('M')
    
    monthly = df_all.groupby('å¹´æœˆ').agg({
        'è²©å£²å•†å“æ•°': 'sum',
        'è²©å£²ç·å£²ä¸Š': 'sum'
    }).reset_index()
    monthly['å¹´æœˆ'] = monthly['å¹´æœˆ'].astype(str)
    
    # ç›´è¿‘12ãƒ¶æœˆã«çµã‚‹
    monthly = monthly.tail(24)
    
    # å‰æœˆæ¯”ã‚’è¨ˆç®—
    monthly['å‰æœˆæ¯”'] = monthly['è²©å£²å•†å“æ•°'].pct_change() * 100
    
    # ã‚°ãƒ©ãƒ•
    fig = go.Figure()
    fig.add_trace(go.Bar(
        x=monthly['å¹´æœˆ'],
        y=monthly['è²©å£²å•†å“æ•°'],
        name='è²©å£²æ•°',
        marker_color='#4285F4'
    ))
    
    fig.update_layout(
        title='æœˆåˆ¥è²©å£²æ•°æ¨ç§»',
        xaxis_title='å¹´æœˆ',
        yaxis_title='è²©å£²æ•°ï¼ˆä½“ï¼‰',
        height=350
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # è¡¨å½¢å¼ã§ã‚‚è¡¨ç¤º
    st.write("**æœˆåˆ¥ãƒ‡ãƒ¼ã‚¿**")
    display_df = monthly[['å¹´æœˆ', 'è²©å£²å•†å“æ•°', 'å‰æœˆæ¯”']].copy()
    display_df.columns = ['å¹´æœˆ', 'è²©å£²æ•°ï¼ˆä½“ï¼‰', 'å‰æœˆæ¯”ï¼ˆ%ï¼‰']
    display_df['è²©å£²æ•°ï¼ˆä½“ï¼‰'] = display_df['è²©å£²æ•°ï¼ˆä½“ï¼‰'].apply(lambda x: f"{int(x):,}")
    display_df['å‰æœˆæ¯”ï¼ˆ%ï¼‰'] = display_df['å‰æœˆæ¯”ï¼ˆ%ï¼‰'].apply(lambda x: f"{x:+.1f}%" if pd.notna(x) else "-")
    st.dataframe(display_df.tail(12), use_container_width=True, hide_index=True)


def render_yearly_trend(df_items: pd.DataFrame, original_names: list):
    """å¹´æ¬¡æ¨ç§»ã‚’è¡¨ç¤ºï¼ˆè¡¨å½¢å¼ã‚’é‡è¦–ï¼‰"""
    st.write("### ğŸ“Š å¹´æ¬¡æ¨ç§»ï¼ˆå¹´åˆ¥æ¯”è¼ƒè¡¨ï¼‰")
    
    # å…¨æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’å¹´åˆ¥ã«é›†è¨ˆ
    df_all = aggregate_by_products(df_items, original_names, aggregate=True)
    
    if df_all.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    df_all['date'] = pd.to_datetime(df_all['date'])
    df_all['å¹´'] = df_all['date'].dt.year
    
    yearly = df_all.groupby('å¹´').agg({
        'è²©å£²å•†å“æ•°': 'sum',
        'è²©å£²ç·å£²ä¸Š': 'sum'
    }).reset_index()
    
    # å‰å¹´æ¯”ã‚’è¨ˆç®—
    yearly['å‰å¹´æ¯”'] = yearly['è²©å£²å•†å“æ•°'].pct_change() * 100
    yearly['å¢—æ¸›æ•°'] = yearly['è²©å£²å•†å“æ•°'].diff()
    
    # ========== è¡¨å½¢å¼ã‚’æœ€åˆã«å¤§ããè¡¨ç¤º ==========
    st.write("**ğŸ“‹ å¹´åˆ¥æ¯”è¼ƒè¡¨**")
    
    # è¦‹ã‚„ã™ã„è¡¨å½¢å¼ã§è¡¨ç¤º
    table_data = []
    for idx, row in yearly.iterrows():
        year = int(row['å¹´'])
        qty = int(row['è²©å£²å•†å“æ•°'])
        diff = row['å¢—æ¸›æ•°']
        pct = row['å‰å¹´æ¯”']
        
        # å¢—æ¸›ã®è¡¨ç¤º
        if pd.notna(diff):
            diff_str = f"{int(diff):+,}ä½“"
            pct_str = f"{pct:+.1f}%"
            if diff > 0:
                eval_str = "ğŸ“ˆ å¢—åŠ "
            elif diff < 0:
                eval_str = "ğŸ“‰ æ¸›å°‘"
            else:
                eval_str = "â¡ï¸ åŒã˜"
        else:
            diff_str = "-"
            pct_str = "-"
            eval_str = "-"
        
        table_data.append({
            'å¹´': f"{year}å¹´",
            'è²©å£²æ•°': f"{qty:,}ä½“",
            'å‰å¹´æ¯”ï¼ˆæ•°ï¼‰': diff_str,
            'å‰å¹´æ¯”ï¼ˆ%ï¼‰': pct_str,
            'è©•ä¾¡': eval_str
        })
    
    display_df = pd.DataFrame(table_data)
    st.dataframe(display_df, use_container_width=True, hide_index=True)
    
    # ========== ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã§æœ€æ–°å¹´ã¨å‰å¹´ã‚’æ¯”è¼ƒ ==========
    if len(yearly) >= 2:
        latest = yearly.iloc[-1]
        prev = yearly.iloc[-2]
        diff = int(latest['è²©å£²å•†å“æ•°'] - prev['è²©å£²å•†å“æ•°'])
        diff_pct = latest['å‰å¹´æ¯”']
        
        st.write("**ğŸ“Š ç›´è¿‘ã®å¹´æ¬¡æ¯”è¼ƒ**")
        col1, col2, col3, col4 = st.columns(4)
        col1.metric(f"ğŸ“… {int(prev['å¹´'])}å¹´", f"{int(prev['è²©å£²å•†å“æ•°']):,}ä½“")
        col2.metric(f"ğŸ“… {int(latest['å¹´'])}å¹´", f"{int(latest['è²©å£²å•†å“æ•°']):,}ä½“")
        col3.metric("ğŸ“Š å¢—æ¸›æ•°", f"{diff:+,}ä½“")
        col4.metric("ğŸ“Š å¢—æ¸›ç‡", f"{diff_pct:+.1f}%")
        
        # ã‚µãƒãƒªãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        if diff > 0:
            st.success(f"âœ… {int(latest['å¹´'])}å¹´ã¯{int(prev['å¹´'])}å¹´ã‚ˆã‚Š **{diff:,}ä½“** å¤šãè²©å£²ï¼ˆ{diff_pct:+.1f}%å¢—ï¼‰")
        elif diff < 0:
            st.warning(f"âš ï¸ {int(latest['å¹´'])}å¹´ã¯{int(prev['å¹´'])}å¹´ã‚ˆã‚Š **{abs(diff):,}ä½“** å°‘ãªãè²©å£²ï¼ˆ{abs(diff_pct):.1f}%æ¸›ï¼‰")
        else:
            st.info(f"â¡ï¸ {int(latest['å¹´'])}å¹´ã¯{int(prev['å¹´'])}å¹´ã¨åŒã˜è²©å£²æ•°")
    
    # ========== ã‚°ãƒ©ãƒ•ã¯è£œåŠ©çš„ã«è¡¨ç¤º ==========
    with st.expander("ğŸ“ˆ ã‚°ãƒ©ãƒ•ã§è¦‹ã‚‹", expanded=False):
        fig = go.Figure()
        fig.add_trace(go.Bar(
            x=yearly['å¹´'].astype(str),
            y=yearly['è²©å£²å•†å“æ•°'],
            name='è²©å£²æ•°',
            marker_color='#4CAF50',
            text=yearly['è²©å£²å•†å“æ•°'].apply(lambda x: f"{int(x):,}"),
            textposition='outside'
        ))
        
        fig.update_layout(
            title='å¹´åˆ¥è²©å£²æ•°æ¨ç§»',
            xaxis_title='å¹´',
            yaxis_title='è²©å£²æ•°ï¼ˆä½“ï¼‰',
            height=350
        )
        st.plotly_chart(fig, use_container_width=True)


def render_forecast_section(sales_data: pd.DataFrame):
    """éœ€è¦äºˆæ¸¬ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆv19: st.formå¯¾å¿œãƒ»ç²¾åº¦å¼·åŒ–ç‰ˆï¼‰"""
    st.markdown('<p class="section-header">â‘£ éœ€è¦ã‚’äºˆæ¸¬ã™ã‚‹</p>', unsafe_allow_html=True)
    
    if sales_data is None or sales_data.empty:
        st.info("å£²ä¸Šãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã¨ã€éœ€è¦äºˆæ¸¬ãŒã§ãã¾ã™")
        return
    
    # ==========================================================================
    # äºˆæ¸¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šï¼ˆst.formã§å›²ã‚“ã§ãƒãƒ©ã¤ãé˜²æ­¢ï¼‰
    # ==========================================================================
    with st.form(key="forecast_form_v19"):
        st.write("### ğŸ¯ äºˆæ¸¬è¨­å®š")
        
        col1, col2 = st.columns(2)
        
        with col1:
            forecast_mode = st.radio(
                "äºˆæ¸¬æœŸé–“ã®æŒ‡å®šæ–¹æ³•",
                ["æ—¥æ•°ã§æŒ‡å®š", "æœŸé–“ã§æŒ‡å®š"],
                horizontal=True,
                key="forecast_mode_existing_v19",
                help="ã€ŒæœŸé–“ã§æŒ‡å®šã€ã¯æœŸé–“é™å®šå“ã®äºˆæ¸¬ã«ä¾¿åˆ©ã§ã™"
            )
        
        with col2:
            available_methods = get_available_forecast_methods()
            # v19: ç²¾åº¦å¼·åŒ–ç‰ˆã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«
            if "ğŸ¯ å­£ç¯€æ€§è€ƒæ…®ï¼ˆç²¾åº¦å¼·åŒ–ç‰ˆï¼‰" in available_methods:
                default_idx = available_methods.index("ğŸ¯ å­£ç¯€æ€§è€ƒæ…®ï¼ˆç²¾åº¦å¼·åŒ–ç‰ˆï¼‰")
            elif "ğŸš€ Vertex AIï¼ˆæ¨å¥¨ï¼‰" in available_methods:
                default_idx = available_methods.index("ğŸš€ Vertex AIï¼ˆæ¨å¥¨ï¼‰")
            else:
                default_idx = 0
            
            method = st.selectbox(
                "äºˆæ¸¬æ–¹æ³•",
                available_methods,
                index=default_idx,
                key="forecast_method_existing_v19"
            )
        
        # äºˆæ¸¬æœŸé–“ã®è¨­å®š
        if forecast_mode == "æ—¥æ•°ã§æŒ‡å®š":
            forecast_days = st.slider("äºˆæ¸¬æ—¥æ•°", 30, 365, 180, key="forecast_days_existing_v19")
            forecast_start_date = None
            forecast_end_date = None
        else:
            # æœŸé–“æŒ‡å®šUI
            today = date.today()
            default_start = today + timedelta(days=1)
            default_end = today + timedelta(days=180)
            
            st.write("**äºˆæ¸¬æœŸé–“æŒ‡å®š**")
            col_s1, col_s2, col_s3, col_e1, col_e2, col_e3 = st.columns([1, 1, 1, 1, 1, 1])
            
            with col_s1:
                start_year = st.selectbox(
                    "äºˆæ¸¬é–‹å§‹å¹´",
                    list(range(2025, 2028)),
                    index=list(range(2025, 2028)).index(default_start.year) if default_start.year in range(2025, 2028) else 0,
                    key="forecast_start_year_v19"
                )
            with col_s2:
                start_month = st.selectbox(
                    "äºˆæ¸¬é–‹å§‹æœˆ",
                    list(range(1, 13)),
                    index=default_start.month - 1,
                    format_func=lambda x: f"{x}æœˆ",
                    key="forecast_start_month_v19"
                )
            with col_s3:
                max_day_start = calendar.monthrange(start_year, start_month)[1]
                start_day = st.selectbox(
                    "äºˆæ¸¬é–‹å§‹æ—¥",
                    list(range(1, max_day_start + 1)),
                    index=min(default_start.day - 1, max_day_start - 1),
                    format_func=lambda x: f"{x}æ—¥",
                    key="forecast_start_day_v19"
                )
            
            with col_e1:
                end_year = st.selectbox(
                    "äºˆæ¸¬çµ‚äº†å¹´",
                    list(range(2025, 2028)),
                    index=list(range(2025, 2028)).index(default_end.year) if default_end.year in range(2025, 2028) else 0,
                    key="forecast_end_year_v19"
                )
            with col_e2:
                end_month = st.selectbox(
                    "äºˆæ¸¬çµ‚äº†æœˆ",
                    list(range(1, 13)),
                    index=default_end.month - 1,
                    format_func=lambda x: f"{x}æœˆ",
                    key="forecast_end_month_v19"
                )
            with col_e3:
                max_day_end = calendar.monthrange(end_year, end_month)[1]
                end_day = st.selectbox(
                    "äºˆæ¸¬çµ‚äº†æ—¥",
                    list(range(1, max_day_end + 1)),
                    index=min(default_end.day - 1, max_day_end - 1),
                    format_func=lambda x: f"{x}æ—¥",
                    key="forecast_end_day_v19"
                )
            
            forecast_start_date = date(start_year, start_month, start_day)
            forecast_end_date = date(end_year, end_month, end_day)
            forecast_days = max(1, (forecast_end_date - forecast_start_date).days + 1)
        
        # ==========================================================================
        # ã€v19æ–°æ©Ÿèƒ½ã€‘ç²¾åº¦å¼·åŒ–ç‰ˆã®è©³ç´°è¨­å®š
        # ==========================================================================
        if "ç²¾åº¦å¼·åŒ–ç‰ˆ" in method:
            with st.expander("âš™ï¸ **è©³ç´°è¨­å®šï¼ˆç²¾åº¦å¼·åŒ–ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰**", expanded=True):
                st.markdown("""
                <div style="background-color: #e8f5e9; padding: 10px; border-radius: 5px; margin-bottom: 10px;">
                    <strong>ğŸ’¡ v19æ–°æ©Ÿèƒ½:</strong> ä»¥ä¸‹ã®è¨­å®šã§äºˆæ¸¬ç²¾åº¦ã‚’èª¿æ•´ã§ãã¾ã™
                </div>
                """, unsafe_allow_html=True)
                
                col_opt1, col_opt2 = st.columns(2)
                
                with col_opt1:
                    baseline_method = st.selectbox(
                        "ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³è¨ˆç®—æ–¹æ³•",
                        options=['median', 'trimmed_mean', 'iqr_mean', 'mean'],
                        format_func=lambda x: {
                            'median': 'ä¸­å¤®å€¤ï¼ˆæ¨å¥¨ãƒ»å¤–ã‚Œå€¤ã«å¼·ã„ï¼‰',
                            'trimmed_mean': 'ãƒˆãƒªãƒ å¹³å‡ï¼ˆä¸Šä¸‹10%é™¤å¤–ï¼‰',
                            'iqr_mean': 'IQRå¹³å‡ï¼ˆå››åˆ†ä½ç¯„å›²å†…ï¼‰',
                            'mean': 'å˜ç´”å¹³å‡ï¼ˆå¾“æ¥æ–¹å¼ï¼‰'
                        }.get(x, x),
                        index=0,
                        key="v19_baseline_method_select",
                        help="æ­£æœˆãªã©ã®ç¹å¿™æœŸãƒ‡ãƒ¼ã‚¿ãŒã‚ã£ã¦ã‚‚å½±éŸ¿ã‚’å—ã‘ã«ãã„è¨ˆç®—æ–¹æ³•ã‚’é¸æŠ"
                    )
                    
                    auto_special_factors = st.checkbox(
                        "ç‰¹åˆ¥æœŸé–“ä¿‚æ•°ã‚’è‡ªå‹•è¨ˆç®—",
                        value=True,
                        key="v19_auto_special_factors_check",
                        help="éå»3å¹´ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ­£æœˆãƒ»ãŠç›†ãƒ»ä¸ƒäº”ä¸‰ãªã©ã®ä¿‚æ•°ã‚’è‡ªå‹•å­¦ç¿’"
                    )
                
                with col_opt2:
                    order_mode = st.selectbox(
                        "ç™ºæ³¨ãƒ¢ãƒ¼ãƒ‰",
                        options=['conservative', 'balanced', 'aggressive'],
                        format_func=lambda x: {
                            'conservative': 'æ»ç•™å›é¿ï¼ˆP50ãƒ»æ§ãˆã‚ï¼‰',
                            'balanced': 'ãƒãƒ©ãƒ³ã‚¹ï¼ˆP80ãƒ»æ¨å¥¨ï¼‰',
                            'aggressive': 'æ¬ å“å›é¿ï¼ˆP90ãƒ»å¤šã‚ï¼‰'
                        }.get(x, x),
                        index=1,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ãƒãƒ©ãƒ³ã‚¹
                        key="v19_order_mode_select",
                        help="æ¬ å“ãƒªã‚¹ã‚¯ã¨åœ¨åº«ãƒªã‚¹ã‚¯ã®ãƒãƒ©ãƒ³ã‚¹ã‚’é¸æŠ"
                    )
                    
                    backtest_days = st.selectbox(
                        "ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæ—¥æ•°",
                        options=[0, 7, 14, 30],
                        format_func=lambda x: f"{x}æ—¥é–“" if x > 0 else "å®Ÿè¡Œã—ãªã„",
                        index=2,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 14æ—¥
                        key="v19_backtest_days_select",
                        help="äºˆæ¸¬ç²¾åº¦ã‚’æ¤œè¨¼ã™ã‚‹ãŸã‚ã®ãƒ›ãƒ¼ãƒ«ãƒ‰ã‚¢ã‚¦ãƒˆæœŸé–“"
                    )
                
                include_quantiles = st.checkbox(
                    "åˆ†ä½ç‚¹äºˆæ¸¬ã‚’å«ã‚ã‚‹ï¼ˆP50/P80/P90ï¼‰",
                    value=True,
                    key="v19_include_quantiles_check",
                    help="äºˆæ¸¬ã®ä¸ç¢ºå®Ÿæ€§ã‚’è€ƒæ…®ã—ãŸç™ºæ³¨æ¨å¥¨"
                )
        else:
            # ç²¾åº¦å¼·åŒ–ç‰ˆä»¥å¤–ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨
            baseline_method = 'median'
            auto_special_factors = True
            order_mode = 'balanced'
            backtest_days = 14
            include_quantiles = False
        
        # å…±å¤‰é‡ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆVertex AIé¸æŠæ™‚ï¼‰
        use_covariates = False
        if "Vertex AI" in method and VERTEX_AI_AVAILABLE:
            use_covariates = st.checkbox(
                "å…±å¤‰é‡ã‚’ä½¿ç”¨ï¼ˆå¤©æ°—ãƒ»å…­æ›œãƒ»ã‚¤ãƒ™ãƒ³ãƒˆï¼‰",
                value=True,
                key="v19_use_covariates",
                help="äºˆæ¸¬ç²¾åº¦ãŒå‘ä¸Šã—ã¾ã™ãŒã€å‡¦ç†æ™‚é–“ãŒé•·ããªã‚‹å ´åˆãŒã‚ã‚Šã¾ã™"
            )
        
        # ==========================================================================
        # äºˆæ¸¬å®Ÿè¡Œãƒœã‚¿ãƒ³
        # ==========================================================================
        submitted = st.form_submit_button(
            "ğŸ”® éœ€è¦ã‚’äºˆæ¸¬",
            type="primary",
            use_container_width=True
        )
    
    # ãƒ•ã‚©ãƒ¼ãƒ å¤–ã«äºˆæ¸¬æ–¹æ³•ã®èª¬æ˜ã‚’è¡¨ç¤º
    method_info = FORECAST_METHODS.get(method, {"icon": "ğŸ“Š", "description": "", "color": "#666"})
    css_class = "vertex-ai" if "Vertex" in method else "seasonality" if "å­£ç¯€" in method else "moving-avg" if "ç§»å‹•" in method else "exponential"
    
    st.markdown(f"""
    <div class="method-card method-{css_class}">
        <strong>{method_info['icon']} {safe_html(method)}</strong><br>
        {safe_html(method_info['description'])}
    </div>
    """, unsafe_allow_html=True)
    
    # ==========================================================================
    # äºˆæ¸¬å®Ÿè¡Œ
    # ==========================================================================
    if submitted:
        # æœŸé–“æŒ‡å®šã®æ¤œè¨¼
        if forecast_mode == "æœŸé–“ã§æŒ‡å®š":
            if forecast_end_date <= forecast_start_date:
                st.error("âš ï¸ çµ‚äº†æ—¥ã¯é–‹å§‹æ—¥ã‚ˆã‚Šå¾Œã«ã—ã¦ãã ã•ã„")
                return
            st.info(f"ğŸ“… äºˆæ¸¬æœŸé–“: {forecast_start_date.strftime('%Yå¹´%mæœˆ%dæ—¥')} ã€œ {forecast_end_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}ï¼ˆ{forecast_days}æ—¥é–“ï¼‰")
        
        with st.spinner("äºˆæ¸¬ä¸­..."):
            try:
                if method == "ğŸ”„ ã™ã¹ã¦ã®æ–¹æ³•ã§æ¯”è¼ƒ":
                    # ã™ã¹ã¦ã®æ–¹æ³•ã§äºˆæ¸¬
                    product_id = "_".join(st.session_state.selected_products[:3])
                    all_results = forecast_all_methods_with_vertex_ai(
                        sales_data, forecast_days, product_id,
                        baseline_method=baseline_method,
                        auto_special_factors=auto_special_factors,
                        backtest_days=backtest_days
                    )
                    display_comparison_results_v19(all_results, forecast_days, sales_data)
                else:
                    # å˜ä¸€ã®äºˆæ¸¬æ–¹æ³•
                    product_id = "_".join(st.session_state.selected_products[:3])
                    
                    forecast, method_message = forecast_with_vertex_ai(
                        sales_data, forecast_days, method, product_id,
                        baseline_method=baseline_method,
                        auto_special_factors=auto_special_factors,
                        include_quantiles=include_quantiles,
                        order_mode=order_mode,
                        backtest_days=backtest_days
                    )
                    
                    if forecast is not None and not forecast.empty:
                        display_single_forecast_result_v19(
                            forecast, forecast_days, method, method_message, 
                            sales_data, order_mode, include_quantiles
                        )
                    else:
                        st.error("äºˆæ¸¬çµæœãŒç©ºã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            except Exception as e:
                # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¯ä¸€èˆ¬çš„ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€è©³ç´°ã¯ãƒ­ã‚°ã¸
                st.error("äºˆæ¸¬ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                logger.error(f"äºˆæ¸¬ã‚¨ãƒ©ãƒ¼ï¼ˆè©³ç´°ï¼‰: {e}")


def display_single_forecast_result_v19(
    forecast: pd.DataFrame, 
    forecast_days: int, 
    method: str, 
    method_message: str, 
    sales_data: pd.DataFrame = None,
    order_mode: str = 'balanced',
    include_quantiles: bool = False
):
    """ã€v19æ–°æ©Ÿèƒ½ã€‘å˜ä¸€ã®äºˆæ¸¬çµæœã‚’è¡¨ç¤ºï¼ˆãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ»åˆ†ä½ç‚¹å¯¾å¿œï¼‰"""
    raw_total = int(forecast['predicted'].sum())
    rounded_total = round_up_to_50(raw_total)
    avg_predicted = forecast['predicted'].mean()
    
    # ==========================================================================
    # äºˆæ¸¬çµæœã‚«ãƒ¼ãƒ‰ï¼ˆv19: æƒ…å ±å……å®Ÿï¼‰
    # ==========================================================================
    if "Vertex AI" in method_message:
        st.success(f"âœ… äºˆæ¸¬å®Œäº†ï¼ï¼ˆğŸš€ {safe_html(method_message)}ï¼‰")
    else:
        st.success(f"âœ… äºˆæ¸¬å®Œäº†ï¼ï¼ˆ{safe_html(method_message)}ï¼‰")
    
    st.session_state.last_forecast_method = method_message
    
    # åŸºæœ¬ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    col1, col2, col3 = st.columns(3)
    col1.metric("ğŸ“¦ äºˆæ¸¬è²©å£²ç·æ•°", f"{rounded_total:,}ä½“")
    col2.metric("ğŸ“ˆ å¹³å‡æ—¥è²©ï¼ˆäºˆæ¸¬ï¼‰", f"{avg_predicted:.1f}ä½“/æ—¥")
    col3.metric("ğŸ“… äºˆæ¸¬æœŸé–“", f"{forecast_days}æ—¥é–“")
    
    # ==========================================================================
    # ã€v19æ–°æ©Ÿèƒ½ã€‘ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã®è¡¨ç¤º
    # ==========================================================================
    if hasattr(forecast, 'attrs') and 'backtest' in forecast.attrs:
        bt = forecast.attrs['backtest']
        if bt.get('available', False):
            st.markdown("---")
            st.write("### ğŸ“Š äºˆæ¸¬ç²¾åº¦ï¼ˆãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœï¼‰")
            
            col_bt1, col_bt2, col_bt3 = st.columns(3)
            
            mape = bt.get('mape')
            mae = bt.get('mae')
            
            with col_bt1:
                if mape is not None:
                    # MAPEè©•ä¾¡ï¼ˆè‰²åˆ†ã‘ï¼‰
                    if mape < 15:
                        mape_color = "good"
                        mape_eval = "âœ… è‰¯å¥½"
                    elif mape < 30:
                        mape_color = "medium"
                        mape_eval = "âš ï¸ æ™®é€š"
                    else:
                        mape_color = "poor"
                        mape_eval = "âŒ è¦æ³¨æ„"
                    
                    st.metric("MAPEï¼ˆå¹³å‡çµ¶å¯¾%èª¤å·®ï¼‰", f"{mape:.1f}%", delta=mape_eval)
                else:
                    st.metric("MAPE", "è¨ˆç®—ä¸å¯")
            
            with col_bt2:
                if mae is not None:
                    st.metric("MAEï¼ˆå¹³å‡çµ¶å¯¾èª¤å·®ï¼‰", f"{mae:.1f}ä½“/æ—¥")
            
            with col_bt3:
                st.metric("æ¤œè¨¼æœŸé–“", f"ç›´è¿‘{bt.get('holdout_days', 14)}æ—¥é–“")
            
            # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆè©³ç´°
            with st.expander("ğŸ“ˆ ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆè©³ç´°ã‚’è¦‹ã‚‹", expanded=False):
                if 'actual' in bt and 'predicted' in bt:
                    bt_df = pd.DataFrame({
                        'å®Ÿç¸¾': bt['actual'],
                        'äºˆæ¸¬': bt['predicted']
                    })
                    bt_df['èª¤å·®'] = bt_df['å®Ÿç¸¾'] - bt_df['äºˆæ¸¬']
                    bt_df['èª¤å·®ç‡(%)'] = ((bt_df['å®Ÿç¸¾'] - bt_df['äºˆæ¸¬']) / bt_df['å®Ÿç¸¾'].replace(0, 1) * 100).round(1)
                    st.dataframe(bt_df, use_container_width=True)
            
            # äºˆæ¸¬ã®ä¿¡é ¼åº¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            if mape is not None:
                if mape < 15:
                    st.info(f"ğŸ’¡ ã“ã®äºˆæ¸¬ã¯é«˜ã„ä¿¡é ¼åº¦ï¼ˆMAPE {mape:.1f}%ï¼‰ã§ã™ã€‚å®‰å¿ƒã—ã¦ç™ºæ³¨è¨ˆç”»ã«æ´»ç”¨ã§ãã¾ã™ã€‚")
                elif mape < 30:
                    st.warning(f"âš ï¸ ã“ã®äºˆæ¸¬ã¯ä¸­ç¨‹åº¦ã®ä¿¡é ¼åº¦ï¼ˆMAPE {mape:.1f}%ï¼‰ã§ã™ã€‚ãƒãƒƒãƒ•ã‚¡ã‚’æŒã£ãŸç™ºæ³¨ã‚’ãŠã™ã™ã‚ã—ã¾ã™ã€‚")
                else:
                    st.error(f"âŒ ã“ã®äºˆæ¸¬ã¯ä¿¡é ¼åº¦ãŒä½ã‚ï¼ˆMAPE {mape:.1f}%ï¼‰ã§ã™ã€‚è¤‡æ•°ã®äºˆæ¸¬æ–¹æ³•ã§æ¯”è¼ƒæ¤œè¨ã—ã¦ãã ã•ã„ã€‚")
    
    # ==========================================================================
    # ã€v19æ–°æ©Ÿèƒ½ã€‘åˆ†ä½ç‚¹äºˆæ¸¬ã¨ç™ºæ³¨æ¨å¥¨
    # ==========================================================================
    if include_quantiles and 'p50' in forecast.columns:
        st.markdown("---")
        st.write("### ğŸ¯ ç™ºæ³¨ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®æ¨å¥¨æ•°é‡")
        
        p50_total = round_up_to_50(int(forecast['p50'].sum()))
        p80_total = round_up_to_50(int(forecast['p80'].sum()))
        p90_total = round_up_to_50(int(forecast['p90'].sum()))
        
        col_q1, col_q2, col_q3 = st.columns(3)
        
        with col_q1:
            highlight = "ğŸ”·" if order_mode == 'conservative' else ""
            st.metric(f"{highlight}æ»ç•™å›é¿ï¼ˆP50ï¼‰", f"{p50_total:,}ä½“", 
                     help="50%ã®ç¢ºç‡ã§ã“ã®æ•°é‡ä»¥ä¸Šå£²ã‚Œã‚‹")
        
        with col_q2:
            highlight = "ğŸ”·" if order_mode == 'balanced' else ""
            st.metric(f"{highlight}ãƒãƒ©ãƒ³ã‚¹ï¼ˆP80ï¼‰", f"{p80_total:,}ä½“",
                     help="80%ã®ç¢ºç‡ã§ã“ã®æ•°é‡ä»¥ä¸Šå£²ã‚Œã‚‹ï¼ˆæ¨å¥¨ï¼‰")
        
        with col_q3:
            highlight = "ğŸ”·" if order_mode == 'aggressive' else ""
            st.metric(f"{highlight}æ¬ å“å›é¿ï¼ˆP90ï¼‰", f"{p90_total:,}ä½“",
                     help="90%ã®ç¢ºç‡ã§ã“ã®æ•°é‡ä»¥ä¸Šå£²ã‚Œã‚‹")
        
        # é¸æŠã•ã‚ŒãŸãƒ¢ãƒ¼ãƒ‰ã‚’å¼·èª¿
        mode_names = {'conservative': 'æ»ç•™å›é¿', 'balanced': 'ãƒãƒ©ãƒ³ã‚¹', 'aggressive': 'æ¬ å“å›é¿'}
        mode_totals = {'conservative': p50_total, 'balanced': p80_total, 'aggressive': p90_total}
        st.info(f"ğŸ”· **ç¾åœ¨ã®ãƒ¢ãƒ¼ãƒ‰: {mode_names[order_mode]}** â†’ æ¨å¥¨ç™ºæ³¨æ•°: **{mode_totals[order_mode]:,}ä½“**")
    
    # ==========================================================================
    # ã€v19æ–°æ©Ÿèƒ½ã€‘ç‰¹åˆ¥æœŸé–“ä¿‚æ•°ã®è¡¨ç¤º
    # ==========================================================================
    if hasattr(forecast, 'attrs') and 'special_factors' in forecast.attrs:
        with st.expander("ğŸ“… ç‰¹åˆ¥æœŸé–“ä¿‚æ•°ã‚’è¦‹ã‚‹", expanded=False):
            sf = forecast.attrs['special_factors']
            st.write("**è‡ªå‹•è¨ˆç®—ã•ã‚ŒãŸç‰¹åˆ¥æœŸé–“ã®ä¿‚æ•°:**")
            
            factor_df = pd.DataFrame([
                {'æœŸé–“': 'æ­£æœˆï¼ˆ1/1ã€œ1/7ï¼‰', 'ä¿‚æ•°': f"{sf.get('new_year', 3.0):.2f}å€"},
                {'æœŸé–“': 'ãŠç›†ï¼ˆ8/13ã€œ8/16ï¼‰', 'ä¿‚æ•°': f"{sf.get('obon', 1.5):.2f}å€"},
                {'æœŸé–“': 'ä¸ƒäº”ä¸‰ï¼ˆ11/10ã€œ11/20ï¼‰', 'ä¿‚æ•°': f"{sf.get('shichigosan', 1.3):.2f}å€"},
                {'æœŸé–“': 'GWï¼ˆ5/3ã€œ5/5ï¼‰', 'ä¿‚æ•°': f"{sf.get('golden_week', 1.3):.2f}å€"},
                {'æœŸé–“': 'å¹´æœ«ï¼ˆ12/28ã€œ12/31ï¼‰', 'ä¿‚æ•°': f"{sf.get('year_end', 1.5):.2f}å€"},
                {'æœŸé–“': 'é€šå¸¸æ—¥', 'ä¿‚æ•°': f"{sf.get('normal', 1.0):.2f}å€"},
            ])
            st.dataframe(factor_df, use_container_width=True, hide_index=True)
    
    # ==========================================================================
    # äºˆæ¸¬ãƒ­ã‚¸ãƒƒã‚¯ã®èª¬æ˜
    # ==========================================================================
    with st.expander("ğŸ“Š äºˆæ¸¬ãƒ­ã‚¸ãƒƒã‚¯ã®è©³ç´°", expanded=False):
        display_forecast_logic_explanation(method, sales_data, forecast, forecast_days, avg_predicted)
    
    # ==========================================================================
    # ã‚°ãƒ©ãƒ•è¡¨ç¤ºï¼ˆã‚¹ãƒãƒ›æœ€é©åŒ–ï¼‰
    # ==========================================================================
    method_info = FORECAST_METHODS.get(method, {"color": "#4285F4"})
    
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=forecast['date'],
        y=forecast['predicted'],
        mode='lines',
        name='äºˆæ¸¬',
        line=dict(color=method_info.get('color', '#4285F4'), width=2)
    ))
    
    # åˆ†ä½ç‚¹ãŒã‚ã‚Œã°å¸¯ã§è¡¨ç¤º
    if 'p50' in forecast.columns and 'p90' in forecast.columns:
        fig.add_trace(go.Scatter(
            x=forecast['date'],
            y=forecast['p90'],
            mode='lines',
            name='P90ï¼ˆæ¬ å“å›é¿ï¼‰',
            line=dict(color='rgba(156, 39, 176, 0.5)', dash='dash'),
            showlegend=True
        ))
        fig.add_trace(go.Scatter(
            x=forecast['date'],
            y=forecast['p50'],
            mode='lines',
            name='P50ï¼ˆæ»ç•™å›é¿ï¼‰',
            line=dict(color='rgba(156, 39, 176, 0.5)', dash='dash'),
            fill='tonexty',
            fillcolor='rgba(156, 39, 176, 0.1)',
            showlegend=True
        ))
    
    # ä¿¡é ¼åŒºé–“ãŒã‚ã‚Œã°è¡¨ç¤ºï¼ˆVertex AIç”¨ï¼‰
    elif 'confidence_lower' in forecast.columns and forecast['confidence_lower'].notna().any():
        fig.add_trace(go.Scatter(
            x=forecast['date'],
            y=forecast['confidence_upper'],
            mode='lines',
            name='ä¸Šé™',
            line=dict(color='rgba(66, 133, 244, 0.3)', dash='dash'),
            showlegend=True
        ))
        fig.add_trace(go.Scatter(
            x=forecast['date'],
            y=forecast['confidence_lower'],
            mode='lines',
            name='ä¸‹é™',
            line=dict(color='rgba(66, 133, 244, 0.3)', dash='dash'),
            fill='tonexty',
            fillcolor='rgba(66, 133, 244, 0.1)',
            showlegend=True
        ))
    
    # ã‚¹ãƒãƒ›æœ€é©åŒ–ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
    layout = get_mobile_chart_layout(f'{safe_html(method)}ã«ã‚ˆã‚‹æ—¥åˆ¥äºˆæ¸¬', height=280)
    layout['xaxis_title'] = 'æ—¥ä»˜'
    layout['yaxis_title'] = 'äºˆæ¸¬è²©å£²æ•°ï¼ˆä½“ï¼‰'
    fig.update_layout(**layout)
    
    st.plotly_chart(fig, use_container_width=True, config=get_mobile_chart_config())
    
    st.session_state.forecast_data = forecast
    st.session_state.forecast_total = rounded_total
    
    # ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚»ã‚¯ã‚·ãƒ§ãƒ³
    product_names = st.session_state.get('selected_products', [])
    factcheck_prompt = generate_factcheck_prompt_single(
        product_names=product_names,
        method=method,
        method_message=method_message,
        sales_data=sales_data,
        forecast=forecast,
        forecast_days=forecast_days,
        raw_total=raw_total,
        rounded_total=rounded_total,
        avg_predicted=avg_predicted
    )
    display_factcheck_section(factcheck_prompt, key_suffix="single_v19")


# æ—§ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¨ã®äº’æ›æ€§ã®ãŸã‚æ®‹ã™
def display_single_forecast_result_v12(forecast: pd.DataFrame, forecast_days: int, method: str, method_message: str, sales_data: pd.DataFrame = None):
    """å˜ä¸€ã®äºˆæ¸¬çµæœã‚’è¡¨ç¤ºï¼ˆv12 äº’æ›æ€§ç¶­æŒç”¨ï¼‰"""
    # v19ç‰ˆã‚’å‘¼ã³å‡ºã—
    display_single_forecast_result_v19(forecast, forecast_days, method, method_message, sales_data)
    product_names = st.session_state.get('selected_products', [])
    factcheck_prompt = generate_factcheck_prompt_single(
        product_names=product_names,
        method=method,
        method_message=method_message,
        sales_data=sales_data,
        forecast=forecast,
        forecast_days=forecast_days,
        raw_total=raw_total,
        rounded_total=rounded_total,
        avg_predicted=avg_predicted
    )
    display_factcheck_section(factcheck_prompt, key_suffix="single")


def display_forecast_logic_explanation(method: str, sales_data: pd.DataFrame, forecast: pd.DataFrame, forecast_days: int, avg_predicted: float):
    """äºˆæ¸¬ãƒ­ã‚¸ãƒƒã‚¯ã®è©³ç´°èª¬æ˜ã‚’è¡¨ç¤º"""
    
    if sales_data is None or sales_data.empty:
        st.write("å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆ
    total_days = len(sales_data)
    total_qty = int(sales_data['è²©å£²å•†å“æ•°'].sum())
    avg_daily = sales_data['è²©å£²å•†å“æ•°'].mean()
    max_daily = sales_data['è²©å£²å•†å“æ•°'].max()
    min_daily = sales_data['è²©å£²å•†å“æ•°'].min()
    
    st.write("#### ğŸ“¥ å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ï¼ˆéå»ã®å®Ÿç¸¾ï¼‰")
    st.write(f"""
    - **åˆ†ææœŸé–“**: {total_days}æ—¥é–“
    - **ç·è²©å£²æ•°**: {total_qty:,}ä½“
    - **å¹³å‡æ—¥è²©**: {avg_daily:.1f}ä½“/æ—¥
    - **æœ€å¤§æ—¥è²©**: {max_daily:.0f}ä½“/æ—¥
    - **æœ€å°æ—¥è²©**: {min_daily:.0f}ä½“/æ—¥
    """)
    
    st.write("#### ğŸ”® äºˆæ¸¬ãƒ­ã‚¸ãƒƒã‚¯")
    
    if "Vertex AI" in method:
        st.write(f"""
        **Vertex AI AutoML Forecasting**
        1. éå»{total_days}æ—¥é–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã«å…¥åŠ›
        2. æ™‚ç³»åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»å‘¨æœŸæ€§ï¼‰ã‚’è‡ªå‹•æ¤œå‡º
        3. å¤©æ°—ãƒ»å…­æ›œãƒ»ã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±ã‚‚è€ƒæ…®ï¼ˆå…±å¤‰é‡ï¼‰
        4. {forecast_days}æ—¥é–“ã®æ—¥åˆ¥äºˆæ¸¬ã‚’ç”Ÿæˆ
        
        **è¨ˆç®—çµæœ**:
        - äºˆæ¸¬å¹³å‡æ—¥è²©: {avg_predicted:.1f}ä½“/æ—¥
        - å®Ÿç¸¾å¹³å‡ã¨ã®å·®: {avg_predicted - avg_daily:+.1f}ä½“/æ—¥ ({((avg_predicted/avg_daily)-1)*100:+.1f}%)
        """)
    
    elif "å­£ç¯€æ€§" in method:
        # æ›œæ—¥åˆ¥å¹³å‡ã‚’è¨ˆç®—
        if 'date' in sales_data.columns:
            sales_data_copy = sales_data.copy()
            sales_data_copy['weekday'] = pd.to_datetime(sales_data_copy['date']).dt.dayofweek
            weekday_avg = sales_data_copy.groupby('weekday')['è²©å£²å•†å“æ•°'].mean()
            weekday_names = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']
            weekday_str = ", ".join([f"{weekday_names[i]}:{weekday_avg.get(i, 0):.1f}" for i in range(7)])
        else:
            weekday_str = "ãƒ‡ãƒ¼ã‚¿ãªã—"
        
        st.write(f"""
        **å­£ç¯€æ€§è€ƒæ…®äºˆæ¸¬**
        1. æ›œæ—¥åˆ¥ã®å¹³å‡è²©å£²æ•°ã‚’è¨ˆç®—
        2. æœˆåˆ¥ã®å­£ç¯€ä¿‚æ•°ã‚’ç®—å‡º
        3. æ›œæ—¥ãƒ‘ã‚¿ãƒ¼ãƒ³ Ã— å­£ç¯€ä¿‚æ•°ã§æ—¥åˆ¥äºˆæ¸¬
        
        **æ›œæ—¥åˆ¥å¹³å‡**: {weekday_str}
        
        **è¨ˆç®—çµæœ**:
        - äºˆæ¸¬å¹³å‡æ—¥è²©: {avg_predicted:.1f}ä½“/æ—¥
        - å®Ÿç¸¾å¹³å‡ã¨ã®å·®: {avg_predicted - avg_daily:+.1f}ä½“/æ—¥ ({((avg_predicted/avg_daily)-1)*100:+.1f}%)
        """)
    
    elif "ç§»å‹•å¹³å‡" in method:
        # ç›´è¿‘30æ—¥ã®å¹³å‡
        recent_30 = sales_data.tail(30)['è²©å£²å•†å“æ•°'].mean() if len(sales_data) >= 30 else avg_daily
        
        st.write(f"""
        **ç§»å‹•å¹³å‡æ³•**
        1. ç›´è¿‘30æ—¥é–“ã®è²©å£²ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
        2. 30æ—¥é–“ã®å¹³å‡å€¤ã‚’åŸºæº–ã¨ã—ã¦äºˆæ¸¬
        
        **ç›´è¿‘30æ—¥å¹³å‡**: {recent_30:.1f}ä½“/æ—¥
        
        **è¨ˆç®—å¼**: äºˆæ¸¬æ—¥è²© = ç›´è¿‘30æ—¥å¹³å‡ = {recent_30:.1f}ä½“/æ—¥
        **äºˆæ¸¬ç·æ•°**: {recent_30:.1f} Ã— {forecast_days}æ—¥ = {recent_30 * forecast_days:.0f}ä½“
        """)
    
    elif "æŒ‡æ•°å¹³æ»‘" in method:
        alpha = 0.3  # å¹³æ»‘åŒ–ä¿‚æ•°
        recent_7 = sales_data.tail(7)['è²©å£²å•†å“æ•°'].mean() if len(sales_data) >= 7 else avg_daily
        
        st.write(f"""
        **æŒ‡æ•°å¹³æ»‘æ³•**
        1. ç›´è¿‘ã®ãƒ‡ãƒ¼ã‚¿ã‚’é‡è¦–ï¼ˆå¹³æ»‘åŒ–ä¿‚æ•° Î±={alpha}ï¼‰
        2. æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã»ã©é«˜ã„é‡ã¿ã§è¨ˆç®—
        
        **ç›´è¿‘7æ—¥å¹³å‡**: {recent_7:.1f}ä½“/æ—¥
        **å…¨æœŸé–“å¹³å‡**: {avg_daily:.1f}ä½“/æ—¥
        
        **è¨ˆç®—å¼**: äºˆæ¸¬ = Î±Ã—ç›´è¿‘ + (1-Î±)Ã—å…¨ä½“ = {alpha}Ã—{recent_7:.1f} + {1-alpha}Ã—{avg_daily:.1f} = {alpha*recent_7 + (1-alpha)*avg_daily:.1f}ä½“/æ—¥
        """)
    
    else:
        st.write(f"""
        **äºˆæ¸¬æ–¹æ³•**: {method}
        - å…¥åŠ›ãƒ‡ãƒ¼ã‚¿: {total_days}æ—¥é–“ã®å®Ÿç¸¾
        - äºˆæ¸¬æœŸé–“: {forecast_days}æ—¥é–“
        - äºˆæ¸¬å¹³å‡æ—¥è²©: {avg_predicted:.1f}ä½“/æ—¥
        """)


def display_comparison_results_v12(all_results: Dict[str, Tuple[pd.DataFrame, str]], forecast_days: int, sales_data: pd.DataFrame = None):
    """ã™ã¹ã¦ã®äºˆæ¸¬æ–¹æ³•ã®æ¯”è¼ƒçµæœã‚’è¡¨ç¤ºï¼ˆv12 ã‚¹ãƒãƒ›æœ€é©åŒ– + äºˆæ¸¬ç·æ•°ä¸€è¦§ï¼‰"""
    st.success("âœ… ã™ã¹ã¦ã®äºˆæ¸¬æ–¹æ³•ã§æ¯”è¼ƒå®Œäº†ï¼")
    
    # å„äºˆæ¸¬æ–¹æ³•ã®äºˆæ¸¬ç·æ•°ã‚’è¨ˆç®—
    method_totals = {}
    for method_name, (forecast, message) in all_results.items():
        raw_total = int(forecast['predicted'].sum())
        rounded_total = round_up_to_50(raw_total)
        avg_predicted = forecast['predicted'].mean()
        method_totals[method_name] = {
            'raw': raw_total,
            'rounded': rounded_total,
            'avg': avg_predicted
        }
    
    # ========== å„äºˆæ¸¬æ–¹æ³•ã®äºˆæ¸¬ç·æ•°ã‚’æ˜ç¢ºã«è¡¨ç¤º ==========
    st.write("### ğŸ“Š å„äºˆæ¸¬æ–¹æ³•ã®äºˆæ¸¬ç·æ•°ï¼ˆç™ºæ³¨æ¨å¥¨æ•°ï¼‰")
    
    # åˆ†ã‹ã‚Šã‚„ã™ã„ãƒªã‚¹ãƒˆå½¢å¼ã§è¡¨ç¤º
    st.markdown("---")
    for method_name, totals in method_totals.items():
        icon = "ğŸš€" if "Vertex" in method_name else "ğŸ“ˆ" if "å­£ç¯€" in method_name else "ğŸ“Š" if "ç§»å‹•" in method_name else "ğŸ“‰"
        short_name = method_name.replace("ï¼ˆçµ±è¨ˆï¼‰", "").replace("ï¼ˆæ¨å¥¨ï¼‰", "")
        st.markdown(f"""
        **{icon} {short_name}**: **{totals['rounded']:,}ä½“**ï¼ˆæ—¥è²© {totals['avg']:.1f}ä½“ã€ç”Ÿå€¤ {totals['raw']:,}ä½“ï¼‰
        """)
    st.markdown("---")
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã§å¤§ããè¡¨ç¤º
    num_methods = len(method_totals)
    cols = st.columns(num_methods)
    
    for i, (method_name, totals) in enumerate(method_totals.items()):
        icon = "ğŸš€" if "Vertex" in method_name else "ğŸ“ˆ" if "å­£ç¯€" in method_name else "ğŸ“Š" if "ç§»å‹•" in method_name else "ğŸ“‰"
        short_name = method_name.replace("ï¼ˆçµ±è¨ˆï¼‰", "").replace("ï¼ˆæ¨å¥¨ï¼‰", "")
        with cols[i]:
            st.metric(
                f"{icon} {short_name}",
                f"{totals['rounded']:,}ä½“",
                f"æ—¥è²© {totals['avg']:.1f}ä½“"
            )
    
    # è©³ç´°è¡¨
    with st.expander("ğŸ“‹ è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º", expanded=False):
        summary_rows = []
        for method_name, totals in method_totals.items():
            icon = "ğŸš€" if "Vertex" in method_name else "ğŸ“ˆ" if "å­£ç¯€" in method_name else "ğŸ“Š" if "ç§»å‹•" in method_name else "ğŸ“‰"
            summary_rows.append({
                'äºˆæ¸¬æ–¹æ³•': f"{icon} {method_name}",
                'äºˆæ¸¬ç·æ•°ï¼ˆç”Ÿå€¤ï¼‰': f"{totals['raw']:,}ä½“",
                'ç™ºæ³¨æ¨å¥¨æ•°ï¼ˆ50å€æ•°ï¼‰': f"{totals['rounded']:,}ä½“",
                'å¹³å‡æ—¥è²©': f"{totals['avg']:.1f}ä½“/æ—¥"
            })
        
        summary_df = pd.DataFrame(summary_rows)
        st.dataframe(summary_df, use_container_width=True, hide_index=True)
    
    # çµ±è¨ˆã‚µãƒãƒªãƒ¼
    all_rounded = [t['rounded'] for t in method_totals.values()]
    all_raw = [t['raw'] for t in method_totals.values()]
    
    st.write("### ğŸ“ˆ äºˆæ¸¬å€¤ã®çµ±è¨ˆ")
    
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("ğŸ“‰ æœ€å°", f"{min(all_rounded):,}ä½“")
    col2.metric("ğŸ“ˆ æœ€å¤§", f"{max(all_rounded):,}ä½“")
    col3.metric("ğŸ“Š å¹³å‡", f"{round_up_to_50(int(sum(all_raw) / len(all_raw))):,}ä½“")
    col4.metric("ğŸ“Š ä¸­å¤®å€¤", f"{round_up_to_50(int(sorted(all_raw)[len(all_raw)//2])):,}ä½“")
    
    # å·®åˆ†ã®è¡¨ç¤º
    if len(all_rounded) >= 2:
        diff = max(all_rounded) - min(all_rounded)
        diff_pct = (max(all_raw) - min(all_raw)) / min(all_raw) * 100 if min(all_raw) > 0 else 0
        st.info(f"ğŸ“ **äºˆæ¸¬å€¤ã®å¹…**: æœ€å°ã€œæœ€å¤§ã§ **{diff:,}ä½“** ã®å·®ï¼ˆ{diff_pct:.1f}%ï¼‰")
    
    method_colors = {
        'Vertex AI': '#4285F4',
        'å­£ç¯€æ€§è€ƒæ…®': '#4CAF50',
        'ç§»å‹•å¹³å‡æ³•': '#1E88E5',
        'æŒ‡æ•°å¹³æ»‘æ³•': '#FF9800'
    }
    
    # æ¯”è¼ƒã‚°ãƒ©ãƒ•ï¼ˆã‚¹ãƒãƒ›æœ€é©åŒ–ï¼‰
    st.write("### ğŸ“ˆ æ—¥åˆ¥äºˆæ¸¬æ¯”è¼ƒã‚°ãƒ©ãƒ•")
    
    fig = go.Figure()
    
    for method_name, (forecast, message) in all_results.items():
        fig.add_trace(go.Scatter(
            x=forecast['date'],
            y=forecast['predicted'],
            mode='lines',
            name=method_name,
            line=dict(color=method_colors.get(method_name, '#666666'), width=2)
        ))
    
    layout = get_mobile_chart_layout('äºˆæ¸¬æ–¹æ³•åˆ¥ã®æ—¥åˆ¥äºˆæ¸¬æ¯”è¼ƒ', height=300)
    layout['xaxis_title'] = 'æ—¥ä»˜'
    layout['yaxis_title'] = 'äºˆæ¸¬è²©å£²æ•°ï¼ˆä½“ï¼‰'
    fig.update_layout(**layout)
    
    st.plotly_chart(fig, use_container_width=True, config=get_mobile_chart_config())
    
    # æ¨å¥¨
    if 'Vertex AI' in all_results:
        st.info("ğŸ’¡ **ãŠã™ã™ã‚**: Vertex AI AutoML Forecastingã¯æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã§å­¦ç¿’æ¸ˆã¿ã®ãŸã‚ã€æœ€ã‚‚ç²¾åº¦ãŒé«˜ã„å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚")
    else:
        st.info("ğŸ’¡ **ãŠã™ã™ã‚**: å­£ç¯€æ€§è€ƒæ…®ã¯æœˆåˆ¥ãƒ»æ›œæ—¥åˆ¥ã®å‚¾å‘ã‚’è€ƒæ…®ã™ã‚‹ãŸã‚ã€çµ±è¨ˆãƒ¢ãƒ‡ãƒ«ã®ä¸­ã§ã¯æœ€ã‚‚ç²¾åº¦ãŒé«˜ã„å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚")
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜ï¼ˆVertex AIãŒã‚ã‚Œã°ãã‚Œã€ãªã‘ã‚Œã°å­£ç¯€æ€§è€ƒæ…®ï¼‰
    if 'Vertex AI' in all_results:
        st.session_state.forecast_data = all_results['Vertex AI'][0]
        st.session_state.forecast_total = method_totals['Vertex AI']['rounded']
    elif 'å­£ç¯€æ€§è€ƒæ…®' in all_results:
        st.session_state.forecast_data = all_results['å­£ç¯€æ€§è€ƒæ…®'][0]
        st.session_state.forecast_total = method_totals['å­£ç¯€æ€§è€ƒæ…®']['rounded']
    
    st.session_state.forecast_results = {k: v[0] for k, v in all_results.items()}
    
    # ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚»ã‚¯ã‚·ãƒ§ãƒ³
    product_names = st.session_state.get('selected_products', [])
    factcheck_prompt = generate_factcheck_prompt_comparison(
        product_names=product_names,
        all_results=all_results,
        method_totals=method_totals,
        forecast_days=forecast_days,
        sales_data=sales_data
    )
    display_factcheck_section(factcheck_prompt, key_suffix="comparison")


def render_individual_analysis(start_date: date, end_date: date):
    """å€‹åˆ¥åˆ†æãƒ¢ãƒ¼ãƒ‰ï¼ˆã‚°ãƒ«ãƒ¼ãƒ—å¯¾å¿œãƒ»å¹´æ¬¡æ¯”è¼ƒãƒ»éƒµé€ã®ã¿å•†å“å¯¾å¿œï¼‰"""
    st.markdown('<p class="section-header">â‘¢ å€‹åˆ¥å£²ä¸Šåˆ†æ</p>', unsafe_allow_html=True)
    
    if not st.session_state.selected_products:
        st.info("æˆä¸å“ã‚’é¸æŠã™ã‚‹ã¨ã€ã“ã“ã«å£²ä¸ŠãŒè¡¨ç¤ºã•ã‚Œã¾ã™")
        return
    
    df_items = st.session_state.data_loader.load_item_sales()
    
    # éƒµé€ãƒ‡ãƒ¼ã‚¿çµ±åˆã‚ªãƒ—ã‚·ãƒ§ãƒ³
    mail_order_enabled = hasattr(config, 'MAIL_ORDER_SPREADSHEET_ID') and config.MAIL_ORDER_SPREADSHEET_ID
    include_mail_orders = False
    
    if mail_order_enabled:
        include_mail_orders = st.checkbox(
            "ğŸ“¬ éƒµé€æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚ã‚‹",
            value=True,
            help="Googleãƒ•ã‚©ãƒ¼ãƒ ã‹ã‚‰ã®éƒµé€ä¾é ¼ã‚‚éœ€è¦ã«å«ã‚ã¾ã™",
            key="individual_include_mail"
        )
    
    # Airãƒ¬ã‚¸ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    if not df_items.empty:
        mask = (df_items['date'] >= pd.Timestamp(start_date)) & (df_items['date'] <= pd.Timestamp(end_date))
        df_filtered = df_items[mask]
    else:
        df_filtered = pd.DataFrame()
    
    # éƒµé€ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    df_mail = pd.DataFrame()
    if include_mail_orders or mail_order_enabled:
        df_mail = st.session_state.data_loader.get_mail_order_summary()
    
    # ã‚°ãƒ«ãƒ¼ãƒ—æ§‹æˆã‚’å–å¾—
    groups_dict = {}  # {ã‚°ãƒ«ãƒ¼ãƒ—ç•ªå·: [å•†å“ãƒªã‚¹ãƒˆ]}
    for product in st.session_state.selected_products:
        group_num = st.session_state.product_groups.get(product, 0)
        if group_num not in groups_dict:
            groups_dict[group_num] = []
        groups_dict[group_num].append(product)
    
    individual_data = {}
    individual_counts = {}
    
    # åˆ†æå˜ä½ã‚’æ§‹ç¯‰ï¼ˆã‚°ãƒ«ãƒ¼ãƒ—0ã®å•†å“ã¯å€‹åˆ¥ã€ãã‚Œä»¥å¤–ã¯ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ï¼‰
    analysis_units = []
    for group_num, products in sorted(groups_dict.items()):
        if group_num == 0:
            # å˜ç‹¬ã®å•†å“ã¯å€‹åˆ¥ã«åˆ†æ
            for product in products:
                analysis_units.append({
                    'name': product,
                    'products': [product],
                    'is_group': False
                })
        else:
            # ã‚°ãƒ«ãƒ¼ãƒ—ã¯ã¾ã¨ã‚ã¦åˆ†æ
            analysis_units.append({
                'name': f"ã‚°ãƒ«ãƒ¼ãƒ—{group_num}: {', '.join(products)}",
                'products': products,
                'is_group': True
            })
    
    # å„åˆ†æå˜ä½ã®ãƒ‡ãƒ¼ã‚¿ã‚’é›†è¨ˆ
    for unit in analysis_units:
        unit_name = unit['name']
        products_in_unit = unit['products']
        
        airregi_count = 0
        mail_order_count = 0
        df_agg_combined = pd.DataFrame()
        
        for product in products_in_unit:
            # Airãƒ¬ã‚¸ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’è©¦ã¿ã‚‹
            original_names = []
            if st.session_state.normalizer:
                original_names = st.session_state.normalizer.get_all_original_names([product])
            
            # Airãƒ¬ã‚¸ãƒ‡ãƒ¼ã‚¿ã®é›†è¨ˆ
            df_agg_airregi = pd.DataFrame()
            if not df_filtered.empty and original_names:
                df_agg_airregi = aggregate_by_products(df_filtered, original_names, aggregate=True)
            
            product_airregi_count = int(df_agg_airregi['è²©å£²å•†å“æ•°'].sum()) if not df_agg_airregi.empty else 0
            airregi_count += product_airregi_count
            
            # éƒµé€ãƒ‡ãƒ¼ã‚¿ã®é›†è¨ˆ
            df_mail_matched = pd.DataFrame()
            if (include_mail_orders or (product_airregi_count == 0 and mail_order_enabled)) and not df_mail.empty:
                matched_rows = []
                
                for _, mail_row in df_mail.iterrows():
                    mail_product = str(mail_row['å•†å“å']).strip()
                    
                    # å•†å“åãŒå®Œå…¨ä¸€è‡´ï¼ˆéƒµé€ã‚·ãƒ¼ãƒˆã®ã¿ã®å•†å“ã®å ´åˆï¼‰
                    if mail_product == product:
                        matched_rows.append(mail_row.copy())
                    # Airãƒ¬ã‚¸ã®å•†å“åã¨ãƒãƒƒãƒãƒ³ã‚°
                    elif original_names:
                        matched_name = match_mail_product_to_airregi(mail_product, original_names)
                        if matched_name:
                            new_row = mail_row.copy()
                            new_row['å•†å“å'] = matched_name
                            matched_rows.append(new_row)
                
                if matched_rows:
                    df_mail_matched = pd.DataFrame(matched_rows)
                    if 'date' in df_mail_matched.columns:
                        df_mail_matched['date'] = pd.to_datetime(df_mail_matched['date'], errors='coerce')
                        mail_mask = (df_mail_matched['date'] >= pd.Timestamp(start_date)) & \
                                   (df_mail_matched['date'] <= pd.Timestamp(end_date))
                        df_mail_matched = df_mail_matched[mail_mask]
                    product_mail_count = int(df_mail_matched['è²©å£²å•†å“æ•°'].sum()) if not df_mail_matched.empty else 0
                    mail_order_count += product_mail_count
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
            if not df_agg_airregi.empty:
                if df_agg_combined.empty:
                    df_agg_combined = df_agg_airregi.copy()
                else:
                    df_agg_combined = pd.concat([df_agg_combined, df_agg_airregi], ignore_index=True)
            
            if not df_mail_matched.empty and (include_mail_orders or product_airregi_count == 0):
                required_cols = ['date', 'è²©å£²å•†å“æ•°', 'è²©å£²ç·å£²ä¸Š', 'è¿”å“å•†å“æ•°']
                available_cols = [c for c in required_cols if c in df_mail_matched.columns]
                if 'date' in available_cols and 'è²©å£²å•†å“æ•°' in available_cols:
                    df_mail_for_merge = df_mail_matched[available_cols].copy()
                    if 'è²©å£²ç·å£²ä¸Š' not in df_mail_for_merge.columns:
                        df_mail_for_merge['è²©å£²ç·å£²ä¸Š'] = 0
                    if 'è¿”å“å•†å“æ•°' not in df_mail_for_merge.columns:
                        df_mail_for_merge['è¿”å“å•†å“æ•°'] = 0
                    if df_agg_combined.empty:
                        df_agg_combined = df_mail_for_merge.copy()
                    else:
                        df_agg_combined = pd.concat([df_agg_combined, df_mail_for_merge], ignore_index=True)
        
        # æ—¥ä»˜ã”ã¨ã«é›†ç´„
        if not df_agg_combined.empty:
            df_agg = df_agg_combined.groupby('date').agg({
                'è²©å£²å•†å“æ•°': 'sum',
                'è²©å£²ç·å£²ä¸Š': 'sum',
                'è¿”å“å•†å“æ•°': 'sum'
            }).reset_index()
            df_agg = df_agg.sort_values('date').reset_index(drop=True)
            individual_data[unit_name] = df_agg
            individual_counts[unit_name] = {'airregi': airregi_count, 'mail': mail_order_count}
    
    st.session_state.individual_sales_data = individual_data
    
    # å„åˆ†æå˜ä½ã®çµæœã‚’è¡¨ç¤º
    for unit_name, df_agg in individual_data.items():
        counts = individual_counts.get(unit_name, {'airregi': 0, 'mail': 0})
        total_qty = counts['airregi'] + counts['mail']
        
        with st.expander(f"ğŸ“¦ **{unit_name}**ï¼ˆåˆè¨ˆ: {total_qty:,}ä½“ï¼‰", expanded=True):
            total_sales = df_agg['è²©å£²ç·å£²ä¸Š'].sum()
            period_days = (end_date - start_date).days + 1
            avg_daily = total_qty / period_days if period_days > 0 else 0
            
            # å¹³æ—¥ãƒ»ä¼‘æ—¥ã®å¹³å‡ã‚’è¨ˆç®—
            df_agg['weekday'] = pd.to_datetime(df_agg['date']).dt.dayofweek
            df_weekday = df_agg[df_agg['weekday'] < 5]
            df_weekend = df_agg[df_agg['weekday'] >= 5]
            avg_weekday = df_weekday['è²©å£²å•†å“æ•°'].mean() if not df_weekday.empty else 0
            avg_weekend = df_weekend['è²©å£²å•†å“æ•°'].mean() if not df_weekend.empty else 0
            
            # åŸºæœ¬ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("ğŸ›’ è²©å£²æ•°é‡åˆè¨ˆ", f"{total_qty:,}ä½“")
            col2.metric("ğŸ’° å£²ä¸Šåˆè¨ˆ", f"Â¥{total_sales:,.0f}")
            col3.metric("ğŸ“ˆ å¹³å‡æ—¥è²©", f"{avg_daily:.1f}ä½“/æ—¥")
            col4.metric("ğŸ“… æœŸé–“", f"{period_days}æ—¥é–“")
            
            # ã‚¨ã‚¢ãƒ¬ã‚¸ã¨éƒµé€ã®å†…è¨³
            col5, col6, col7, col8 = st.columns(4)
            col5.metric("ğŸª Airãƒ¬ã‚¸", f"{counts['airregi']:,}ä½“")
            col6.metric("ğŸ“¬ éƒµé€", f"{counts['mail']:,}ä½“")
            if avg_weekday > 0:
                ratio = avg_weekend / avg_weekday
                col7.metric("ğŸ“Š ä¼‘æ—¥/å¹³æ—¥æ¯”", f"{ratio:.2f}å€")
            
            # ========== å¹´æ¬¡æ¯”è¼ƒï¼ˆå€‹åˆ¥ãƒ¢ãƒ¼ãƒ‰ç”¨ï¼‰ ==========
            render_individual_year_comparison(df_agg, unit_name, start_date, end_date, total_qty)
    
    render_individual_forecast_section()
    render_delivery_section()


def render_individual_year_comparison(df_agg: pd.DataFrame, unit_name: str, start_date: date, end_date: date, current_total: int):
    """å€‹åˆ¥åˆ†æãƒ¢ãƒ¼ãƒ‰ç”¨ã®å¹´æ¬¡æ¯”è¼ƒ"""
    
    with st.expander("ğŸ“Š å¹´æ¬¡æ¯”è¼ƒ", expanded=False):
        if df_agg.empty:
            st.warning("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        df_all = df_agg.copy()
        df_all['date'] = pd.to_datetime(df_all['date'])
        df_all['å¹´'] = df_all['date'].dt.year
        
        yearly = df_all.groupby('å¹´').agg({
            'è²©å£²å•†å“æ•°': 'sum',
            'è²©å£²ç·å£²ä¸Š': 'sum'
        }).reset_index()
        
        if len(yearly) < 1:
            st.info("å¹´æ¬¡æ¯”è¼ƒã«ã¯è¤‡æ•°å¹´ã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™")
            return
        
        # å‰å¹´æ¯”ã‚’è¨ˆç®—
        yearly['å‰å¹´æ¯”'] = yearly['è²©å£²å•†å“æ•°'].pct_change() * 100
        yearly['å¢—æ¸›æ•°'] = yearly['è²©å£²å•†å“æ•°'].diff()
        
        # è¡¨å½¢å¼ã§è¡¨ç¤º
        st.write("**ğŸ“‹ å¹´åˆ¥æ¯”è¼ƒè¡¨**")
        
        table_data = []
        for idx, row in yearly.iterrows():
            year = int(row['å¹´'])
            qty = int(row['è²©å£²å•†å“æ•°'])
            diff = row['å¢—æ¸›æ•°']
            pct = row['å‰å¹´æ¯”']
            
            if pd.notna(diff):
                diff_str = f"{int(diff):+,}ä½“"
                pct_str = f"{pct:+.1f}%"
                eval_str = "ğŸ“ˆ å¢—åŠ " if diff > 0 else ("ğŸ“‰ æ¸›å°‘" if diff < 0 else "â¡ï¸ åŒã˜")
            else:
                diff_str = "-"
                pct_str = "-"
                eval_str = "-"
            
            table_data.append({
                'å¹´': f"{year}å¹´",
                'è²©å£²æ•°': f"{qty:,}ä½“",
                'å‰å¹´æ¯”ï¼ˆæ•°ï¼‰': diff_str,
                'å‰å¹´æ¯”ï¼ˆ%ï¼‰': pct_str,
                'è©•ä¾¡': eval_str
            })
        
        display_df = pd.DataFrame(table_data)
        st.dataframe(display_df, use_container_width=True, hide_index=True)
        
        # ç›´è¿‘ã®å¹´æ¬¡æ¯”è¼ƒ
        if len(yearly) >= 2:
            latest = yearly.iloc[-1]
            prev = yearly.iloc[-2]
            diff = int(latest['è²©å£²å•†å“æ•°'] - prev['è²©å£²å•†å“æ•°'])
            diff_pct = latest['å‰å¹´æ¯”']
            
            if diff > 0:
                st.success(f"âœ… {int(latest['å¹´'])}å¹´ã¯{int(prev['å¹´'])}å¹´ã‚ˆã‚Š **{diff:,}ä½“** å¢—åŠ ï¼ˆ{diff_pct:+.1f}%ï¼‰")
            elif diff < 0:
                st.warning(f"âš ï¸ {int(latest['å¹´'])}å¹´ã¯{int(prev['å¹´'])}å¹´ã‚ˆã‚Š **{abs(diff):,}ä½“** æ¸›å°‘ï¼ˆ{diff_pct:.1f}%ï¼‰")
            else:
                st.info(f"â¡ï¸ {int(latest['å¹´'])}å¹´ã¯{int(prev['å¹´'])}å¹´ã¨åŒã˜è²©å£²æ•°")


def render_individual_forecast_section():
    """å€‹åˆ¥äºˆæ¸¬ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆv19: st.formå¯¾å¿œãƒ»ç²¾åº¦å¼·åŒ–ç‰ˆï¼‰"""
    st.markdown('<p class="section-header">â‘£ å€‹åˆ¥éœ€è¦äºˆæ¸¬</p>', unsafe_allow_html=True)
    
    if not st.session_state.individual_sales_data:
        st.info("å£²ä¸Šãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã¨ã€éœ€è¦äºˆæ¸¬ãŒã§ãã¾ã™")
        return
    
    # ==========================================================================
    # äºˆæ¸¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šï¼ˆst.formã§å›²ã‚“ã§ãƒãƒ©ã¤ãé˜²æ­¢ï¼‰
    # ==========================================================================
    with st.form(key="individual_forecast_form_v19"):
        st.write("### ğŸ¯ äºˆæ¸¬è¨­å®š")
        
        col1, col2 = st.columns(2)
        
        with col1:
            forecast_mode = st.radio(
                "äºˆæ¸¬æœŸé–“ã®æŒ‡å®šæ–¹æ³•",
                ["æ—¥æ•°ã§æŒ‡å®š", "æœŸé–“ã§æŒ‡å®š"],
                horizontal=True,
                key="individual_forecast_mode_v19",
                help="ã€ŒæœŸé–“ã§æŒ‡å®šã€ã¯æœŸé–“é™å®šå“ã®äºˆæ¸¬ã«ä¾¿åˆ©ã§ã™"
            )
        
        with col2:
            available_methods = get_available_forecast_methods()
            # v19: ç²¾åº¦å¼·åŒ–ç‰ˆã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«
            if "ğŸ¯ å­£ç¯€æ€§è€ƒæ…®ï¼ˆç²¾åº¦å¼·åŒ–ç‰ˆï¼‰" in available_methods:
                default_idx = available_methods.index("ğŸ¯ å­£ç¯€æ€§è€ƒæ…®ï¼ˆç²¾åº¦å¼·åŒ–ç‰ˆï¼‰")
            elif "ğŸš€ Vertex AIï¼ˆæ¨å¥¨ï¼‰" in available_methods:
                default_idx = available_methods.index("ğŸš€ Vertex AIï¼ˆæ¨å¥¨ï¼‰")
            else:
                default_idx = 0
            
            method = st.selectbox(
                "äºˆæ¸¬æ–¹æ³•",
                available_methods,
                index=default_idx,
                key="individual_forecast_method_v19"
            )
        
        # äºˆæ¸¬æœŸé–“ã®è¨­å®š
        if forecast_mode == "æ—¥æ•°ã§æŒ‡å®š":
            forecast_days = st.slider("äºˆæ¸¬æ—¥æ•°", 30, 365, 180, key="individual_forecast_days_v19")
            forecast_start_date = None
            forecast_end_date = None
        else:
            # æœŸé–“æŒ‡å®šUI
            today = date.today()
            default_start = today + timedelta(days=1)
            default_end = today + timedelta(days=180)
            
            st.write("**äºˆæ¸¬æœŸé–“æŒ‡å®š**")
            col_s1, col_s2, col_s3, col_e1, col_e2, col_e3 = st.columns([1, 1, 1, 1, 1, 1])
            
            with col_s1:
                start_year = st.selectbox(
                    "äºˆæ¸¬é–‹å§‹å¹´",
                    list(range(2025, 2028)),
                    index=list(range(2025, 2028)).index(default_start.year) if default_start.year in range(2025, 2028) else 0,
                    key="ind_forecast_start_year_v19"
                )
            with col_s2:
                start_month = st.selectbox(
                    "äºˆæ¸¬é–‹å§‹æœˆ",
                    list(range(1, 13)),
                    index=default_start.month - 1,
                    format_func=lambda x: f"{x}æœˆ",
                    key="ind_forecast_start_month_v19"
                )
            with col_s3:
                max_day_start = calendar.monthrange(start_year, start_month)[1]
                start_day = st.selectbox(
                    "äºˆæ¸¬é–‹å§‹æ—¥",
                    list(range(1, max_day_start + 1)),
                    index=min(default_start.day - 1, max_day_start - 1),
                    format_func=lambda x: f"{x}æ—¥",
                    key="ind_forecast_start_day_v19"
                )
            
            with col_e1:
                end_year = st.selectbox(
                    "äºˆæ¸¬çµ‚äº†å¹´",
                    list(range(2025, 2028)),
                    index=list(range(2025, 2028)).index(default_end.year) if default_end.year in range(2025, 2028) else 0,
                    key="ind_forecast_end_year_v19"
                )
            with col_e2:
                end_month = st.selectbox(
                    "äºˆæ¸¬çµ‚äº†æœˆ",
                    list(range(1, 13)),
                    index=default_end.month - 1,
                    format_func=lambda x: f"{x}æœˆ",
                    key="ind_forecast_end_month_v19"
                )
            with col_e3:
                max_day_end = calendar.monthrange(end_year, end_month)[1]
                end_day = st.selectbox(
                    "äºˆæ¸¬çµ‚äº†æ—¥",
                    list(range(1, max_day_end + 1)),
                    index=min(default_end.day - 1, max_day_end - 1),
                    format_func=lambda x: f"{x}æ—¥",
                    key="ind_forecast_end_day_v19"
                )
            
            forecast_start_date = date(start_year, start_month, start_day)
            forecast_end_date = date(end_year, end_month, end_day)
            forecast_days = max(1, (forecast_end_date - forecast_start_date).days + 1)
        
        # ==========================================================================
        # ã€v19æ–°æ©Ÿèƒ½ã€‘ç²¾åº¦å¼·åŒ–ç‰ˆã®è©³ç´°è¨­å®š
        # ==========================================================================
        if "ç²¾åº¦å¼·åŒ–ç‰ˆ" in method:
            with st.expander("âš™ï¸ **è©³ç´°è¨­å®šï¼ˆç²¾åº¦å¼·åŒ–ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰**", expanded=False):
                col_opt1, col_opt2 = st.columns(2)
                
                with col_opt1:
                    baseline_method = st.selectbox(
                        "ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³è¨ˆç®—æ–¹æ³•",
                        options=['median', 'trimmed_mean', 'iqr_mean', 'mean'],
                        format_func=lambda x: {
                            'median': 'ä¸­å¤®å€¤ï¼ˆæ¨å¥¨ï¼‰',
                            'trimmed_mean': 'ãƒˆãƒªãƒ å¹³å‡',
                            'iqr_mean': 'IQRå¹³å‡',
                            'mean': 'å˜ç´”å¹³å‡'
                        }.get(x, x),
                        index=0,
                        key="ind_v19_baseline_method"
                    )
                    
                    auto_special_factors = st.checkbox(
                        "ç‰¹åˆ¥æœŸé–“ä¿‚æ•°ã‚’è‡ªå‹•è¨ˆç®—",
                        value=True,
                        key="ind_v19_auto_special_factors"
                    )
                
                with col_opt2:
                    order_mode = st.selectbox(
                        "ç™ºæ³¨ãƒ¢ãƒ¼ãƒ‰",
                        options=['conservative', 'balanced', 'aggressive'],
                        format_func=lambda x: {
                            'conservative': 'æ»ç•™å›é¿ï¼ˆP50ï¼‰',
                            'balanced': 'ãƒãƒ©ãƒ³ã‚¹ï¼ˆP80ï¼‰',
                            'aggressive': 'æ¬ å“å›é¿ï¼ˆP90ï¼‰'
                        }.get(x, x),
                        index=1,
                        key="ind_v19_order_mode"
                    )
                    
                    backtest_days = st.selectbox(
                        "ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæ—¥æ•°",
                        options=[0, 7, 14, 30],
                        format_func=lambda x: f"{x}æ—¥é–“" if x > 0 else "å®Ÿè¡Œã—ãªã„",
                        index=2,
                        key="ind_v19_backtest_days"
                    )
                
                include_quantiles = st.checkbox(
                    "åˆ†ä½ç‚¹äºˆæ¸¬ã‚’å«ã‚ã‚‹ï¼ˆP50/P80/P90ï¼‰",
                    value=True,
                    key="ind_v19_include_quantiles"
                )
                
                # ==========================================================================
                # ã€v20æ–°æ©Ÿèƒ½ã€‘ç²¾åº¦å‘ä¸Šã‚ªãƒ—ã‚·ãƒ§ãƒ³
                # ==========================================================================
                st.markdown("---")
                st.markdown("**ğŸ“ˆ v20 ç²¾åº¦å‘ä¸Šã‚ªãƒ—ã‚·ãƒ§ãƒ³**")
                
                col_v20_1, col_v20_2 = st.columns(2)
                
                with col_v20_1:
                    enable_zero_fill = st.checkbox(
                        "0åŸ‹ã‚å‡¦ç†ï¼ˆæ¨å¥¨ï¼‰",
                        value=True,
                        help="å£²ä¸ŠãŒãªã„æ—¥ã‚’0ã§è£œå®Œã—ã€æ­£ç¢ºãªæ›œæ—¥ãƒ»å­£ç¯€ä¿‚æ•°ã‚’è¨ˆç®—ã—ã¾ã™",
                        key="ind_v20_zero_fill"
                    )
                    
                    enable_trend = st.checkbox(
                        "ãƒˆãƒ¬ãƒ³ãƒ‰ä¿‚æ•°ï¼ˆå‰å¹´æ¯”ï¼‰",
                        value=True,
                        help="ç›´è¿‘ã®å£²ä¸Šã¨å‰å¹´åŒæœŸã‚’æ¯”è¼ƒã—ã€æˆé•·/è¡°é€€ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’åæ˜ ã—ã¾ã™",
                        key="ind_v20_trend"
                    )
                
                with col_v20_2:
                    use_daily_new_year = st.checkbox(
                        "æ­£æœˆæ—¥åˆ¥ä¿‚æ•°ï¼ˆ1/1ã€œ1/7ï¼‰",
                        value=True,
                        help="æ­£æœˆã‚’æ—¥åˆ¥ã«ä¿‚æ•°è¨­å®šã—ã€å…ƒæ—¥ã®ãƒ”ãƒ¼ã‚¯ã‚’æ­£ç¢ºã«æ‰ãˆã¾ã™",
                        key="ind_v20_daily_new_year"
                    )
                    
                    trend_window_days = st.selectbox(
                        "ãƒˆãƒ¬ãƒ³ãƒ‰æ¯”è¼ƒæœŸé–“",
                        options=[30, 60, 90],
                        format_func=lambda x: f"ç›´è¿‘{x}æ—¥é–“",
                        index=1,
                        key="ind_v20_trend_window"
                    )
                
                # æ¬ å“æœŸé–“ã®å…¥åŠ›
                st.markdown("**ğŸš« æ¬ å“æœŸé–“ã®é™¤å¤–**")
                st.caption("åœ¨åº«åˆ‡ã‚ŒæœŸé–“ã‚’æŒ‡å®šã™ã‚‹ã¨ã€ãã®æœŸé–“ã¯å­¦ç¿’ã‹ã‚‰é™¤å¤–ã•ã‚Œã¾ã™")
                
                col_stock1, col_stock2, col_stock3 = st.columns([2, 2, 1])
                
                with col_stock1:
                    stockout_start = st.date_input(
                        "æ¬ å“é–‹å§‹æ—¥",
                        value=None,
                        key="ind_v20_stockout_start"
                    )
                
                with col_stock2:
                    stockout_end = st.date_input(
                        "æ¬ å“çµ‚äº†æ—¥",
                        value=None,
                        key="ind_v20_stockout_end"
                    )
                
                with col_stock3:
                    add_stockout = st.button("è¿½åŠ ", key="ind_v20_add_stockout")
                
                # æ¬ å“æœŸé–“ã®è¿½åŠ å‡¦ç†
                if add_stockout and stockout_start and stockout_end:
                    if stockout_start <= stockout_end:
                        new_period = (stockout_start, stockout_end)
                        if new_period not in st.session_state.v20_stockout_periods:
                            st.session_state.v20_stockout_periods.append(new_period)
                            st.success(f"æ¬ å“æœŸé–“ã‚’è¿½åŠ ã—ã¾ã—ãŸ: {stockout_start} ã€œ {stockout_end}")
                    else:
                        st.warning("çµ‚äº†æ—¥ã¯é–‹å§‹æ—¥ä»¥é™ã«ã—ã¦ãã ã•ã„")
                
                # ç™»éŒ²æ¸ˆã¿æ¬ å“æœŸé–“ã®è¡¨ç¤º
                if st.session_state.v20_stockout_periods:
                    st.markdown("**ç™»éŒ²æ¸ˆã¿æ¬ å“æœŸé–“:**")
                    for i, (s, e) in enumerate(st.session_state.v20_stockout_periods):
                        col_p1, col_p2 = st.columns([4, 1])
                        with col_p1:
                            st.text(f"  {i+1}. {s} ã€œ {e}")
                        with col_p2:
                            if st.button("å‰Šé™¤", key=f"del_stockout_{i}"):
                                st.session_state.v20_stockout_periods.pop(i)
                                st.rerun()
                    
                    if st.button("ã™ã¹ã¦ã‚¯ãƒªã‚¢", key="clear_all_stockout"):
                        st.session_state.v20_stockout_periods = []
                        st.rerun()
                
                # v20ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®å–å¾—
                stockout_periods = st.session_state.v20_stockout_periods if st.session_state.v20_stockout_periods else None
        else:
            # ç²¾åº¦å¼·åŒ–ç‰ˆä»¥å¤–ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            baseline_method = 'median'
            auto_special_factors = True
            order_mode = 'balanced'
            backtest_days = 14
            include_quantiles = False
            # v20ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            enable_zero_fill = True
            enable_trend = True
            use_daily_new_year = True
            trend_window_days = 60
            stockout_periods = None
        
        # ==========================================================================
        # äºˆæ¸¬å®Ÿè¡Œãƒœã‚¿ãƒ³
        # ==========================================================================
        submitted = st.form_submit_button(
            "ğŸ”® å€‹åˆ¥ã«éœ€è¦äºˆæ¸¬ã‚’å®Ÿè¡Œ",
            type="primary",
            use_container_width=True
        )
    
    # ãƒ•ã‚©ãƒ¼ãƒ å¤–ã«äºˆæ¸¬æ–¹æ³•ã®èª¬æ˜ã‚’è¡¨ç¤º
    method_info = FORECAST_METHODS.get(method, {"icon": "ğŸ“Š", "description": "", "color": "#666"})
    st.markdown(f"""
    <div class="analysis-card">
        <strong>{method_info['icon']} {safe_html(method)}</strong><br>
        {safe_html(method_info['description'])}
    </div>
    """, unsafe_allow_html=True)
    
    # ==========================================================================
    # äºˆæ¸¬å®Ÿè¡Œ
    # ==========================================================================
    if submitted:
        # æœŸé–“æŒ‡å®šã®æ¤œè¨¼
        if forecast_mode == "æœŸé–“ã§æŒ‡å®š":
            if forecast_end_date <= forecast_start_date:
                st.error("âš ï¸ çµ‚äº†æ—¥ã¯é–‹å§‹æ—¥ã‚ˆã‚Šå¾Œã«ã—ã¦ãã ã•ã„")
                return
            st.info(f"ğŸ“… äºˆæ¸¬æœŸé–“: {forecast_start_date.strftime('%Yå¹´%mæœˆ%dæ—¥')} ã€œ {forecast_end_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}ï¼ˆ{forecast_days}æ—¥é–“ï¼‰")
        
        with st.spinner("äºˆæ¸¬ä¸­..."):
            # ã€Œã™ã¹ã¦ã®æ–¹æ³•ã§æ¯”è¼ƒã€ãŒé¸ã°ã‚ŒãŸå ´åˆ
            if method == "ğŸ”„ ã™ã¹ã¦ã®æ–¹æ³•ã§æ¯”è¼ƒ":
                # ãƒãƒˆãƒªãƒƒã‚¯ã‚¹å½¢å¼ã§çµæœã‚’ä¿å­˜
                matrix_results = {}
                method_names = []
                backtest_info = {}
                
                for product, sales_data in st.session_state.individual_sales_data.items():
                    try:
                        method_results = forecast_all_methods_with_vertex_ai(
                            sales_data, forecast_days, product,
                            baseline_method=baseline_method,
                            auto_special_factors=auto_special_factors,
                            backtest_days=backtest_days
                        )
                        
                        matrix_results[product] = {}
                        for method_name, (forecast_df, message) in method_results.items():
                            if method_name not in method_names:
                                method_names.append(method_name)
                            
                            raw_total = int(forecast_df['predicted'].sum())
                            rounded_total = round_up_to_50(raw_total)
                            matrix_results[product][method_name] = rounded_total
                            
                            # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæƒ…å ±ã‚’åé›†
                            if hasattr(forecast_df, 'attrs') and 'backtest' in forecast_df.attrs:
                                bt = forecast_df.attrs['backtest']
                                if bt.get('mape') is not None:
                                    if method_name not in backtest_info:
                                        backtest_info[method_name] = []
                                    backtest_info[method_name].append(bt['mape'])
                    except Exception as e:
                        st.warning(f"{safe_html(product)}ã®äºˆæ¸¬ã«å¤±æ•—ã—ã¾ã—ãŸ")
                        logger.error(f"{product}ã®äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
                
                if matrix_results:
                    st.success("âœ… ã™ã¹ã¦ã®äºˆæ¸¬æ–¹æ³•ã§æ¯”è¼ƒå®Œäº†ï¼")
                    
                    # ãƒãƒˆãƒªãƒƒã‚¯ã‚¹å½¢å¼ã®è¡¨ã‚’ä½œæˆ
                    st.write("### ğŸ“Š å•†å“Ã—äºˆæ¸¬æ–¹æ³• ãƒãƒˆãƒªãƒƒã‚¯ã‚¹è¡¨")
                    
                    table_data = []
                    method_totals = {m: 0 for m in method_names}
                    
                    for product, methods in matrix_results.items():
                        row = {'å•†å“å': product}
                        for method_name in method_names:
                            value = methods.get(method_name, 0)
                            row[method_name] = f"{value:,}ä½“"
                            method_totals[method_name] += value
                        table_data.append(row)
                    
                    # åˆè¨ˆè¡Œã‚’è¿½åŠ 
                    total_row = {'å•†å“å': '**åˆè¨ˆ**'}
                    for method_name in method_names:
                        total_row[method_name] = f"**{method_totals[method_name]:,}ä½“**"
                    table_data.append(total_row)
                    
                    df_matrix = pd.DataFrame(table_data)
                    st.dataframe(df_matrix, use_container_width=True, hide_index=True)
                    
                    # äºˆæ¸¬æ–¹æ³•ã”ã¨ã®åˆè¨ˆã‚’ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã§è¡¨ç¤º
                    st.write("### ğŸ“ˆ äºˆæ¸¬æ–¹æ³•åˆ¥ åˆè¨ˆ")
                    
                    num_methods = len(method_names)
                    cols = st.columns(min(num_methods, 4))
                    for i, method_name in enumerate(method_names):
                        icon = "ğŸš€" if "Vertex" in method_name else "ğŸ¯" if "ç²¾åº¦å¼·åŒ–" in method_name else "ğŸ“ˆ" if "å­£ç¯€" in method_name else "ğŸ“Š" if "ç§»å‹•" in method_name else "ğŸ“‰"
                        short_name = method_name.replace("ï¼ˆçµ±è¨ˆï¼‰", "").replace("ï¼ˆæ¨å¥¨ï¼‰", "")
                        
                        # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå¹³å‡MAPE
                        mape_str = ""
                        if method_name in backtest_info and backtest_info[method_name]:
                            avg_mape = sum(backtest_info[method_name]) / len(backtest_info[method_name])
                            mape_str = f"MAPE {avg_mape:.1f}%"
                        
                        with cols[i % 4]:
                            st.metric(f"{icon} {safe_html(short_name)}", f"{method_totals[method_name]:,}ä½“", mape_str if mape_str else None)
                    
                    # session_stateã«ä¿å­˜
                    st.session_state.individual_all_methods_results = matrix_results
                    
                    # ç²¾åº¦å¼·åŒ–ç‰ˆå„ªå…ˆã€ãªã‘ã‚Œã°å­£ç¯€æ€§è€ƒæ…®ã‚’ä½¿ç”¨
                    preferred_method = 'ç²¾åº¦å¼·åŒ–ç‰ˆ' if 'ç²¾åº¦å¼·åŒ–ç‰ˆ' in method_names else ('å­£ç¯€æ€§è€ƒæ…®' if 'å­£ç¯€æ€§è€ƒæ…®' in method_names else method_names[0])
                    
                    forecast_results_for_delivery = []
                    for product, methods in matrix_results.items():
                        forecast_results_for_delivery.append({
                            'product': product,
                            'forecast': None,
                            'raw_total': methods.get(preferred_method, 0),
                            'rounded_total': methods.get(preferred_method, 0),
                            'avg_predicted': methods.get(preferred_method, 0) / forecast_days if forecast_days > 0 else 0,
                            'method_message': f'{preferred_method}ï¼ˆã™ã¹ã¦ã®æ–¹æ³•ã§æ¯”è¼ƒã‹ã‚‰ï¼‰'
                        })
                    
                    st.session_state.individual_forecast_results = forecast_results_for_delivery
                    
                    if preferred_method in method_totals:
                        st.session_state.forecast_total = method_totals[preferred_method]
                    elif method_totals:
                        st.session_state.forecast_total = method_totals[method_names[0]]
                    
                    st.session_state.last_forecast_method = f'{preferred_method}ï¼ˆã™ã¹ã¦ã®æ–¹æ³•ã§æ¯”è¼ƒï¼‰'
                    
                    # ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                    product_names = list(matrix_results.keys())
                    factcheck_prompt = generate_factcheck_prompt_matrix(
                        matrix_results=matrix_results,
                        method_names=method_names,
                        method_totals=method_totals,
                        forecast_days=forecast_days,
                        sales_data_dict=st.session_state.individual_sales_data
                    )
                    display_factcheck_section(factcheck_prompt, key_suffix="individual_matrix_v19")
                    
                    st.rerun()
            else:
                # é€šå¸¸ã®å˜ä¸€äºˆæ¸¬æ–¹æ³•ã®å ´åˆ
                results = []
                
                for product, sales_data in st.session_state.individual_sales_data.items():
                    try:
                        forecast, method_message = forecast_with_vertex_ai(
                            sales_data, forecast_days, method, product,
                            baseline_method=baseline_method,
                            auto_special_factors=auto_special_factors,
                            include_quantiles=include_quantiles,
                            order_mode=order_mode,
                            backtest_days=backtest_days,
                            # v20ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                            enable_zero_fill=enable_zero_fill,
                            stockout_periods=stockout_periods,
                            enable_trend=enable_trend,
                            use_daily_new_year=use_daily_new_year,
                            trend_window_days=trend_window_days
                        )
                        
                        if forecast is not None and not forecast.empty:
                            raw_total = int(forecast['predicted'].sum())
                            rounded_total = round_up_to_50(raw_total)
                            avg_predicted = forecast['predicted'].mean()
                            
                            results.append({
                                'product': product,
                                'forecast': forecast,
                                'raw_total': raw_total,
                                'rounded_total': rounded_total,
                                'avg_predicted': avg_predicted,
                                'method_message': method_message
                            })
                    except Exception as e:
                        import traceback
                        error_detail = traceback.format_exc()
                        st.warning(f"{safe_html(product)}ã®äºˆæ¸¬ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)[:100]}")
                        logger.error(f"{product}ã®äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}\n{error_detail}")
                
                if results:
                    # ç´å“è¨ˆç”»ã§ä½¿ãˆã‚‹ã‚ˆã†ã«session_stateã«ä¿å­˜
                    if len(results) == 1:
                        st.session_state.forecast_data = results[0]['forecast']
                    else:
                        combined_forecast = results[0]['forecast'].copy()
                        combined_forecast = combined_forecast.rename(columns={'predicted': 'predicted_sum'})
                        
                        for r in results[1:]:
                            merged = combined_forecast.merge(
                                r['forecast'][['date', 'predicted']], 
                                on='date', 
                                how='outer'
                            )
                            merged['predicted_sum'] = merged['predicted_sum'].fillna(0) + merged['predicted'].fillna(0)
                            merged = merged.drop(columns=['predicted'])
                            combined_forecast = merged
                        
                        combined_forecast = combined_forecast.rename(columns={'predicted_sum': 'predicted'})
                        st.session_state.forecast_data = combined_forecast
                    
                    total_all = sum(r['rounded_total'] for r in results)
                    st.session_state.forecast_total = total_all
                    st.session_state.last_forecast_method = results[0]['method_message'] if results else ""
                    st.session_state.individual_forecast_results = results
                    st.rerun()  # ç´å“ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ›´æ–°ã™ã‚‹ãŸã‚å†æç”»
    
    # äºˆæ¸¬çµæœã®è¡¨ç¤ºï¼ˆsession_stateã‹ã‚‰ï¼‰
    # ã€Œã™ã¹ã¦ã®æ–¹æ³•ã§æ¯”è¼ƒã€ã®ãƒãƒˆãƒªãƒƒã‚¯ã‚¹çµæœãŒã‚ã‚‹å ´åˆ
    if st.session_state.get('individual_all_methods_results'):
        matrix_results = st.session_state.individual_all_methods_results
        method_names = []
        for product_methods in matrix_results.values():
            for method_name in product_methods.keys():
                if method_name not in method_names:
                    method_names.append(method_name)
        
        st.success("âœ… ã™ã¹ã¦ã®äºˆæ¸¬æ–¹æ³•ã§æ¯”è¼ƒå®Œäº†ï¼")
        
        # ãƒãƒˆãƒªãƒƒã‚¯ã‚¹å½¢å¼ã®è¡¨ã‚’ä½œæˆ
        st.write("### ğŸ“Š å•†å“Ã—äºˆæ¸¬æ–¹æ³• ãƒãƒˆãƒªãƒƒã‚¯ã‚¹è¡¨")
        
        table_data = []
        method_totals = {m: 0 for m in method_names}
        
        for product, methods in matrix_results.items():
            row = {'å•†å“å': product}
            for method_name in method_names:
                value = methods.get(method_name, 0)
                row[method_name] = f"{value:,}ä½“"
                method_totals[method_name] += value
            table_data.append(row)
        
        # åˆè¨ˆè¡Œã‚’è¿½åŠ 
        total_row = {'å•†å“å': '**åˆè¨ˆ**'}
        for method_name in method_names:
            total_row[method_name] = f"**{method_totals[method_name]:,}ä½“**"
        table_data.append(total_row)
        
        df_matrix = pd.DataFrame(table_data)
        st.dataframe(df_matrix, use_container_width=True, hide_index=True)
        
        # äºˆæ¸¬æ–¹æ³•ã”ã¨ã®åˆè¨ˆã‚’ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã§è¡¨ç¤º
        st.write("### ğŸ“ˆ äºˆæ¸¬æ–¹æ³•åˆ¥ åˆè¨ˆ")
        
        num_methods = len(method_names)
        cols = st.columns(min(num_methods, 4))
        for i, method_name in enumerate(method_names):
            icon = "ğŸš€" if "Vertex" in method_name else "ğŸ“ˆ" if "å­£ç¯€" in method_name else "ğŸ“Š" if "ç§»å‹•" in method_name else "ğŸ“‰"
            short_name = method_name.replace("ï¼ˆçµ±è¨ˆï¼‰", "").replace("ï¼ˆæ¨å¥¨ï¼‰", "")
            with cols[i % 4]:
                st.metric(f"{icon} {short_name}", f"{method_totals[method_name]:,}ä½“")
        
        # ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆãƒãƒˆãƒªãƒƒã‚¯ã‚¹ï¼‰
        individual_sales_data = st.session_state.get('individual_sales_data', {})
        # forecast_daysã‚’å–å¾—ï¼ˆsession_stateã®å€‹åˆ¥äºˆæ¸¬çµæœã‹ã‚‰æ¨æ¸¬ï¼‰
        forecast_days_matrix = 180  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        if st.session_state.get('individual_forecast_results'):
            first_result = st.session_state.individual_forecast_results[0]
            if first_result.get('forecast') is not None and not first_result['forecast'].empty:
                forecast_days_matrix = len(first_result['forecast'])
        
        factcheck_prompt_matrix = generate_factcheck_prompt_matrix(
            matrix_results=matrix_results,
            method_names=method_names,
            method_totals=method_totals,
            forecast_days=forecast_days_matrix,
            individual_sales_data=individual_sales_data
        )
        display_factcheck_section(factcheck_prompt_matrix, key_suffix="matrix")
    
    # é€šå¸¸ã®äºˆæ¸¬çµæœãŒã‚ã‚‹å ´åˆ
    elif 'individual_forecast_results' in st.session_state and st.session_state.individual_forecast_results:
        results = st.session_state.individual_forecast_results
        st.success(f"âœ… {len(results)}ä»¶ã®æˆä¸å“ã®äºˆæ¸¬ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        
        summary_df = pd.DataFrame([
            {
                'æˆä¸å“': r['product'],
                'äºˆæ¸¬ç·æ•°': f"{r['rounded_total']:,}ä½“",
                'å¹³å‡æ—¥è²©': f"{r['avg_predicted']:.1f}ä½“/æ—¥",
                'ç™ºæ³¨æ¨å¥¨æ•°ï¼ˆ50å€æ•°ï¼‰': r['rounded_total']
            }
            for r in results
        ])
        st.dataframe(summary_df, use_container_width=True, hide_index=True)
        
        total_all = sum(r['rounded_total'] for r in results)
        st.metric("ğŸ“¦ å…¨ä½“ã®äºˆæ¸¬ç·æ•°", f"{total_all:,}ä½“")
        
        # ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆå€‹åˆ¥äºˆæ¸¬ï¼‰
        individual_sales_data = st.session_state.get('individual_sales_data', {})
        # forecast_daysã‚’å–å¾—
        forecast_days_individual = 180  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        if results and results[0].get('forecast') is not None:
            forecast_df = results[0]['forecast']
            if forecast_df is not None and not forecast_df.empty:
                forecast_days_individual = len(forecast_df)
        
        factcheck_prompt_individual = generate_factcheck_prompt_individual(
            results=results,
            forecast_days=forecast_days_individual,
            individual_sales_data=individual_sales_data
        )
        display_factcheck_section(factcheck_prompt_individual, key_suffix="individual")


def render_delivery_section():
    """ç´å“è¨ˆç”»ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆå€‹åˆ¥ãƒ¢ãƒ¼ãƒ‰å¯¾å¿œï¼‰"""
    st.markdown('<p class="section-header">â‘¤ ç´å“è¨ˆç”»ã‚’ç«‹ã¦ã‚‹</p>', unsafe_allow_html=True)
    
    # äºˆæ¸¬çµæœãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    individual_results = st.session_state.get('individual_forecast_results', [])
    forecast = st.session_state.get('forecast_data')
    forecast_total = st.session_state.get('forecast_total', 0)
    all_methods_results = st.session_state.get('individual_all_methods_results', {})
    
    # äºˆæ¸¬çµæœãŒãªã„å ´åˆï¼ˆindividual_resultsã€forecastã€forecast_totalã€all_methods_resultsã®ã„ãšã‚Œã‚‚ãªã„ï¼‰
    has_any_forecast = (
        (individual_results and len(individual_results) > 0) or
        (forecast is not None and not (isinstance(forecast, pd.DataFrame) and forecast.empty)) or
        (forecast_total > 0) or
        (all_methods_results and len(all_methods_results) > 0)
    )
    
    if not has_any_forecast:
        st.info("éœ€è¦äºˆæ¸¬ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€ç´å“è¨ˆç”»ã‚’ç«‹ã¦ã‚‰ã‚Œã¾ã™")
        return
    
    # è¤‡æ•°å•†å“ã®å€‹åˆ¥äºˆæ¸¬çµæœãŒã‚ã‚‹å ´åˆ
    if individual_results and len(individual_results) >= 1:
        if len(individual_results) > 1:
            st.success(f"ğŸ“¦ **{len(individual_results)}ä»¶ã®å•†å“**ã®äºˆæ¸¬çµæœãŒã‚ã‚Šã¾ã™")
            
            delivery_view = st.radio(
                "ç´å“è¨ˆç”»ã®è¡¨ç¤ºæ–¹æ³•",
                ["ğŸ“Š å…¨å•†å“ã‚’åˆç®—ã—ã¦è¨ˆç”»", "ğŸ“¦ å•†å“ã”ã¨ã«å€‹åˆ¥è¨ˆç”»"],
                horizontal=True,
                key="delivery_view_mode_main"
            )
            
            if delivery_view == "ğŸ“¦ å•†å“ã”ã¨ã«å€‹åˆ¥è¨ˆç”»":
                st.divider()
                for idx, r in enumerate(individual_results):
                    product = r['product']
                    forecast_df = r['forecast']
                    rounded_total = r['rounded_total']
                    avg_predicted = r['avg_predicted']
                    
                    with st.expander(f"ğŸ“¦ **{product}**ï¼ˆäºˆæ¸¬: {rounded_total:,}ä½“ã€æ—¥è²©: {avg_predicted:.1f}ä½“ï¼‰", expanded=(idx==0)):
                        render_delivery_inputs_and_schedule(
                            total_demand=rounded_total,
                            forecast_data=forecast_df,
                            product_name=product,
                            avg_daily=avg_predicted
                        )
                return
        else:
            # 1å•†å“ã®ã¿ã®å ´åˆ
            r = individual_results[0]
            st.success(f"ğŸ“¦ **{r['product']}** ã®äºˆæ¸¬çµæœ")
    
    # åˆç®—ãƒ¢ãƒ¼ãƒ‰
    total_demand = st.session_state.get('forecast_total', 0)
    method_used = st.session_state.get('last_forecast_method', '')
    forecast_data = forecast
    
    # å¹³å‡æ—¥è²©ã‚’è¨ˆç®—
    forecast_days = len(forecast_data) if forecast_data is not None and not forecast_data.empty else 180
    avg_daily = total_demand / forecast_days if forecast_days > 0 else 0
    
    if method_used:
        st.info(f"ğŸ“¦ äºˆæ¸¬ã•ã‚ŒãŸéœ€è¦æ•°: **{total_demand:,}ä½“**ï¼ˆ{forecast_days}æ—¥é–“ã€æ—¥è²©{avg_daily:.1f}ä½“ï¼‰ - {method_used}")
    else:
        st.info(f"ğŸ“¦ äºˆæ¸¬ã•ã‚ŒãŸéœ€è¦æ•°: **{total_demand:,}ä½“**ï¼ˆ{forecast_days}æ—¥é–“ã€æ—¥è²©{avg_daily:.1f}ä½“ï¼‰")
    
    render_delivery_inputs_and_schedule(total_demand, forecast_data, "åˆç®—", avg_daily)


def render_individual_delivery_plans(results: list):
    """å€‹åˆ¥å•†å“ã”ã¨ã®ç´å“è¨ˆç”»ã‚’è¡¨ç¤º"""
    for idx, r in enumerate(results):
        product = r['product']
        forecast = r['forecast']
        rounded_total = r['rounded_total']
        avg_predicted = r['avg_predicted']
        
        with st.expander(f"ğŸ“¦ **{product}** ã®ç´å“è¨ˆç”»ï¼ˆäºˆæ¸¬: {rounded_total:,}ä½“ï¼‰", expanded=(idx==0)):
            render_delivery_inputs_and_schedule(
                total_demand=rounded_total,
                forecast_data=forecast,
                product_name=product,
                avg_daily=avg_predicted
            )


def render_delivery_inputs_and_schedule(total_demand: int, forecast_data: pd.DataFrame, product_name: str, avg_daily: float = 0):
    """ç´å“è¨ˆç”»ã®å…¥åŠ›ã¨è¨ˆç®—ã‚’è¡¨ç¤º"""
    
    key_suffix = f"{product_name.replace(' ', '_')[:8]}_{hash(product_name) % 999}"
    
    # äºˆæ¸¬æœŸé–“ï¼ˆæ—¥æ•°ï¼‰ã‚’å–å¾—
    forecast_days = len(forecast_data) if forecast_data is not None and not forecast_data.empty else 180
    if avg_daily == 0:
        avg_daily = total_demand / forecast_days if forecast_days > 0 else 0
    
    # å…¥åŠ›ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.write("**ğŸ“ åœ¨åº«ãƒ»ç™ºæ³¨æƒ…å ±ã‚’å…¥åŠ›**")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        current_stock = st.number_input(
            "ğŸ  ç¾åœ¨ã®åœ¨åº«æ•°", 
            min_value=0, 
            value=500, 
            step=50, 
            key=f"stk_{key_suffix}"
        )
    
    with col2:
        min_stock = st.number_input(
            "âš ï¸ å®‰å…¨åœ¨åº«æ•°", 
            min_value=0, 
            value=100, 
            step=50, 
            key=f"minstk_{key_suffix}"
        )
    
    with col3:
        lead_time = st.number_input(
            "ğŸšš ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ (æ—¥)", 
            min_value=1, 
            value=14, 
            step=1, 
            key=f"lt_{key_suffix}",
            help="ç™ºæ³¨ã‹ã‚‰ç´å“ã¾ã§ã®æ—¥æ•°"
        )
    
    # ç™ºæ³¨æ•°ã®è¨ˆç®—
    needed = total_demand + min_stock - current_stock
    recommended_order = round_up_to_50(max(0, needed))
    
    # æ¨å¥¨ç™ºæ³¨æ•°ã¨è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ã‚’å¸¸ã«è¡¨ç¤º
    st.divider()
    st.write("**ğŸ§® ç™ºæ³¨æ¨å¥¨æ•°ã®è¨ˆç®—**")
    
    # è¨ˆç®—éç¨‹ã‚’è¡¨å½¢å¼ã§è¡¨ç¤º
    col_calc1, col_calc2 = st.columns([2, 1])
    
    with col_calc1:
        st.markdown(f"""
        | è¨ˆç®—é …ç›® | æ•°å€¤ | èª¬æ˜ |
        |:---------|-----:|:-----|
        | â‘  äºˆæ¸¬éœ€è¦ | **{total_demand:,}ä½“** | {forecast_days}æ—¥é–“ Ã— {avg_daily:.1f}ä½“/æ—¥ |
        | â‘¡ å®‰å…¨åœ¨åº« | **+{min_stock:,}ä½“** | æ¬ å“é˜²æ­¢ã®ä½™è£•åˆ† |
        | â‘¢ ç¾åœ¨åœ¨åº« | **-{current_stock:,}ä½“** | æ—¢ã«ã‚ã‚‹åœ¨åº« |
        | **å¿…è¦æ•°é‡** | **{needed:,}ä½“** | â‘  + â‘¡ - â‘¢ |
        | **ç™ºæ³¨æ¨å¥¨æ•°** | **{recommended_order:,}ä½“** | 50ã®å€æ•°ã«åˆ‡ã‚Šä¸Šã’ |
        """)
    
    with col_calc2:
        if needed <= 0:
            st.success(f"âœ… ç™ºæ³¨ä¸è¦\n\nåœ¨åº«ã§{forecast_days}æ—¥é–“ã‚«ãƒãƒ¼å¯èƒ½")
        else:
            days_until_stockout = int(current_stock / avg_daily) if avg_daily > 0 else 999
            st.warning(f"âš ï¸ è¦ç™ºæ³¨\n\nç´„{days_until_stockout}æ—¥ã§åœ¨åº«åˆ‡ã‚Œ")
    
    # ç™ºæ³¨æ•°å…¥åŠ›æ–¹æ³•
    order_mode = st.radio(
        "ç™ºæ³¨æ•°ã®æ±ºã‚æ–¹",
        ["ğŸ”® äºˆæ¸¬ã‹ã‚‰è‡ªå‹•è¨ˆç®—", "âœï¸ æ‰‹å…¥åŠ›ã§æŒ‡å®š"],
        horizontal=True,
        key=f"ordmode_{key_suffix}"
    )
    
    if order_mode == "ğŸ”® äºˆæ¸¬ã‹ã‚‰è‡ªå‹•è¨ˆç®—":
        order_quantity = recommended_order
        st.metric("ğŸ›’ ç™ºæ³¨æ•°ï¼ˆè‡ªå‹•è¨ˆç®—ï¼‰", f"{recommended_order:,}ä½“")
    else:
        order_quantity = st.number_input(
            "âœï¸ ç™ºæ³¨æ•°ã‚’å…¥åŠ›",
            min_value=0,
            value=recommended_order,
            step=50,
            key=f"manord_{key_suffix}"
        )
    
    # ç´å“ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ææ¡ˆ
    st.divider()
    st.write("**ğŸ“… ç´å“ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ææ¡ˆ**")
    
    delivery_mode = st.radio(
        "ç´å“æ–¹æ³•",
        ["ä¸€æ‹¬ç´å“", "åˆ†å‰²ç´å“ï¼ˆæœˆåˆ¥ï¼‰", "åˆ†å‰²ç´å“ï¼ˆã‚«ã‚¹ã‚¿ãƒ ï¼‰"],
        horizontal=True,
        key=f"delivery_mode_{key_suffix}"
    )
    
    if st.button("ğŸ“Š ç´å“ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½œæˆ", type="primary", use_container_width=True, key=f"create_schedule_btn_{key_suffix}"):
        if order_quantity <= 0:
            st.warning("ç™ºæ³¨æ•°ãŒ0ã§ã™ã€‚ç™ºæ³¨ã®å¿…è¦ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            schedule = create_delivery_schedule(
                order_quantity=order_quantity,
                current_stock=current_stock,
                min_stock=min_stock,
                lead_time=lead_time,
                forecast_data=forecast_data,
                delivery_mode=delivery_mode
            )
            
            display_delivery_schedule(schedule, current_stock, min_stock, forecast_data)


def create_delivery_schedule(
    order_quantity: int,
    current_stock: int,
    min_stock: int,
    lead_time: int,
    forecast_data: pd.DataFrame,
    delivery_mode: str
) -> List[Dict]:
    """ç´å“ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½œæˆ"""
    
    today = date.today()
    
    if delivery_mode == "ä¸€æ‹¬ç´å“":
        delivery_date = today + timedelta(days=lead_time)
        return [{
            'date': delivery_date,
            'quantity': order_quantity,
            'type': 'ä¸€æ‹¬ç´å“'
        }]
    
    elif delivery_mode == "åˆ†å‰²ç´å“ï¼ˆæœˆåˆ¥ï¼‰":
        if forecast_data is None or forecast_data.empty:
            months = 3
        else:
            forecast_days = len(forecast_data)
            months = max(1, forecast_days // 30)
            months = min(months, 6)
        
        schedule = []
        qty_per_delivery = round_up_to_50(order_quantity // months)
        remaining = order_quantity
        
        for i in range(months):
            delivery_date = today + timedelta(days=lead_time + (i * 30))
            qty = min(qty_per_delivery, remaining)
            if qty > 0:
                schedule.append({
                    'date': delivery_date,
                    'quantity': qty,
                    'type': f'{i+1}å›ç›®'
                })
                remaining -= qty
        
        if remaining > 0 and schedule:
            schedule[-1]['quantity'] += remaining
        
        return schedule
    
    else:  # ã‚«ã‚¹ã‚¿ãƒ åˆ†å‰²
        schedule = []
        stock = current_stock
        
        if forecast_data is not None and not forecast_data.empty:
            daily_demands = forecast_data['predicted'].tolist()
        else:
            daily_demands = [5] * 180
        
        delivery_qty = round_up_to_50(order_quantity // 3)
        remaining = order_quantity
        last_delivery_date = today
        
        for i, daily_demand in enumerate(daily_demands):
            target_date = today + timedelta(days=i)
            stock -= daily_demand
            
            if stock <= min_stock and remaining > 0:
                order_date = target_date - timedelta(days=lead_time)
                if order_date < last_delivery_date:
                    order_date = last_delivery_date + timedelta(days=1)
                
                delivery_date = order_date + timedelta(days=lead_time)
                qty = min(delivery_qty, remaining)
                
                schedule.append({
                    'date': delivery_date,
                    'quantity': qty,
                    'type': f'{len(schedule)+1}å›ç›®'
                })
                
                stock += qty
                remaining -= qty
                last_delivery_date = delivery_date
        
        if not schedule and remaining > 0:
            schedule.append({
                'date': today + timedelta(days=lead_time),
                'quantity': remaining,
                'type': 'ä¸€æ‹¬ç´å“'
            })
        
        return schedule


def display_delivery_schedule(schedule: List[Dict], current_stock: int, min_stock: int, forecast_data: pd.DataFrame):
    """ç´å“ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’è¡¨ç¤º"""
    
    st.success(f"âœ… ç´å“ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸï¼ˆ{len(schedule)}å›ç´å“ï¼‰")
    
    st.write("**ğŸ“‹ ç´å“ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«**")
    
    schedule_df = pd.DataFrame([
        {
            'ç´å“æ—¥': s['date'].strftime('%Y/%m/%d'),
            'æ›œæ—¥': ['æœˆ','ç«','æ°´','æœ¨','é‡‘','åœŸ','æ—¥'][s['date'].weekday()],
            'æ•°é‡': f"{s['quantity']:,}ä½“",
            'å‚™è€ƒ': s['type']
        }
        for s in schedule
    ])
    
    st.dataframe(schedule_df, use_container_width=True, hide_index=True)
    
    total_delivery = sum(s['quantity'] for s in schedule)
    st.metric("ğŸ“¦ ç´å“åˆè¨ˆ", f"{total_delivery:,}ä½“")
    
    with st.expander("ğŸ“ˆ åœ¨åº«æ¨ç§»ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³", expanded=True):
        sim_data = simulate_inventory(
            schedule=schedule,
            current_stock=current_stock,
            min_stock=min_stock,
            forecast_data=forecast_data
        )
        
        if sim_data:
            display_inventory_chart(sim_data, min_stock)


def simulate_inventory(schedule: List[Dict], current_stock: int, min_stock: int, forecast_data: pd.DataFrame) -> List[Dict]:
    """åœ¨åº«ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ"""
    
    today = date.today()
    
    if forecast_data is None or forecast_data.empty:
        return []
    
    sim_data = []
    stock = current_stock
    
    delivery_dict = {}
    for s in schedule:
        d = s['date']
        if d not in delivery_dict:
            delivery_dict[d] = 0
        delivery_dict[d] += s['quantity']
    
    sim_days = min(len(forecast_data), 90)
    
    for i in range(sim_days):
        target_date = today + timedelta(days=i)
        
        if target_date in delivery_dict:
            stock += delivery_dict[target_date]
        
        if i < len(forecast_data):
            daily_demand = forecast_data.iloc[i]['predicted']
        else:
            daily_demand = forecast_data['predicted'].mean()
        
        stock -= daily_demand
        stock = max(0, stock)
        
        sim_data.append({
            'date': target_date,
            'stock': stock,
            'demand': daily_demand,
            'delivery': delivery_dict.get(target_date, 0)
        })
    
    return sim_data


def display_inventory_chart(sim_data: List[Dict], min_stock: int):
    """åœ¨åº«æ¨ç§»ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºï¼ˆã‚¹ãƒãƒ›æœ€é©åŒ–ï¼‰"""
    
    df = pd.DataFrame(sim_data)
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=df['date'],
        y=df['stock'],
        mode='lines',
        name='åœ¨åº«æ•°',
        line=dict(color='#1E88E5', width=2),
        fill='tozeroy',
        fillcolor='rgba(30, 136, 229, 0.1)'
    ))
    
    fig.add_hline(
        y=min_stock, 
        line_dash="dash", 
        line_color="red",
        annotation_text=f"å®‰å…¨åœ¨åº« {min_stock}",
        annotation_position="right"
    )
    
    deliveries = df[df['delivery'] > 0]
    if not deliveries.empty:
        fig.add_trace(go.Scatter(
            x=deliveries['date'],
            y=deliveries['stock'],
            mode='markers',
            name='ç´å“',
            marker=dict(color='green', size=12, symbol='triangle-up')
        ))
    
    fig.update_layout(
        title='åœ¨åº«æ¨ç§»ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³',
        xaxis_title='æ—¥ä»˜',
        yaxis_title='åœ¨åº«æ•°ï¼ˆä½“ï¼‰',
        height=300,
        margin=dict(l=10, r=10, t=40, b=10),
        legend=dict(
            orientation='h',
            yanchor='bottom',
            y=1.02,
            xanchor='center',
            x=0.5
        ),
        dragmode=False,
    )
    
    config = {
        'displayModeBar': False,
        'staticPlot': False,
        'responsive': True
    }
    
    st.plotly_chart(fig, use_container_width=True, config=config)
    
    stock_below_min = df[df['stock'] < min_stock]
    if not stock_below_min.empty:
        first_danger = stock_below_min.iloc[0]['date']
        st.warning(f"âš ï¸ {first_danger.strftime('%Y/%m/%d')}é ƒã«åœ¨åº«ãŒå®‰å…¨åœ¨åº«ã‚’ä¸‹å›ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")


# =============================================================================
# æ–°è¦æˆä¸å“ã®éœ€è¦äºˆæ¸¬
# =============================================================================

def render_new_product_forecast():
    """æ–°è¦æˆä¸å“ã®éœ€è¦äºˆæ¸¬"""
    
    st.markdown("""
    <div class="new-product-card">
        <h2>âœ¨ æ–°è¦æˆä¸å“ã®éœ€è¦äºˆæ¸¬</h2>
        <p>ã¾ã è²©å£²å®Ÿç¸¾ã®ãªã„æ–°ã—ã„æˆä¸å“ã®éœ€è¦ã‚’ã€é¡ä¼¼å•†å“ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰äºˆæ¸¬ã—ã¾ã™ã€‚</p>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown('<p class="section-header">â‘  æ–°è¦æˆä¸å“ã®æƒ…å ±ã‚’å…¥åŠ›</p>', unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        new_product_name = st.text_input(
            "æˆä¸å“å",
            placeholder="ä¾‹: ç¸çµã³æ°´æ™¶å®ˆ",
            help="æ–°ã—ãä½œã‚‹æˆä¸å“ã®åå‰"
        )
        
        new_product_category = st.selectbox(
            "ã‚«ãƒ†ã‚´ãƒªãƒ¼",
            list(CATEGORY_CHARACTERISTICS.keys()),
            help="æœ€ã‚‚è¿‘ã„ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’é¸ã‚“ã§ãã ã•ã„"
        )
        
        new_product_price = st.number_input(
            "ä¾¡æ ¼ï¼ˆå††ï¼‰",
            min_value=100,
            max_value=50000,
            value=1000,
            step=100,
            help="è²©å£²äºˆå®šä¾¡æ ¼"
        )
    
    with col2:
        new_product_description = st.text_area(
            "ç‰¹å¾´ãƒ»ã‚³ãƒ³ã‚»ãƒ—ãƒˆ",
            placeholder="ä¾‹: æ°´æ™¶ã‚’ä½¿ç”¨ã—ãŸç¸çµã³ã®ãŠå®ˆã‚Šã€‚è‹¥ã„å¥³æ€§å‘ã‘ã€‚",
            help="æˆä¸å“ã®ç‰¹å¾´ã‚’è¨˜è¿°"
        )
        
        target_audience = st.multiselect(
            "ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤",
            ["è‹¥ã„å¥³æ€§", "è‹¥ã„ç”·æ€§", "ä¸­é«˜å¹´å¥³æ€§", "ä¸­é«˜å¹´ç”·æ€§", "å®¶æ—é€£ã‚Œ", "è¦³å…‰å®¢", "åœ°å…ƒã®æ–¹"],
            default=["è‹¥ã„å¥³æ€§", "è¦³å…‰å®¢"]
        )
    
    st.markdown('<p class="section-header">â‘¡ é¡ä¼¼å•†å“ã‚’åˆ†æ</p>', unsafe_allow_html=True)
    
    if new_product_name and new_product_name.strip():
        similar_products = find_similar_products(
            new_product_name, 
            new_product_category, 
            new_product_price,
            new_product_description
        )
        
        if similar_products:
            st.write(f"**é¡ä¼¼å•†å“ãŒ {len(similar_products)} ä»¶è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ**")
            
            for i, prod in enumerate(similar_products[:5], 1):
                col1, col2, col3 = st.columns([3, 1, 1])
                with col1:
                    st.write(f"{i}. {prod['name']}")
                with col2:
                    st.write(f"å¹³å‡ {prod['avg_daily']:.1f}ä½“/æ—¥")
                with col3:
                    st.write(f"é¡ä¼¼åº¦ {prod['similarity']:.0f}%")
        else:
            st.info("é¡ä¼¼å•†å“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®å¹³å‡å€¤ã‹ã‚‰äºˆæ¸¬ã—ã¾ã™ã€‚")
    else:
        similar_products = []
        st.info("ğŸ‘† æˆä¸å“åã‚’å…¥åŠ›ã™ã‚‹ã¨ã€é¡ä¼¼å•†å“ã‚’æ¤œç´¢ã—ã¾ã™")
    
    st.markdown('<p class="section-header">â‘¢ éœ€è¦äºˆæ¸¬</p>', unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        forecast_period = st.selectbox(
            "äºˆæ¸¬æœŸé–“",
            ["1ãƒ¶æœˆ", "3ãƒ¶æœˆ", "6ãƒ¶æœˆ", "1å¹´"],
            index=2
        )
    
    with col2:
        confidence_level = st.selectbox(
            "äºˆæ¸¬ã®ä¿å®ˆæ€§",
            ["æ¥½è¦³çš„", "æ¨™æº–", "ä¿å®ˆçš„"],
            index=1
        )
    
    if st.button("ğŸ”® æ–°è¦æˆä¸å“ã®éœ€è¦ã‚’äºˆæ¸¬", type="primary", use_container_width=True):
        if not new_product_name or not new_product_name.strip():
            st.error("æˆä¸å“åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        else:
            with st.spinner("äºˆæ¸¬ä¸­..."):
                forecast_result = forecast_new_product(
                    new_product_name,
                    new_product_category,
                    new_product_price,
                    similar_products,
                    forecast_period,
                    confidence_level
                )
                
                display_new_product_forecast(forecast_result, new_product_name, new_product_price)


def find_similar_products(name: str, category: str, price: int, description: str) -> list:
    """é¡ä¼¼å•†å“ã‚’æ¢ã™"""
    
    if not name or not name.strip():
        return []
    
    if st.session_state.data_loader is None:
        return []
    
    df_items = st.session_state.data_loader.load_item_sales()
    
    if df_items.empty:
        return []
    
    product_col = 'å•†å“å'
    qty_col = 'è²©å£²å•†å“æ•°'
    sales_col = 'è²©å£²ç·å£²ä¸Š'
    
    product_stats = df_items.groupby(product_col).agg({
        qty_col: ['sum', 'mean', 'count'],
        sales_col: 'sum'
    }).reset_index()
    
    product_stats.columns = ['name', 'total_qty', 'avg_daily', 'days_count', 'total_sales']
    
    product_stats['unit_price'] = product_stats['total_sales'] / product_stats['total_qty']
    product_stats['unit_price'] = product_stats['unit_price'].fillna(0)
    
    similar = []
    
    keywords = set(re.findall(r'[\u4e00-\u9fff]+', name.lower()))
    if description:
        keywords.update(re.findall(r'[\u4e00-\u9fff]+', description.lower()))
    
    for _, row in product_stats.iterrows():
        prod_name = row['name']
        
        name_keywords = set(re.findall(r'[\u4e00-\u9fff]+', prod_name.lower()))
        name_match = len(keywords & name_keywords) / max(len(keywords), 1) * 50
        
        if row['unit_price'] > 0:
            price_diff = abs(price - row['unit_price']) / price
            price_match = max(0, (1 - price_diff)) * 30
        else:
            price_match = 0
        
        category_keywords = {
            "ãŠå®ˆã‚Š": ["å®ˆ", "ãŠå®ˆã‚Š", "ã¾ã‚‚ã‚Š"],
            "å¾¡æœ±å°": ["å¾¡æœ±å°", "æœ±å°"],
            "å¾¡æœ±å°å¸³": ["å¾¡æœ±å°å¸³", "æœ±å°å¸³"],
            "ãŠã¿ãã˜": ["ãŠã¿ãã˜", "ã¿ãã˜"],
            "çµµé¦¬": ["çµµé¦¬"],
            "ãŠæœ­": ["æœ­", "ãŠæœ­"],
            "ç¸èµ·ç‰©": ["ç¸èµ·", "ã ã‚‹ã¾", "æ‹›ãçŒ«"],
        }
        
        cat_match = 0
        for cat, kws in category_keywords.items():
            if cat == category:
                for kw in kws:
                    if kw in prod_name:
                        cat_match = 20
                        break
        
        similarity = name_match + price_match + cat_match
        
        if similarity > 10 and row['total_qty'] > 0:
            similar.append({
                'name': prod_name,
                'total_qty': row['total_qty'],
                'avg_daily': row['avg_daily'],
                'unit_price': row['unit_price'],
                'similarity': similarity
            })
    
    similar.sort(key=lambda x: x['similarity'], reverse=True)
    
    return similar[:10]


def forecast_new_product(name: str, category: str, price: int, 
                         similar_products: list, period: str, confidence: str) -> dict:
    """æ–°è¦æˆä¸å“ã®éœ€è¦ã‚’äºˆæ¸¬"""
    
    period_days = {"1ãƒ¶æœˆ": 30, "3ãƒ¶æœˆ": 90, "6ãƒ¶æœˆ": 180, "1å¹´": 365}[period]
    confidence_factor = {"æ¥½è¦³çš„": 1.2, "æ¨™æº–": 1.0, "ä¿å®ˆçš„": 0.7}[confidence]
    
    if similar_products:
        weighted_sum = sum(p['avg_daily'] * p['similarity'] for p in similar_products[:5])
        weight_total = sum(p['similarity'] for p in similar_products[:5])
        base_daily = weighted_sum / weight_total if weight_total > 0 else 1.0
    else:
        base_daily = CATEGORY_CHARACTERISTICS.get(category, {}).get('base_daily', 1.0)
    
    cat_char = CATEGORY_CHARACTERISTICS.get(category, {})
    seasonality = cat_char.get('seasonality', 'medium')
    
    if seasonality == 'high':
        month_factors = {1: 3.0, 2: 0.7, 3: 0.9, 4: 0.9, 5: 1.0, 6: 0.8,
                        7: 0.9, 8: 1.1, 9: 0.9, 10: 1.0, 11: 1.2, 12: 1.5}
    elif seasonality == 'medium':
        month_factors = {1: 1.5, 2: 0.9, 3: 1.0, 4: 1.0, 5: 1.1, 6: 0.9,
                        7: 1.0, 8: 1.1, 9: 1.0, 10: 1.0, 11: 1.1, 12: 1.2}
    else:
        month_factors = {i: 1.0 for i in range(1, 13)}
    
    daily_forecast = []
    total_qty = 0
    
    for i in range(period_days):
        target_date = date.today() + timedelta(days=i)
        month = target_date.month
        weekday = target_date.weekday()
        
        weekday_factor = 1.5 if weekday >= 5 else 1.0
        month_factor = month_factors.get(month, 1.0)
        
        pred = base_daily * weekday_factor * month_factor * confidence_factor
        pred = max(0, round(pred))
        
        daily_forecast.append({
            'date': target_date,
            'predicted': pred
        })
        
        total_qty += pred
    
    total_qty_rounded = round_up_to_50(total_qty)
    
    df_forecast = pd.DataFrame(daily_forecast)
    df_forecast['month'] = pd.to_datetime(df_forecast['date']).dt.to_period('M')
    monthly = df_forecast.groupby('month')['predicted'].sum().to_dict()
    
    return {
        'daily_forecast': daily_forecast,
        'total_qty': total_qty,
        'total_qty_rounded': total_qty_rounded,
        'avg_daily': total_qty / period_days,
        'period_days': period_days,
        'monthly': monthly,
        'base_daily': base_daily,
        'confidence': confidence,
        'similar_count': len(similar_products)
    }


def display_new_product_forecast(result: dict, product_name: str, price: int):
    """æ–°è¦æˆä¸å“ã®äºˆæ¸¬çµæœã‚’è¡¨ç¤º"""
    
    st.success("âœ… äºˆæ¸¬å®Œäº†ï¼")
    
    st.write(f"### ğŸ“¦ ã€Œ{product_name}ã€ã®éœ€è¦äºˆæ¸¬")
    
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("äºˆæ¸¬è²©å£²ç·æ•°", f"{result['total_qty_rounded']:,}ä½“")
    col2.metric("äºˆæ¸¬å£²ä¸Š", f"Â¥{result['total_qty_rounded'] * price:,.0f}")
    col3.metric("å¹³å‡æ—¥è²©", f"{result['avg_daily']:.1f}ä½“/æ—¥")
    col4.metric("äºˆæ¸¬æœŸé–“", f"{result['period_days']}æ—¥é–“")
    
    if result['similar_count'] >= 3:
        st.info(f"ğŸ“Š é¡ä¼¼å•†å“ {result['similar_count']} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’åŸºã«äºˆæ¸¬ã—ã¾ã—ãŸã€‚ä¿¡é ¼åº¦: â­â­â­")
    elif result['similar_count'] >= 1:
        st.warning(f"ğŸ“Š é¡ä¼¼å•†å“ {result['similar_count']} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’åŸºã«äºˆæ¸¬ã—ã¾ã—ãŸã€‚ä¿¡é ¼åº¦: â­â­")
    else:
        st.warning("ğŸ“Š é¡ä¼¼å•†å“ãŒãªã‹ã£ãŸãŸã‚ã€ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®å¹³å‡å€¤ã‹ã‚‰äºˆæ¸¬ã—ã¾ã—ãŸã€‚ä¿¡é ¼åº¦: â­")
    
    monthly_data = []
    for period, qty in result['monthly'].items():
        monthly_data.append({'æœˆ': str(period), 'äºˆæ¸¬è²©å£²æ•°': qty})
    
    df_monthly = pd.DataFrame(monthly_data)
    
    fig = px.bar(
        df_monthly, x='æœˆ', y='äºˆæ¸¬è²©å£²æ•°',
        title='æœˆåˆ¥äºˆæ¸¬è²©å£²æ•°',
        color='äºˆæ¸¬è²©å£²æ•°',
        color_continuous_scale='Blues'
    )
    st.plotly_chart(fig, use_container_width=True)
    
    st.write("### ğŸ“‹ åˆå›ç™ºæ³¨é‡ã®ææ¡ˆ")
    
    col1, col2, col3 = st.columns(3)
    col1.metric("å°‘ãªã‚ï¼ˆ1ãƒ¶æœˆåˆ†ï¼‰", f"{round_up_to_50(int(result['avg_daily'] * 30))}ä½“")
    col2.metric("æ¨™æº–ï¼ˆ3ãƒ¶æœˆåˆ†ï¼‰", f"{round_up_to_50(int(result['avg_daily'] * 90))}ä½“")
    col3.metric("å¤šã‚ï¼ˆ6ãƒ¶æœˆåˆ†ï¼‰", f"{round_up_to_50(int(result['avg_daily'] * 180))}ä½“")


# =============================================================================
# é«˜åº¦ãªåˆ†æ
# =============================================================================

def render_advanced_analysis():
    """é«˜åº¦ãªåˆ†æã‚¿ãƒ–"""
    st.markdown('<p class="section-header">ğŸ”¬ é«˜åº¦ãªåˆ†æ</p>', unsafe_allow_html=True)
    
    if not ADVANCED_ANALYSIS_AVAILABLE:
        st.warning("demand_analyzer.pyãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    sales_data = st.session_state.get('sales_data')
    
    if sales_data is None or sales_data.empty:
        st.info("ã€Œæ—¢å­˜æˆä¸å“ã®åˆ†æãƒ»äºˆæ¸¬ã€ã‚¿ãƒ–ã§æˆä¸å“ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return
    
    try:
        df_items = st.session_state.data_loader.load_item_sales()
        internal = InternalAnalyzer(df_items)
        external = ExternalAnalyzer(df_items, None)
    except Exception as e:
        st.error(f"åˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return
    
    with st.expander("ğŸ“Š **é«˜åº¦ãªåˆ†æã‚’è¦‹ã‚‹**", expanded=False):
        tab1, tab2, tab3 = st.tabs(["ğŸ“ˆ ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ", "ğŸ—“ï¸ å­£ç¯€æ€§åˆ†æ", "ğŸŒ¤ï¸ å¤–éƒ¨è¦å› åˆ†æ"])
        
        with tab1:
            render_trend_analysis(internal)
        
        with tab2:
            render_seasonality_analysis(internal)
        
        with tab3:
            render_external_analysis(external)


def render_trend_analysis(internal):
    """ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã‚’è¡¨ç¤º"""
    st.write("### ğŸ“ˆ è²©å£²ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ")
    
    try:
        trend = internal.analyze_sales_trend()
        
        col1, col2, col3 = st.columns(3)
        col1.metric("ãƒˆãƒ¬ãƒ³ãƒ‰æ–¹å‘", trend['trend_direction'])
        col2.metric("æˆé•·ç‡", f"{trend['growth_rate']}%")
        col3.metric("å¤‰å‹•æ€§", f"{trend['volatility']:.2f}")
        
        if 'monthly_data' in trend and not trend['monthly_data'].empty:
            fig = px.line(
                trend['monthly_data'], 
                x='period', 
                y='è²©å£²å•†å“æ•°',
                title='æœˆåˆ¥è²©å£²æ¨ç§»'
            )
            st.plotly_chart(fig, use_container_width=True)
    except Exception as e:
        st.warning(f"ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")


def render_seasonality_analysis(internal):
    """å­£ç¯€æ€§åˆ†æã‚’è¡¨ç¤º"""
    st.write("### ğŸ—“ï¸ å­£ç¯€æ€§åˆ†æ")
    
    try:
        seasonality = internal.detect_seasonality()
        
        st.metric("å­£ç¯€æ€§ã®å¼·ã•", f"{seasonality['seasonality_strength']:.2f}")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**æœˆåˆ¥ä¿‚æ•°**")
            monthly = seasonality['monthly_pattern']
            df_monthly = pd.DataFrame({
                'æœˆ': list(monthly.keys()),
                'ä¿‚æ•°': list(monthly.values())
            })
            fig = px.bar(df_monthly, x='æœˆ', y='ä¿‚æ•°', title='æœˆåˆ¥è²©å£²ä¿‚æ•°')
            fig.add_hline(y=1.0, line_dash="dash", line_color="red")
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.write("**æ›œæ—¥åˆ¥ä¿‚æ•°**")
            weekday = seasonality['weekday_pattern']
            df_weekday = pd.DataFrame({
                'æ›œæ—¥': list(weekday.keys()),
                'ä¿‚æ•°': list(weekday.values())
            })
            fig = px.bar(df_weekday, x='æ›œæ—¥', y='ä¿‚æ•°', title='æ›œæ—¥åˆ¥è²©å£²ä¿‚æ•°')
            fig.add_hline(y=1.0, line_dash="dash", line_color="red")
            st.plotly_chart(fig, use_container_width=True)
    except Exception as e:
        st.warning(f"å­£ç¯€æ€§åˆ†æã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")


def render_external_analysis(external):
    """å¤–éƒ¨è¦å› åˆ†æã‚’è¡¨ç¤º"""
    st.write("### ğŸŒ¤ï¸ å¤–éƒ¨è¦å› åˆ†æ")
    
    try:
        calendar_effect = external.analyze_calendar_effect()
        
        if calendar_effect.get('available', False):
            st.metric("ä¼‘æ—¥ã®å½±éŸ¿åº¦", f"{calendar_effect['holiday_impact']:.2f}x")
        else:
            st.info("ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚ã€å¤–éƒ¨è¦å› åˆ†æã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
    except Exception as e:
        st.warning(f"å¤–éƒ¨è¦å› åˆ†æã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")


# =============================================================================
# äºˆæ¸¬ç²¾åº¦ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
# =============================================================================

def render_accuracy_dashboard():
    """äºˆæ¸¬ç²¾åº¦ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"""
    
    st.markdown('<p class="section-header">ğŸ“ˆ äºˆæ¸¬ç²¾åº¦ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰</p>', unsafe_allow_html=True)
    
    try:
        service = st.session_state.data_loader.service
        result = service.spreadsheets().values().get(
            spreadsheetId=st.session_state.data_loader.spreadsheet_id,
            range="'forecast_accuracy'!A:H"
        ).execute()
        
        values = result.get('values', [])
        
        if len(values) <= 1:
            st.info("""
            ğŸ“Š ã¾ã äºˆæ¸¬ç²¾åº¦ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚
            
            è‡ªå‹•å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ãŒç¨¼åƒã™ã‚‹ã¨ã€ã“ã“ã«äºˆæ¸¬ç²¾åº¦ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚
            """)
            return
        
        headers = values[0]
        df = pd.DataFrame(values[1:], columns=headers)
        
        df['date'] = pd.to_datetime(df['date'], errors='coerce')
        df['predicted_qty'] = pd.to_numeric(df['predicted_qty'], errors='coerce')
        df['actual_qty'] = pd.to_numeric(df['actual_qty'], errors='coerce')
        df['diff_pct'] = pd.to_numeric(df['diff_pct'], errors='coerce')
        
        st.write("### éå»30æ—¥é–“ã®äºˆæ¸¬ç²¾åº¦")
        
        recent = df[df['date'] >= (datetime.now() - timedelta(days=30))]
        
        if not recent.empty:
            avg_error = recent['diff_pct'].abs().mean()
            total_predicted = recent['predicted_qty'].sum()
            total_actual = recent['actual_qty'].sum()
            accuracy = 100 - avg_error
            
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("å¹³å‡èª¤å·®ç‡", f"{avg_error:.1f}%")
            col2.metric("äºˆæ¸¬ç²¾åº¦", f"{accuracy:.1f}%")
            col3.metric("äºˆæ¸¬åˆè¨ˆ", f"{total_predicted:.0f}ä½“")
            col4.metric("å®Ÿç¸¾åˆè¨ˆ", f"{total_actual:.0f}ä½“")
            
            fig = go.Figure()
            
            daily = recent.groupby('date').agg({
                'predicted_qty': 'sum',
                'actual_qty': 'sum'
            }).reset_index()
            
            fig.add_trace(go.Scatter(
                x=daily['date'],
                y=daily['predicted_qty'],
                mode='lines+markers',
                name='äºˆæ¸¬',
                line=dict(color='#4285F4')
            ))
            
            fig.add_trace(go.Scatter(
                x=daily['date'],
                y=daily['actual_qty'],
                mode='lines+markers',
                name='å®Ÿç¸¾',
                line=dict(color='#4CAF50')
            ))
            
            fig.update_layout(
                title='äºˆæ¸¬ vs å®Ÿç¸¾ï¼ˆæ—¥åˆ¥ï¼‰',
                xaxis_title='æ—¥ä»˜',
                yaxis_title='è²©å£²æ•°ï¼ˆä½“ï¼‰'
            )
            
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("éå»30æ—¥é–“ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
    
    except Exception as e:
        st.info("""
        ğŸ“Š äºˆæ¸¬ç²¾åº¦ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’è¡¨ç¤ºã™ã‚‹ã«ã¯ã€è‡ªå‹•å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãŒå¿…è¦ã§ã™ã€‚
        """)


# =============================================================================
# ãƒ¡ã‚¤ãƒ³é–¢æ•°
# =============================================================================

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    
    # ========== å‰Šé™¤ãƒ•ãƒ©ã‚°ã®å‡¦ç†ï¼ˆãƒšãƒ¼ã‚¸å…ˆé ­ã§å®Ÿè¡Œï¼‰ ==========
    if st.session_state.get('pending_delete_product'):
        product_to_delete = st.session_state.pending_delete_product
        if product_to_delete in st.session_state.selected_products:
            st.session_state.selected_products.remove(product_to_delete)
        if product_to_delete in st.session_state.product_groups:
            del st.session_state.product_groups[product_to_delete]
        st.session_state.sales_data = None
        st.session_state.forecast_data = None
        st.session_state.individual_sales_data = {}
        st.session_state.individual_forecast_results = []
        st.session_state.individual_all_methods_results = {}
        st.session_state.pending_delete_product = None
    
    if not init_data():
        st.stop()
    
    render_header()
    st.divider()
    render_main_tabs()
    
    st.divider()
    
    # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ï¼ˆv20æ›´æ–°ï¼‰
    version_info = "v20 (ç²¾åº¦å‘ä¸Šç‰ˆ - 0åŸ‹ã‚ãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»æ­£æœˆæ—¥åˆ¥å¯¾å¿œ)"
    if VERTEX_AI_AVAILABLE:
        version_info += " | ğŸš€ Vertex AI: æœ‰åŠ¹"
    else:
        version_info += " | âš ï¸ Vertex AI: æœªè¨­å®š"
    
    st.caption(f"â›©ï¸ é…’åˆ—ç£¯å‰ç¥ç¤¾ æˆä¸å“ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ  {version_info}")


if __name__ == "__main__":
    main()
